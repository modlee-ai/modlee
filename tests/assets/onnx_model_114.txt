<
   ir_version: 9,
   opset_import: ["" : 17],
   producer_name: "pytorch",
   producer_version: "2.2.2"
>
main_graph (float[input_1_dynamic_axes_1,1,28,28] input_1, float[6,1,5,5] classifier_conv1_weight, float[6] classifier_conv1_bias, float[16,6,5,5] classifier_conv2_weight, float[16] classifier_conv2_bias, float[120,256] classifier_fc1_weight, float[120] classifier_fc1_bias, float[84,120] classifier_fc2_weight, float[84] classifier_fc2_bias, float[10,84] classifier_fc3_weight, float[10] classifier_fc3_bias) => (float[softmax_output_0000_dynamic_axes_1,10] output_var) {
   conv_output_0000 = Conv <dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [0, 0, 0, 0], strides = [1, 1]> (input_1, classifier_conv1_weight, classifier_conv1_bias)
   relu_output_0000 = Relu (conv_output_0000)
   maxpool_output_0000 = MaxPool <ceil_mode = 0, dilations = [1, 1], kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]> (relu_output_0000)
   conv_output_0001 = Conv <dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [0, 0, 0, 0], strides = [1, 1]> (maxpool_output_0000, classifier_conv2_weight, classifier_conv2_bias)
   relu_output_0001 = Relu (conv_output_0001)
   maxpool_output_0001 = MaxPool <ceil_mode = 0, dilations = [1, 1], kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]> (relu_output_0001)
   constant_output_0000 = Constant <value = int64[2] {-1,256}> ()
   reshape_output_0000 = Reshape <allowzero = 0> (maxpool_output_0001, constant_output_0000)
   gemm_output_0000 = Gemm <alpha = 1, beta = 1, transB = 1> (reshape_output_0000, classifier_fc1_weight, classifier_fc1_bias)
   relu_output_0002 = Relu (gemm_output_0000)
   gemm_output_0001 = Gemm <alpha = 1, beta = 1, transB = 1> (relu_output_0002, classifier_fc2_weight, classifier_fc2_bias)
   relu_output_0003 = Relu (gemm_output_0001)
   gemm_output_0002 = Gemm <alpha = 1, beta = 1, transB = 1> (relu_output_0003, classifier_fc3_weight, classifier_fc3_bias)
   output_var = Softmax <axis = 1> (gemm_output_0002)
}