{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/modlee3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/.conda/envs/modlee3.12/lib/python3.12/site-packages/modlee/converter.py:354: SyntaxWarning: invalid escape sequence '\\('\n",
      "  \"makrograph-edge\\((\\d*),(\\d*)\\)_\",\n",
      "/home/ubuntu/.conda/envs/modlee3.12/lib/python3.12/site-packages/modlee/converter.py:535: SyntaxWarning: invalid escape sequence '\\['\n",
      "  bool_dim = re.search(\"bool\\[(?P<bool_dim>.*)\\]\", input_str)\n",
      "/home/ubuntu/.conda/envs/modlee3.12/lib/python3.12/site-packages/modlee/converter.py:577: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  return re.sub(\"([\\s(,]+)(\\d+)_*([a-zA-Z0-9]*)[\\s_=]\", \"\\\\1\\\\3_\\\\2_\", input_str)\n",
      "/home/ubuntu/.conda/envs/modlee3.12/lib/python3.12/site-packages/modlee/converter.py:1044: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  \"(Tile.*), (.*)\\)\",\n",
      "/home/ubuntu/.conda/envs/modlee3.12/lib/python3.12/site-packages/modlee/converter.py:1056: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  return re.sub(\"(Gather.*), (.*)\\)\", \"\\\\1, \\\\2.type(torch.int64))\", input_str)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmodlee\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m \u001b[39mimport\u001b[39;00m data_metafeatures \u001b[39mas\u001b[39;00m dmf\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m text_loaders, image_loaders\n",
      "File \u001b[0;32m~/.conda/envs/modlee3.12/lib/python3.12/site-packages/modlee/__init__.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m save_run, last_run_path, save_run_as_json\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel_text_converter\u001b[39;00m \u001b[39mimport\u001b[39;00m get_code_text, get_code_text_for_model\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     model_text_converter,\n\u001b[1;32m     36\u001b[0m     exp_loss_logger,\n\u001b[1;32m     37\u001b[0m     data_metafeatures,\n\u001b[1;32m     38\u001b[0m     model,\n\u001b[1;32m     39\u001b[0m     recommender,\n\u001b[1;32m     40\u001b[0m     config\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m api_modules \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mmodel_text_converter\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mexp_loss_logger\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     44\u001b[0m modules \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(join(dirname(\u001b[39m__file__\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39m*.py\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/modlee3.12/lib/python3.12/site-packages/modlee/model/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimage_model\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrecommended_model\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/modlee3.12/lib/python3.12/site-packages/modlee/model/model.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m \u001b[39mimport\u001b[39;00m data_metafeatures, save_run, get_code_text_for_model, save_run_as_json\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m \u001b[39mimport\u001b[39;00m logging, utils \u001b[39mas\u001b[39;00m modlee_utils, exp_loss_logger\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverter\u001b[39;00m \u001b[39mimport\u001b[39;00m Converter\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     27\u001b[0m modlee_converter \u001b[39m=\u001b[39m Converter()\n",
      "File \u001b[0;32m~/.conda/envs/modlee3.12/lib/python3.12/site-packages/modlee/converter.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39monnx_graphsurgeon\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgs\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39monnx\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39monnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m net_drawer\n\u001b[1;32m     26\u001b[0m ONNX_MINOR_VERSION \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(onnx\u001b[39m.\u001b[39m__version__\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/modlee3.12/lib/python3.12/site-packages/onnx/tools/net_drawer.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Callable, Dict, Optional\n\u001b[0;32m---> 22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpydot\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m GraphProto, ModelProto, NodeProto\n\u001b[1;32m     26\u001b[0m OP_STYLE \u001b[39m=\u001b[39m {\n\u001b[1;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mbox\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m#0F9D58\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstyle\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mfilled\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfontcolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m#FFFFFF\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m }\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pytest\n",
    "import re, os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "import modlee\n",
    "from modlee import data_metafeatures as dmf\n",
    "from modlee.utils import text_loaders, image_loaders\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import karateclub\n",
    "\n",
    "import torch_geometric\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx \n",
    "import onnx\n",
    "from onnx.tools import net_drawer\n",
    "import matplotlib as mpl\n",
    "import copy\n",
    "# import torch_geometric as pyg\n",
    "import numpy as np\n",
    "import torch_geometric as pyg\n",
    "# from torch_geometric.utils import convert\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from transformers import GraphormerForGraphClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import torch\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import DimeNet, DimeNetPlusPlus\n",
    "\n",
    "DATA_ROOT = os.path.expanduser(\"~/efs/.data\")\n",
    "IMAGE_DATALOADER = modlee.utils.get_imagenette_dataloader()\n",
    "# TEXT_DATALOADER = modlee.utils.get_wnli_dataloader() \n",
    "\n",
    "\n",
    "TEXT_LOADERS = {loader_fn:getattr(text_loaders, loader_fn) for loader_fn in dir(text_loaders) if re.match('get_(.*)_dataloader', loader_fn)}\n",
    "IMAGE_LOADERS = [getattr(image_loaders, loader_fn) for loader_fn in dir(image_loaders) if re.match('get_(.*)_dataloader', loader_fn)]\n",
    "\n",
    "# things to install:\n",
    "# torch_geometric, pydot, transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/modlee312/bin/pip3\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
      "Requirement already satisfied: torch-scatter in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (2.1.2+pt23cu121)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
      "Collecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp312-cp312-linux_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-sparse) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from scipy->torch-sparse) (1.26.4)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.18+pt23cu121\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
      "Requirement already satisfied: torch-cluster in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (1.6.3+pt23cu121)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-cluster) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from scipy->torch-cluster) (1.26.4)\n",
      "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
      "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-jxmo42r3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-jxmo42r3\n",
      "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit e9648df16dcb6dde0e09b5736b1b2da5d68db2ad\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (3.9.5)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (2024.5.0)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (3.1.4)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (3.1.2)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (2.32.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (1.4.2)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (1.13.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch-geometric==2.6.0) (4.66.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch-geometric==2.6.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch-geometric==2.6.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch-geometric==2.6.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch-geometric==2.6.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch-geometric==2.6.0) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from jinja2->torch-geometric==2.6.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from requests->torch-geometric==2.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from requests->torch-geometric==2.6.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from requests->torch-geometric==2.6.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from requests->torch-geometric==2.6.0) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from scikit-learn->torch-geometric==2.6.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from scikit-learn->torch-geometric==2.6.0) (3.5.0)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (4.41.0)\n",
      "Requirement already satisfied: pydot in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: torch_geometric in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (2.32.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from pydot) (3.1.2)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch_geometric) (3.9.5)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch_geometric) (2024.5.0)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch_geometric) (5.9.8)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch_geometric) (1.4.2)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from torch_geometric) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch_geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages (from scikit-learn->torch_geometric) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Only need to run if the environment does not have torch-{scatter,sparse,cluster}\n",
    "!which pip3\n",
    "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster --y\n",
    "!pip install --no-cache torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install  --no-cache torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install  --no-cache torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip3 install transformers pydot torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imports():\n",
    "    # !cat metafeatures.ipynb | grep import\n",
    "    with open('./metafeatures.ipynb','r') as _f:\n",
    "        l = _f.readlines()\n",
    "    # print('\\n'.join(l[:100]))\n",
    "        \n",
    "    l = [_l.strip().replace('\\\\n','').replace('\"','').replace(',','') for _l in l if 'import' in _l]\n",
    "    # print(l)\n",
    "    # print('\\n'.join(l))\n",
    "    return '\\n'.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_global = None\n",
    "def get_df_from_loaders(loaders, modality, n_samples=1):\n",
    "    global mf_global\n",
    "    if isinstance(loaders, dict):\n",
    "        loaders = list(loaders.values())\n",
    "    df = pd.DataFrame()\n",
    "    print(loaders)\n",
    "    features = []\n",
    "    MFClass = getattr(dmf, f\"{modality.capitalize()}DataMetafeatures\")\n",
    "    for loader_fn in loaders:\n",
    "        for _ in range(n_samples):\n",
    "            metafeatures = MFClass(\n",
    "                loader_fn(root=DATA_ROOT), testing=True\n",
    "            )\n",
    "            if hasattr(loader_fn, 'args'):\n",
    "                dataset_name = loader_fn.args[0]\n",
    "            else:\n",
    "                dataset_name = loader_fn.__name__\n",
    "            mf_global = metafeatures\n",
    "            features.append({\n",
    "                    'dataset_name':dataset_name,\n",
    "                    **metafeatures.embedding,\n",
    "                    **metafeatures.mfe,\n",
    "                    **metafeatures.properties,\n",
    "            })\n",
    "            pd.DataFrame(features[-1]).to_csv(\n",
    "                f'./{modality}_features_cache.csv',\n",
    "                mode='a')\n",
    "    df = pd.DataFrame(features)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_mf_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataframes\u001b[39;00m \u001b[39mimport\u001b[39;00m ModleeDataFrame, default_transforms\n\u001b[0;32m----> 2\u001b[0m model_mf_df \u001b[39m=\u001b[39m ModleeDataFrame(model_mf_list)\n\u001b[1;32m      3\u001b[0m modlee_mf_df \u001b[39m=\u001b[39m default_transforms(model_mf_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_mf_list' is not defined"
     ]
    }
   ],
   "source": [
    "from modlee.dataframes import ModleeDataFrame, default_transforms\n",
    "model_mf_df = ModleeDataFrame(model_mf_list)\n",
    "modlee_mf_df = default_transforms(model_mf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = MFDF(pd.read_csv('./text_features_cache.csv'))\n",
    "image_df = MFDF(pd.read_csv('./image_features_cache.csv'))\n",
    "concat_df = MFDF(pd.concat([text_df, image_df], ignore_index=True))\n",
    "# text_df.save_labels('./labels_test.txt')\n",
    "print(concat_df)\n",
    "print(concat_df.name)\n",
    "concat_df.save_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_df = MFDF(df_transforms(text_df))\n",
    "text_df.save_tsv('./test_text.tsv')\n",
    "print(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test_model_metafeatures\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "os.getcwd()\n",
    "sys.path.insert(0, '..')\n",
    "# from tests import test_model_metafeatures\n",
    "# import tests\n",
    "# print(dir(tests))\n",
    "# print(tests)\n",
    "import test_model_metafeatures\n",
    "# tests.test\n",
    "# from test_model_metafeatures import *\n",
    "tmm = test_model_metafeatures.TestModelMetafeatures()\n",
    "image_mf = tmm.test_image_model_metafeatures(test_model_metafeatures.IMAGE_MODELS[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(image_mf)\n",
    "# TODO - consider making the metafeatures a subclass of dataframes themselves\n",
    "# image_mf.dataframe\n",
    "image_mf.get_parameter_statistics(image_mf.dataframe['conv_dilations_0'])\n",
    "print(image_mf.dataframe.select_dtypes(include='float'))\n",
    "print(image_mf.dataframe.shape)\n",
    "image_mf.get_propertie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/models/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/transforms.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/functional.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/prototype/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from conftest import IMAGE_MODELS, IMAGE_SEGMENTATION_MODELS\n",
    "\n",
    "\n",
    "models = IMAGE_MODELS + IMAGE_SEGMENTATION_MODELS\n",
    "from modlee import model_metafeatures as mmf\n",
    "model_mfs = []\n",
    "for model in IMAGE_MODELS:\n",
    "    model_mf = mmf.ImageModelMetafeatures(model)\n",
    "    model_mfs.append(model_mf)\n",
    "for model in IMAGE_SEGMENTATION_MODELS:\n",
    "    model_mf = mmf.ImageSegmentationModelMetafeatures(model)\n",
    "    model_mfs.append(model_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_impl',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_make_layer',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_norm_layer',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'avgpool',\n",
       " 'base_width',\n",
       " 'bfloat16',\n",
       " 'bn1',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'conv1',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'dilation',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fc',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'groups',\n",
       " 'half',\n",
       " 'inplanes',\n",
       " 'ipu',\n",
       " 'layer1',\n",
       " 'layer2',\n",
       " 'layer3',\n",
       " 'layer4',\n",
       " 'load_state_dict',\n",
       " 'maxpool',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'relu',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_labels = [\n",
    "    'clf_resnet18_pretrained',\n",
    "    'clf_resnet18',\n",
    "    'clf_resnet50',\n",
    "    'clf_resnet152',\n",
    "    'seg_fcn_resnet50',\n",
    "    'seg_fcn_resnet101',\n",
    "    'seg_lraspp_mobilenet_v3_large',\n",
    "    'seg_deeplabv3_resnet50',\n",
    "    'seg_deeplabv3_resnet101',\n",
    "]\n",
    "models[0].__dir__()\n",
    "# models[0]._get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def __init__(self, torch_model: torch.nn.Module, *args, **kwargs):\n",
      "        #  Should work with any of the available model representations\n",
      "        # Torch model/text, ONNX graph/text\n",
      "        # Store these different representations\n",
      "        self.torch_model = torch_model\n",
      "        self.onnx_graph = converter.torch_model2onnx_graph(\n",
      "            self.torch_model\n",
      "        )\n",
      "        # Must calculate NetworkX before initializing tensors\n",
      "        self.onnx_nx = converter.index_nx(\n",
      "            converter.onnx_graph2onnx_nx(\n",
      "                self.onnx_graph\n",
      "        ))\n",
      "        self.onnx_text = converter.onnx_graph2onnx_text(self.onnx_graph)\n",
      "        self.onnx_graph = converter.init_onnx_tensors(\n",
      "            converter.init_onnx_params(\n",
      "                self.onnx_graph\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        self.dataframe = self.get_graph_dataframe(self.onnx_graph)\n",
      "        self.properties = self.get_properties()\n",
      "        self.embeddings = self.get_embedding()\n",
      "        pass\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embd_0': 0.31196684,\n",
       " 'embd_1': -0.13048755,\n",
       " 'embd_2': -0.23547895,\n",
       " 'embd_3': -0.1046185,\n",
       " 'embd_4': -0.16155484,\n",
       " 'embd_5': -0.0060918448,\n",
       " 'embd_6': 0.110071965,\n",
       " 'embd_7': -0.28069374,\n",
       " 'embd_8': -0.16768284,\n",
       " 'embd_9': -0.03657363,\n",
       " 'embd_10': 0.14379497,\n",
       " 'embd_11': 0.1822052,\n",
       " 'embd_12': -0.0034986995,\n",
       " 'embd_13': 0.213183,\n",
       " 'embd_14': 0.047922615,\n",
       " 'embd_15': -0.06087632,\n",
       " 'embd_16': 0.054494657,\n",
       " 'embd_17': 0.05638334,\n",
       " 'embd_18': -0.17757621,\n",
       " 'embd_19': 0.16681549,\n",
       " 'embd_20': -0.1442158,\n",
       " 'embd_21': -0.21799125,\n",
       " 'embd_22': 0.087584496,\n",
       " 'embd_23': 0.006274946,\n",
       " 'embd_24': 0.0064659547,\n",
       " 'embd_25': -0.109127015,\n",
       " 'embd_26': 0.26742074,\n",
       " 'embd_27': -0.06537563,\n",
       " 'embd_28': -0.087547764,\n",
       " 'embd_29': 0.020294983,\n",
       " 'embd_30': 0.05076538,\n",
       " 'embd_31': 0.15639642,\n",
       " 'embd_32': 0.007632737,\n",
       " 'embd_33': 0.11286494,\n",
       " 'embd_34': -0.040336784,\n",
       " 'embd_35': -0.129337,\n",
       " 'embd_36': 0.09923463,\n",
       " 'embd_37': 0.056437753,\n",
       " 'embd_38': 0.24824236,\n",
       " 'embd_39': 0.07697988,\n",
       " 'embd_40': -0.016854452,\n",
       " 'embd_41': -0.078441374,\n",
       " 'embd_42': -0.07794314,\n",
       " 'embd_43': 0.2921073,\n",
       " 'embd_44': 0.057429373,\n",
       " 'embd_45': -0.20530462,\n",
       " 'embd_46': 0.095595516,\n",
       " 'embd_47': 0.09449865,\n",
       " 'embd_48': 0.042773385,\n",
       " 'embd_49': -0.10920356,\n",
       " 'embd_50': 0.17230642,\n",
       " 'embd_51': -0.079878025,\n",
       " 'embd_52': 0.04115345,\n",
       " 'embd_53': 0.15852305,\n",
       " 'embd_54': 0.102739476,\n",
       " 'embd_55': 0.19602096,\n",
       " 'embd_56': -0.13222323,\n",
       " 'embd_57': 0.12289969,\n",
       " 'embd_58': -0.25437698,\n",
       " 'embd_59': 0.16565986,\n",
       " 'embd_60': 0.08947053,\n",
       " 'embd_61': -0.08470269,\n",
       " 'embd_62': 0.18817247,\n",
       " 'embd_63': -0.07303846,\n",
       " 'embd_64': 0.12379815,\n",
       " 'embd_65': -0.029677223,\n",
       " 'embd_66': -0.18853919,\n",
       " 'embd_67': -0.17787498,\n",
       " 'embd_68': 0.23397551,\n",
       " 'embd_69': -0.031341482,\n",
       " 'embd_70': 0.039137434,\n",
       " 'embd_71': 0.0049201953,\n",
       " 'embd_72': 0.123640604,\n",
       " 'embd_73': 0.027620453,\n",
       " 'embd_74': -0.20567848,\n",
       " 'embd_75': -0.2908738,\n",
       " 'embd_76': 0.060986258,\n",
       " 'embd_77': -0.14730658,\n",
       " 'embd_78': 0.00015947428,\n",
       " 'embd_79': -0.08103157,\n",
       " 'embd_80': 0.19675167,\n",
       " 'embd_81': -0.18058383,\n",
       " 'embd_82': -0.075701095,\n",
       " 'embd_83': 0.10349777,\n",
       " 'embd_84': 0.06614524,\n",
       " 'embd_85': -0.07718885,\n",
       " 'embd_86': 0.2215704,\n",
       " 'embd_87': 0.18897004,\n",
       " 'embd_88': 0.14234693,\n",
       " 'embd_89': -0.16458279,\n",
       " 'embd_90': 0.104080886,\n",
       " 'embd_91': 0.13780653,\n",
       " 'embd_92': -0.048599876,\n",
       " 'embd_93': 0.07441802,\n",
       " 'embd_94': -0.022418572,\n",
       " 'embd_95': 0.11321082,\n",
       " 'embd_96': 0.18035458,\n",
       " 'embd_97': 0.0051105544,\n",
       " 'embd_98': 0.2766973,\n",
       " 'embd_99': -0.13475823,\n",
       " 'embd_100': -0.04072789,\n",
       " 'embd_101': -0.14979534,\n",
       " 'embd_102': -0.17197756,\n",
       " 'embd_103': -0.1883993,\n",
       " 'embd_104': 0.18943773,\n",
       " 'embd_105': -0.16223301,\n",
       " 'embd_106': -0.0064417785,\n",
       " 'embd_107': 0.06405405,\n",
       " 'embd_108': 0.084052615,\n",
       " 'embd_109': -0.018559087,\n",
       " 'embd_110': 0.17839646,\n",
       " 'embd_111': -0.13212873,\n",
       " 'embd_112': 0.20767616,\n",
       " 'embd_113': 0.1524136,\n",
       " 'embd_114': 0.2270414,\n",
       " 'embd_115': 0.059596088,\n",
       " 'embd_116': -0.25180933,\n",
       " 'embd_117': -0.08095049,\n",
       " 'embd_118': 0.16033562,\n",
       " 'embd_119': -0.0779932,\n",
       " 'embd_120': -0.1072412,\n",
       " 'embd_121': -0.07570122,\n",
       " 'embd_122': -0.19792894,\n",
       " 'embd_123': -0.07967359,\n",
       " 'embd_124': 0.06654457,\n",
       " 'embd_125': -0.011317778,\n",
       " 'embd_126': -0.04629853,\n",
       " 'embd_127': -0.016478008}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(model_mf.__init__))\n",
    "model_mf.get_embedding()\n",
    "for model_mf in model_mfs:\n",
    "    model_mf.embedding = model_mf.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mf_df = pd.DataFrame(\n",
    "    # [{**model_mf.properties, **{f\"embd_{i}\":e for i,e in enumerate(model_mf.embedding[0])}} for model_mf in model_mfs]\n",
    "    [{**model_mf.properties, **model_mf.embedding} for model_mf in model_mfs]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import modlee\n",
    "from modlee.dataframes import default_transforms\n",
    "# model_mf_df\n",
    "# model_mf_df.select_dtypes(include=['object']).columns\n",
    "model_df = default_transforms(model_mf_df)\n",
    "# model_mf_df\n",
    "model_df['labels'] = model_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_csv(\"../src/modlee/model_metafeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_impl',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_make_layer',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_norm_layer',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'avgpool',\n",
       " 'base_width',\n",
       " 'bfloat16',\n",
       " 'bn1',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'conv1',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'dilation',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fc',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'groups',\n",
       " 'half',\n",
       " 'inplanes',\n",
       " 'ipu',\n",
       " 'layer1',\n",
       " 'layer2',\n",
       " 'layer3',\n",
       " 'layer4',\n",
       " 'load_state_dict',\n",
       " 'maxpool',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'relu',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].__dir__()\n",
    "with open('model_mf_labels.txt','w') as _file:\n",
    "    model_sizes = list(model_df['size'].apply(lambda x: f\"model_{x}\"))\n",
    "    _file.write('\\n'.join(model_sizes))\n",
    "    # _file.writelines(model_df['size'].apply(lambda x: f\"model_{x}\"))\n",
    "model_df_props = model_df[[col for col in model_df.columns if 'embd' not in col]]\n",
    "\n",
    "model_df.to_csv(\n",
    "'model_embd.tsv',\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    header=False\n",
    ")\n",
    "model_df_props.to_csv(\n",
    "'model_props_embd.tsv',\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    header=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_mf in model_mfs:\n",
    "    print(model_mf['conv_count'])\n",
    "df_model = pd.DataFrame([model_mf for model_mf in model_mfs])\n",
    "print(df_model['model_name'])\n",
    "df_model['dataset_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model\n",
    "count_cols = [col for col in df_model.columns if 'count' in col]\n",
    "print(count_cols)\n",
    "df_model['dataset_name'] = df_model[count_cols].sum(axis=1)\n",
    "df_model['dataset_name'] = df_model['dataset_name'].apply(str)\n",
    "name_cols = ['dataset_name','model_name']\n",
    "# df_model['dataset_name'] = df_model[name_cols].apply(lambda x: ' '.join(x))\n",
    "df_model['dataset_name'] = df_model['model_name'] + df_model['dataset_name']\n",
    "print(df_model[['dataset_name','model_name']])\n",
    "save_labels(df_model, f'./model_labels.txt')\n",
    "norm_model = df_transforms(df_model)\n",
    "norm_model\n",
    "\n",
    "save_tsv(norm_model, f'model_metafeatures.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# There is only one split on the hub\n",
    "dataset = load_dataset(\"OGB/ogbg-molhiv\")\n",
    "\n",
    "dataset = dataset.shuffle(seed=0)\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We want to plot the first train graph\n",
    "graph = dataset[\"train\"][0]\n",
    "\n",
    "edges = graph[\"edge_index\"]\n",
    "num_edges = len(edges[0])\n",
    "num_nodes = graph[\"num_nodes\"]\n",
    "\n",
    "# Conversion to networkx format\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(num_nodes))\n",
    "G.add_edges_from([(edges[0][i], edges[1][i]) for i in range(num_edges)])\n",
    "\n",
    "# Plot\n",
    "nx.draw(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"graph-ml\", model=\"clefourrier/graphormer-base-pcqm4mv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX -> PyG starts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/models/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/transforms.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/functional.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/torchtext/prototype/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from conftest import IMAGE_MODELS, IMAGE_SEGMENTATION_MODELS\n",
    "model = IMAGE_SEGMENTATION_MODELS[2]\n",
    "model = IMAGE_MODELS[0]\n",
    "import modlee\n",
    "converter = modlee.converter.Converter()\n",
    "\n",
    "onnx_graph = converter.torch_model2onnx_graph(model)\n",
    "models = IMAGE_MODELS + IMAGE_SEGMENTATION_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# onnx_graph\n",
    "# dir(onnx_graph)\n",
    "# print(dir(onnx_graph))\n",
    "import torch_geometric\n",
    "import matplotlib.pyplot as plt\n",
    "# ax = plt.axes([0,0,5,10])\n",
    "import networkx as nx \n",
    "import onnx\n",
    "from onnx.tools import net_drawer\n",
    "# print(onnx_graph.node)\n",
    "\n",
    "def filter_node(x):\n",
    "    return 'onnx::' in x \\\n",
    "        or 'Identity' in x \\\n",
    "        or 'fc.' in x\n",
    "        \n",
    "def prune_onnx_nx(onnx_nx):\n",
    "    nodes_to_prune = [k for k in onnx_nx.nodes.keys() if filter_node(k)]\n",
    "    # help(onnx_nx.remove_node)\n",
    "    onnx_nx_layers_only = copy.deepcopy(onnx_nx)\n",
    "    for node in nodes_to_prune:\n",
    "        onnx_nx_layers_only.remove_node(node)\n",
    "    return onnx_nx_layers_only\n",
    "        \n",
    "def onnx_graph2onnx_nx(onnx_graph, prune=True):\n",
    "    onnx_pydot = onnx.tools.net_drawer.GetPydotGraph(\n",
    "        converter.onnx_parameterless2onnx(onnx_graph).graph)\n",
    "    onnx_pydot.set_name(\"onnx_graph\")\n",
    "    onnx_nx = nx.nx_pydot.from_pydot(onnx_pydot)\n",
    "    if prune:\n",
    "        onnx_nx = prune_onnx_nx(onnx_nx)\n",
    "    return onnx_nx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_nxs = []\n",
    "for model in models:\n",
    "    onnx_nxs.append(onnx_graph2onnx_nx(\n",
    "        converter.torch_model2onnx_graph(model)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f2c9f977200>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f2c9fa501a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f2cac262ae0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f2ca68d90a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f2c9fa52f30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f2ca68da750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f2ca5adcc80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f2c9f900860>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f2c9f767f20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Shape/Shape (op#6)\\\\n input0 input_1\\\\n output0 /Shape_output_0': 0, 'input_10': 1, '/Shape_output_00': 2, '/Constant/Constant (op#7)\\\\n output0 /Constant_output_0': 3, '/Constant_output_00': 4, '/Gather/Gather (op#8)\\\\n input0 /Shape_output_0\\\\n input1 /Constant_output_0\\\\n output0 /Gather_output_0': 5, '/Gather_output_00': 6, '/Shape_1/Shape (op#9)\\\\n input0 input_1\\\\n output0 /Shape_1_output_0': 7, '/Shape_1_output_00': 8, '/Constant_1/Constant (op#10)\\\\n output0 /Constant_1_output_0': 9, '/Constant_1_output_00': 10, '/Gather_1/Gather (op#11)\\\\n input0 /Shape_1_output_0\\\\n input1 /Constant_1_output_0\\\\n output0 /Gather_1_output_0': 11, '/Gather_1_output_00': 12, '/backbone/conv1/Conv/Conv (op#12)\\\\n input0 input_1\\\\n input1 onnx': 13, '/backbone/conv1/Conv_output_00': 14, '/backbone/relu/Relu/Relu (op#13)\\\\n input0 /backbone/conv1/Conv_output_0\\\\n output0 /backbone/relu/Relu_output_0': 15, '/backbone/relu/Relu_output_00': 16, '/backbone/maxpool/MaxPool/MaxPool (op#14)\\\\n input0 /backbone/relu/Relu_output_0\\\\n output0 /backbone/maxpool/MaxPool_output_0': 17, '/backbone/maxpool/MaxPool_output_00': 18, '/backbone/layer1/layer1.0/conv1/Conv/Conv (op#15)\\\\n input0 /backbone/maxpool/MaxPool_output_0\\\\n input1 onnx': 19, '/backbone/layer1/layer1.0/conv1/Conv_output_00': 20, '/backbone/layer1/layer1.0/relu/Relu/Relu (op#16)\\\\n input0 /backbone/layer1/layer1.0/conv1/Conv_output_0\\\\n output0 /backbone/layer1/layer1.0/relu/Relu_output_0': 21, '/backbone/layer1/layer1.0/relu/Relu_output_00': 22, '/backbone/layer1/layer1.0/conv2/Conv/Conv (op#17)\\\\n input0 /backbone/layer1/layer1.0/relu/Relu_output_0\\\\n input1 onnx': 23, '/backbone/layer1/layer1.0/conv2/Conv_output_00': 24, '/backbone/layer1/layer1.0/relu_1/Relu/Relu (op#18)\\\\n input0 /backbone/layer1/layer1.0/conv2/Conv_output_0\\\\n output0 /backbone/layer1/layer1.0/relu_1/Relu_output_0': 25, '/backbone/layer1/layer1.0/relu_1/Relu_output_00': 26, '/backbone/layer1/layer1.0/conv3/Conv/Conv (op#19)\\\\n input0 /backbone/layer1/layer1.0/relu_1/Relu_output_0\\\\n input1 onnx': 27, '/backbone/layer1/layer1.0/conv3/Conv_output_00': 28, '/backbone/layer1/layer1.0/downsample/downsample.0/Conv/Conv (op#20)\\\\n input0 /backbone/maxpool/MaxPool_output_0\\\\n input1 onnx': 29, '/backbone/layer1/layer1.0/downsample/downsample.0/Conv_output_00': 30, '/backbone/layer1/layer1.0/Add/Add (op#21)\\\\n input0 /backbone/layer1/layer1.0/conv3/Conv_output_0\\\\n input1 /backbone/layer1/layer1.0/downsample/downsample.0/Conv_output_0\\\\n output0 /backbone/layer1/layer1.0/Add_output_0': 31, '/backbone/layer1/layer1.0/Add_output_00': 32, '/backbone/layer1/layer1.0/relu_2/Relu/Relu (op#22)\\\\n input0 /backbone/layer1/layer1.0/Add_output_0\\\\n output0 /backbone/layer1/layer1.0/relu_2/Relu_output_0': 33, '/backbone/layer1/layer1.0/relu_2/Relu_output_00': 34, '/backbone/layer1/layer1.1/conv1/Conv/Conv (op#23)\\\\n input0 /backbone/layer1/layer1.0/relu_2/Relu_output_0\\\\n input1 onnx': 35, '/backbone/layer1/layer1.1/conv1/Conv_output_00': 36, '/backbone/layer1/layer1.1/relu/Relu/Relu (op#24)\\\\n input0 /backbone/layer1/layer1.1/conv1/Conv_output_0\\\\n output0 /backbone/layer1/layer1.1/relu/Relu_output_0': 37, '/backbone/layer1/layer1.1/relu/Relu_output_00': 38, '/backbone/layer1/layer1.1/conv2/Conv/Conv (op#25)\\\\n input0 /backbone/layer1/layer1.1/relu/Relu_output_0\\\\n input1 onnx': 39, '/backbone/layer1/layer1.1/conv2/Conv_output_00': 40, '/backbone/layer1/layer1.1/relu_1/Relu/Relu (op#26)\\\\n input0 /backbone/layer1/layer1.1/conv2/Conv_output_0\\\\n output0 /backbone/layer1/layer1.1/relu_1/Relu_output_0': 41, '/backbone/layer1/layer1.1/relu_1/Relu_output_00': 42, '/backbone/layer1/layer1.1/conv3/Conv/Conv (op#27)\\\\n input0 /backbone/layer1/layer1.1/relu_1/Relu_output_0\\\\n input1 onnx': 43, '/backbone/layer1/layer1.1/conv3/Conv_output_00': 44, '/backbone/layer1/layer1.1/Add/Add (op#28)\\\\n input0 /backbone/layer1/layer1.1/conv3/Conv_output_0\\\\n input1 /backbone/layer1/layer1.0/relu_2/Relu_output_0\\\\n output0 /backbone/layer1/layer1.1/Add_output_0': 45, '/backbone/layer1/layer1.1/Add_output_00': 46, '/backbone/layer1/layer1.1/relu_2/Relu/Relu (op#29)\\\\n input0 /backbone/layer1/layer1.1/Add_output_0\\\\n output0 /backbone/layer1/layer1.1/relu_2/Relu_output_0': 47, '/backbone/layer1/layer1.1/relu_2/Relu_output_00': 48, '/backbone/layer1/layer1.2/conv1/Conv/Conv (op#30)\\\\n input0 /backbone/layer1/layer1.1/relu_2/Relu_output_0\\\\n input1 onnx': 49, '/backbone/layer1/layer1.2/conv1/Conv_output_00': 50, '/backbone/layer1/layer1.2/relu/Relu/Relu (op#31)\\\\n input0 /backbone/layer1/layer1.2/conv1/Conv_output_0\\\\n output0 /backbone/layer1/layer1.2/relu/Relu_output_0': 51, '/backbone/layer1/layer1.2/relu/Relu_output_00': 52, '/backbone/layer1/layer1.2/conv2/Conv/Conv (op#32)\\\\n input0 /backbone/layer1/layer1.2/relu/Relu_output_0\\\\n input1 onnx': 53, '/backbone/layer1/layer1.2/conv2/Conv_output_00': 54, '/backbone/layer1/layer1.2/relu_1/Relu/Relu (op#33)\\\\n input0 /backbone/layer1/layer1.2/conv2/Conv_output_0\\\\n output0 /backbone/layer1/layer1.2/relu_1/Relu_output_0': 55, '/backbone/layer1/layer1.2/relu_1/Relu_output_00': 56, '/backbone/layer1/layer1.2/conv3/Conv/Conv (op#34)\\\\n input0 /backbone/layer1/layer1.2/relu_1/Relu_output_0\\\\n input1 onnx': 57, '/backbone/layer1/layer1.2/conv3/Conv_output_00': 58, '/backbone/layer1/layer1.2/Add/Add (op#35)\\\\n input0 /backbone/layer1/layer1.2/conv3/Conv_output_0\\\\n input1 /backbone/layer1/layer1.1/relu_2/Relu_output_0\\\\n output0 /backbone/layer1/layer1.2/Add_output_0': 59, '/backbone/layer1/layer1.2/Add_output_00': 60, '/backbone/layer1/layer1.2/relu_2/Relu/Relu (op#36)\\\\n input0 /backbone/layer1/layer1.2/Add_output_0\\\\n output0 /backbone/layer1/layer1.2/relu_2/Relu_output_0': 61, '/backbone/layer1/layer1.2/relu_2/Relu_output_00': 62, '/backbone/layer2/layer2.0/conv1/Conv/Conv (op#37)\\\\n input0 /backbone/layer1/layer1.2/relu_2/Relu_output_0\\\\n input1 onnx': 63, '/backbone/layer2/layer2.0/conv1/Conv_output_00': 64, '/backbone/layer2/layer2.0/relu/Relu/Relu (op#38)\\\\n input0 /backbone/layer2/layer2.0/conv1/Conv_output_0\\\\n output0 /backbone/layer2/layer2.0/relu/Relu_output_0': 65, '/backbone/layer2/layer2.0/relu/Relu_output_00': 66, '/backbone/layer2/layer2.0/conv2/Conv/Conv (op#39)\\\\n input0 /backbone/layer2/layer2.0/relu/Relu_output_0\\\\n input1 onnx': 67, '/backbone/layer2/layer2.0/conv2/Conv_output_00': 68, '/backbone/layer2/layer2.0/relu_1/Relu/Relu (op#40)\\\\n input0 /backbone/layer2/layer2.0/conv2/Conv_output_0\\\\n output0 /backbone/layer2/layer2.0/relu_1/Relu_output_0': 69, '/backbone/layer2/layer2.0/relu_1/Relu_output_00': 70, '/backbone/layer2/layer2.0/conv3/Conv/Conv (op#41)\\\\n input0 /backbone/layer2/layer2.0/relu_1/Relu_output_0\\\\n input1 onnx': 71, '/backbone/layer2/layer2.0/conv3/Conv_output_00': 72, '/backbone/layer2/layer2.0/downsample/downsample.0/Conv/Conv (op#42)\\\\n input0 /backbone/layer1/layer1.2/relu_2/Relu_output_0\\\\n input1 onnx': 73, '/backbone/layer2/layer2.0/downsample/downsample.0/Conv_output_00': 74, '/backbone/layer2/layer2.0/Add/Add (op#43)\\\\n input0 /backbone/layer2/layer2.0/conv3/Conv_output_0\\\\n input1 /backbone/layer2/layer2.0/downsample/downsample.0/Conv_output_0\\\\n output0 /backbone/layer2/layer2.0/Add_output_0': 75, '/backbone/layer2/layer2.0/Add_output_00': 76, '/backbone/layer2/layer2.0/relu_2/Relu/Relu (op#44)\\\\n input0 /backbone/layer2/layer2.0/Add_output_0\\\\n output0 /backbone/layer2/layer2.0/relu_2/Relu_output_0': 77, '/backbone/layer2/layer2.0/relu_2/Relu_output_00': 78, '/backbone/layer2/layer2.1/conv1/Conv/Conv (op#45)\\\\n input0 /backbone/layer2/layer2.0/relu_2/Relu_output_0\\\\n input1 onnx': 79, '/backbone/layer2/layer2.1/conv1/Conv_output_00': 80, '/backbone/layer2/layer2.1/relu/Relu/Relu (op#46)\\\\n input0 /backbone/layer2/layer2.1/conv1/Conv_output_0\\\\n output0 /backbone/layer2/layer2.1/relu/Relu_output_0': 81, '/backbone/layer2/layer2.1/relu/Relu_output_00': 82, '/backbone/layer2/layer2.1/conv2/Conv/Conv (op#47)\\\\n input0 /backbone/layer2/layer2.1/relu/Relu_output_0\\\\n input1 onnx': 83, '/backbone/layer2/layer2.1/conv2/Conv_output_00': 84, '/backbone/layer2/layer2.1/relu_1/Relu/Relu (op#48)\\\\n input0 /backbone/layer2/layer2.1/conv2/Conv_output_0\\\\n output0 /backbone/layer2/layer2.1/relu_1/Relu_output_0': 85, '/backbone/layer2/layer2.1/relu_1/Relu_output_00': 86, '/backbone/layer2/layer2.1/conv3/Conv/Conv (op#49)\\\\n input0 /backbone/layer2/layer2.1/relu_1/Relu_output_0\\\\n input1 onnx': 87, '/backbone/layer2/layer2.1/conv3/Conv_output_00': 88, '/backbone/layer2/layer2.1/Add/Add (op#50)\\\\n input0 /backbone/layer2/layer2.1/conv3/Conv_output_0\\\\n input1 /backbone/layer2/layer2.0/relu_2/Relu_output_0\\\\n output0 /backbone/layer2/layer2.1/Add_output_0': 89, '/backbone/layer2/layer2.1/Add_output_00': 90, '/backbone/layer2/layer2.1/relu_2/Relu/Relu (op#51)\\\\n input0 /backbone/layer2/layer2.1/Add_output_0\\\\n output0 /backbone/layer2/layer2.1/relu_2/Relu_output_0': 91, '/backbone/layer2/layer2.1/relu_2/Relu_output_00': 92, '/backbone/layer2/layer2.2/conv1/Conv/Conv (op#52)\\\\n input0 /backbone/layer2/layer2.1/relu_2/Relu_output_0\\\\n input1 onnx': 93, '/backbone/layer2/layer2.2/conv1/Conv_output_00': 94, '/backbone/layer2/layer2.2/relu/Relu/Relu (op#53)\\\\n input0 /backbone/layer2/layer2.2/conv1/Conv_output_0\\\\n output0 /backbone/layer2/layer2.2/relu/Relu_output_0': 95, '/backbone/layer2/layer2.2/relu/Relu_output_00': 96, '/backbone/layer2/layer2.2/conv2/Conv/Conv (op#54)\\\\n input0 /backbone/layer2/layer2.2/relu/Relu_output_0\\\\n input1 onnx': 97, '/backbone/layer2/layer2.2/conv2/Conv_output_00': 98, '/backbone/layer2/layer2.2/relu_1/Relu/Relu (op#55)\\\\n input0 /backbone/layer2/layer2.2/conv2/Conv_output_0\\\\n output0 /backbone/layer2/layer2.2/relu_1/Relu_output_0': 99, '/backbone/layer2/layer2.2/relu_1/Relu_output_00': 100, '/backbone/layer2/layer2.2/conv3/Conv/Conv (op#56)\\\\n input0 /backbone/layer2/layer2.2/relu_1/Relu_output_0\\\\n input1 onnx': 101, '/backbone/layer2/layer2.2/conv3/Conv_output_00': 102, '/backbone/layer2/layer2.2/Add/Add (op#57)\\\\n input0 /backbone/layer2/layer2.2/conv3/Conv_output_0\\\\n input1 /backbone/layer2/layer2.1/relu_2/Relu_output_0\\\\n output0 /backbone/layer2/layer2.2/Add_output_0': 103, '/backbone/layer2/layer2.2/Add_output_00': 104, '/backbone/layer2/layer2.2/relu_2/Relu/Relu (op#58)\\\\n input0 /backbone/layer2/layer2.2/Add_output_0\\\\n output0 /backbone/layer2/layer2.2/relu_2/Relu_output_0': 105, '/backbone/layer2/layer2.2/relu_2/Relu_output_00': 106, '/backbone/layer2/layer2.3/conv1/Conv/Conv (op#59)\\\\n input0 /backbone/layer2/layer2.2/relu_2/Relu_output_0\\\\n input1 onnx': 107, '/backbone/layer2/layer2.3/conv1/Conv_output_00': 108, '/backbone/layer2/layer2.3/relu/Relu/Relu (op#60)\\\\n input0 /backbone/layer2/layer2.3/conv1/Conv_output_0\\\\n output0 /backbone/layer2/layer2.3/relu/Relu_output_0': 109, '/backbone/layer2/layer2.3/relu/Relu_output_00': 110, '/backbone/layer2/layer2.3/conv2/Conv/Conv (op#61)\\\\n input0 /backbone/layer2/layer2.3/relu/Relu_output_0\\\\n input1 onnx': 111, '/backbone/layer2/layer2.3/conv2/Conv_output_00': 112, '/backbone/layer2/layer2.3/relu_1/Relu/Relu (op#62)\\\\n input0 /backbone/layer2/layer2.3/conv2/Conv_output_0\\\\n output0 /backbone/layer2/layer2.3/relu_1/Relu_output_0': 113, '/backbone/layer2/layer2.3/relu_1/Relu_output_00': 114, '/backbone/layer2/layer2.3/conv3/Conv/Conv (op#63)\\\\n input0 /backbone/layer2/layer2.3/relu_1/Relu_output_0\\\\n input1 onnx': 115, '/backbone/layer2/layer2.3/conv3/Conv_output_00': 116, '/backbone/layer2/layer2.3/Add/Add (op#64)\\\\n input0 /backbone/layer2/layer2.3/conv3/Conv_output_0\\\\n input1 /backbone/layer2/layer2.2/relu_2/Relu_output_0\\\\n output0 /backbone/layer2/layer2.3/Add_output_0': 117, '/backbone/layer2/layer2.3/Add_output_00': 118, '/backbone/layer2/layer2.3/relu_2/Relu/Relu (op#65)\\\\n input0 /backbone/layer2/layer2.3/Add_output_0\\\\n output0 /backbone/layer2/layer2.3/relu_2/Relu_output_0': 119, '/backbone/layer2/layer2.3/relu_2/Relu_output_00': 120, '/backbone/layer3/layer3.0/conv1/Conv/Conv (op#66)\\\\n input0 /backbone/layer2/layer2.3/relu_2/Relu_output_0\\\\n input1 onnx': 121, '/backbone/layer3/layer3.0/conv1/Conv_output_00': 122, '/backbone/layer3/layer3.0/relu/Relu/Relu (op#67)\\\\n input0 /backbone/layer3/layer3.0/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.0/relu/Relu_output_0': 123, '/backbone/layer3/layer3.0/relu/Relu_output_00': 124, '/backbone/layer3/layer3.0/conv2/Conv/Conv (op#68)\\\\n input0 /backbone/layer3/layer3.0/relu/Relu_output_0\\\\n input1 onnx': 125, '/backbone/layer3/layer3.0/conv2/Conv_output_00': 126, '/backbone/layer3/layer3.0/relu_1/Relu/Relu (op#69)\\\\n input0 /backbone/layer3/layer3.0/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.0/relu_1/Relu_output_0': 127, '/backbone/layer3/layer3.0/relu_1/Relu_output_00': 128, '/backbone/layer3/layer3.0/conv3/Conv/Conv (op#70)\\\\n input0 /backbone/layer3/layer3.0/relu_1/Relu_output_0\\\\n input1 onnx': 129, '/backbone/layer3/layer3.0/conv3/Conv_output_00': 130, '/backbone/layer3/layer3.0/downsample/downsample.0/Conv/Conv (op#71)\\\\n input0 /backbone/layer2/layer2.3/relu_2/Relu_output_0\\\\n input1 onnx': 131, '/backbone/layer3/layer3.0/downsample/downsample.0/Conv_output_00': 132, '/backbone/layer3/layer3.0/Add/Add (op#72)\\\\n input0 /backbone/layer3/layer3.0/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.0/downsample/downsample.0/Conv_output_0\\\\n output0 /backbone/layer3/layer3.0/Add_output_0': 133, '/backbone/layer3/layer3.0/Add_output_00': 134, '/backbone/layer3/layer3.0/relu_2/Relu/Relu (op#73)\\\\n input0 /backbone/layer3/layer3.0/Add_output_0\\\\n output0 /backbone/layer3/layer3.0/relu_2/Relu_output_0': 135, '/backbone/layer3/layer3.0/relu_2/Relu_output_00': 136, '/backbone/layer3/layer3.1/conv1/Conv/Conv (op#74)\\\\n input0 /backbone/layer3/layer3.0/relu_2/Relu_output_0\\\\n input1 onnx': 137, '/backbone/layer3/layer3.1/conv1/Conv_output_00': 138, '/backbone/layer3/layer3.1/relu/Relu/Relu (op#75)\\\\n input0 /backbone/layer3/layer3.1/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.1/relu/Relu_output_0': 139, '/backbone/layer3/layer3.1/relu/Relu_output_00': 140, '/backbone/layer3/layer3.1/conv2/Conv/Conv (op#76)\\\\n input0 /backbone/layer3/layer3.1/relu/Relu_output_0\\\\n input1 onnx': 141, '/backbone/layer3/layer3.1/conv2/Conv_output_00': 142, '/backbone/layer3/layer3.1/relu_1/Relu/Relu (op#77)\\\\n input0 /backbone/layer3/layer3.1/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.1/relu_1/Relu_output_0': 143, '/backbone/layer3/layer3.1/relu_1/Relu_output_00': 144, '/backbone/layer3/layer3.1/conv3/Conv/Conv (op#78)\\\\n input0 /backbone/layer3/layer3.1/relu_1/Relu_output_0\\\\n input1 onnx': 145, '/backbone/layer3/layer3.1/conv3/Conv_output_00': 146, '/backbone/layer3/layer3.1/Add/Add (op#79)\\\\n input0 /backbone/layer3/layer3.1/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.0/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.1/Add_output_0': 147, '/backbone/layer3/layer3.1/Add_output_00': 148, '/backbone/layer3/layer3.1/relu_2/Relu/Relu (op#80)\\\\n input0 /backbone/layer3/layer3.1/Add_output_0\\\\n output0 /backbone/layer3/layer3.1/relu_2/Relu_output_0': 149, '/backbone/layer3/layer3.1/relu_2/Relu_output_00': 150, '/backbone/layer3/layer3.2/conv1/Conv/Conv (op#81)\\\\n input0 /backbone/layer3/layer3.1/relu_2/Relu_output_0\\\\n input1 onnx': 151, '/backbone/layer3/layer3.2/conv1/Conv_output_00': 152, '/backbone/layer3/layer3.2/relu/Relu/Relu (op#82)\\\\n input0 /backbone/layer3/layer3.2/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.2/relu/Relu_output_0': 153, '/backbone/layer3/layer3.2/relu/Relu_output_00': 154, '/backbone/layer3/layer3.2/conv2/Conv/Conv (op#83)\\\\n input0 /backbone/layer3/layer3.2/relu/Relu_output_0\\\\n input1 onnx': 155, '/backbone/layer3/layer3.2/conv2/Conv_output_00': 156, '/backbone/layer3/layer3.2/relu_1/Relu/Relu (op#84)\\\\n input0 /backbone/layer3/layer3.2/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.2/relu_1/Relu_output_0': 157, '/backbone/layer3/layer3.2/relu_1/Relu_output_00': 158, '/backbone/layer3/layer3.2/conv3/Conv/Conv (op#85)\\\\n input0 /backbone/layer3/layer3.2/relu_1/Relu_output_0\\\\n input1 onnx': 159, '/backbone/layer3/layer3.2/conv3/Conv_output_00': 160, '/backbone/layer3/layer3.2/Add/Add (op#86)\\\\n input0 /backbone/layer3/layer3.2/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.1/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.2/Add_output_0': 161, '/backbone/layer3/layer3.2/Add_output_00': 162, '/backbone/layer3/layer3.2/relu_2/Relu/Relu (op#87)\\\\n input0 /backbone/layer3/layer3.2/Add_output_0\\\\n output0 /backbone/layer3/layer3.2/relu_2/Relu_output_0': 163, '/backbone/layer3/layer3.2/relu_2/Relu_output_00': 164, '/backbone/layer3/layer3.3/conv1/Conv/Conv (op#88)\\\\n input0 /backbone/layer3/layer3.2/relu_2/Relu_output_0\\\\n input1 onnx': 165, '/backbone/layer3/layer3.3/conv1/Conv_output_00': 166, '/backbone/layer3/layer3.3/relu/Relu/Relu (op#89)\\\\n input0 /backbone/layer3/layer3.3/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.3/relu/Relu_output_0': 167, '/backbone/layer3/layer3.3/relu/Relu_output_00': 168, '/backbone/layer3/layer3.3/conv2/Conv/Conv (op#90)\\\\n input0 /backbone/layer3/layer3.3/relu/Relu_output_0\\\\n input1 onnx': 169, '/backbone/layer3/layer3.3/conv2/Conv_output_00': 170, '/backbone/layer3/layer3.3/relu_1/Relu/Relu (op#91)\\\\n input0 /backbone/layer3/layer3.3/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.3/relu_1/Relu_output_0': 171, '/backbone/layer3/layer3.3/relu_1/Relu_output_00': 172, '/backbone/layer3/layer3.3/conv3/Conv/Conv (op#92)\\\\n input0 /backbone/layer3/layer3.3/relu_1/Relu_output_0\\\\n input1 onnx': 173, '/backbone/layer3/layer3.3/conv3/Conv_output_00': 174, '/backbone/layer3/layer3.3/Add/Add (op#93)\\\\n input0 /backbone/layer3/layer3.3/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.2/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.3/Add_output_0': 175, '/backbone/layer3/layer3.3/Add_output_00': 176, '/backbone/layer3/layer3.3/relu_2/Relu/Relu (op#94)\\\\n input0 /backbone/layer3/layer3.3/Add_output_0\\\\n output0 /backbone/layer3/layer3.3/relu_2/Relu_output_0': 177, '/backbone/layer3/layer3.3/relu_2/Relu_output_00': 178, '/backbone/layer3/layer3.4/conv1/Conv/Conv (op#95)\\\\n input0 /backbone/layer3/layer3.3/relu_2/Relu_output_0\\\\n input1 onnx': 179, '/backbone/layer3/layer3.4/conv1/Conv_output_00': 180, '/backbone/layer3/layer3.4/relu/Relu/Relu (op#96)\\\\n input0 /backbone/layer3/layer3.4/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.4/relu/Relu_output_0': 181, '/backbone/layer3/layer3.4/relu/Relu_output_00': 182, '/backbone/layer3/layer3.4/conv2/Conv/Conv (op#97)\\\\n input0 /backbone/layer3/layer3.4/relu/Relu_output_0\\\\n input1 onnx': 183, '/backbone/layer3/layer3.4/conv2/Conv_output_00': 184, '/backbone/layer3/layer3.4/relu_1/Relu/Relu (op#98)\\\\n input0 /backbone/layer3/layer3.4/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.4/relu_1/Relu_output_0': 185, '/backbone/layer3/layer3.4/relu_1/Relu_output_00': 186, '/backbone/layer3/layer3.4/conv3/Conv/Conv (op#99)\\\\n input0 /backbone/layer3/layer3.4/relu_1/Relu_output_0\\\\n input1 onnx': 187, '/backbone/layer3/layer3.4/conv3/Conv_output_00': 188, '/backbone/layer3/layer3.4/Add/Add (op#100)\\\\n input0 /backbone/layer3/layer3.4/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.3/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.4/Add_output_0': 189, '/backbone/layer3/layer3.4/Add_output_00': 190, '/backbone/layer3/layer3.4/relu_2/Relu/Relu (op#101)\\\\n input0 /backbone/layer3/layer3.4/Add_output_0\\\\n output0 /backbone/layer3/layer3.4/relu_2/Relu_output_0': 191, '/backbone/layer3/layer3.4/relu_2/Relu_output_00': 192, '/backbone/layer3/layer3.5/conv1/Conv/Conv (op#102)\\\\n input0 /backbone/layer3/layer3.4/relu_2/Relu_output_0\\\\n input1 onnx': 193, '/backbone/layer3/layer3.5/conv1/Conv_output_00': 194, '/backbone/layer3/layer3.5/relu/Relu/Relu (op#103)\\\\n input0 /backbone/layer3/layer3.5/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.5/relu/Relu_output_0': 195, '/backbone/layer3/layer3.5/relu/Relu_output_00': 196, '/backbone/layer3/layer3.5/conv2/Conv/Conv (op#104)\\\\n input0 /backbone/layer3/layer3.5/relu/Relu_output_0\\\\n input1 onnx': 197, '/backbone/layer3/layer3.5/conv2/Conv_output_00': 198, '/backbone/layer3/layer3.5/relu_1/Relu/Relu (op#105)\\\\n input0 /backbone/layer3/layer3.5/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.5/relu_1/Relu_output_0': 199, '/backbone/layer3/layer3.5/relu_1/Relu_output_00': 200, '/backbone/layer3/layer3.5/conv3/Conv/Conv (op#106)\\\\n input0 /backbone/layer3/layer3.5/relu_1/Relu_output_0\\\\n input1 onnx': 201, '/backbone/layer3/layer3.5/conv3/Conv_output_00': 202, '/backbone/layer3/layer3.5/Add/Add (op#107)\\\\n input0 /backbone/layer3/layer3.5/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.4/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.5/Add_output_0': 203, '/backbone/layer3/layer3.5/Add_output_00': 204, '/backbone/layer3/layer3.5/relu_2/Relu/Relu (op#108)\\\\n input0 /backbone/layer3/layer3.5/Add_output_0\\\\n output0 /backbone/layer3/layer3.5/relu_2/Relu_output_0': 205, '/backbone/layer3/layer3.5/relu_2/Relu_output_00': 206, '/backbone/layer3/layer3.6/conv1/Conv/Conv (op#109)\\\\n input0 /backbone/layer3/layer3.5/relu_2/Relu_output_0\\\\n input1 onnx': 207, '/backbone/layer3/layer3.6/conv1/Conv_output_00': 208, '/backbone/layer3/layer3.6/relu/Relu/Relu (op#110)\\\\n input0 /backbone/layer3/layer3.6/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.6/relu/Relu_output_0': 209, '/backbone/layer3/layer3.6/relu/Relu_output_00': 210, '/backbone/layer3/layer3.6/conv2/Conv/Conv (op#111)\\\\n input0 /backbone/layer3/layer3.6/relu/Relu_output_0\\\\n input1 onnx': 211, '/backbone/layer3/layer3.6/conv2/Conv_output_00': 212, '/backbone/layer3/layer3.6/relu_1/Relu/Relu (op#112)\\\\n input0 /backbone/layer3/layer3.6/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.6/relu_1/Relu_output_0': 213, '/backbone/layer3/layer3.6/relu_1/Relu_output_00': 214, '/backbone/layer3/layer3.6/conv3/Conv/Conv (op#113)\\\\n input0 /backbone/layer3/layer3.6/relu_1/Relu_output_0\\\\n input1 onnx': 215, '/backbone/layer3/layer3.6/conv3/Conv_output_00': 216, '/backbone/layer3/layer3.6/Add/Add (op#114)\\\\n input0 /backbone/layer3/layer3.6/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.5/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.6/Add_output_0': 217, '/backbone/layer3/layer3.6/Add_output_00': 218, '/backbone/layer3/layer3.6/relu_2/Relu/Relu (op#115)\\\\n input0 /backbone/layer3/layer3.6/Add_output_0\\\\n output0 /backbone/layer3/layer3.6/relu_2/Relu_output_0': 219, '/backbone/layer3/layer3.6/relu_2/Relu_output_00': 220, '/backbone/layer3/layer3.7/conv1/Conv/Conv (op#116)\\\\n input0 /backbone/layer3/layer3.6/relu_2/Relu_output_0\\\\n input1 onnx': 221, '/backbone/layer3/layer3.7/conv1/Conv_output_00': 222, '/backbone/layer3/layer3.7/relu/Relu/Relu (op#117)\\\\n input0 /backbone/layer3/layer3.7/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.7/relu/Relu_output_0': 223, '/backbone/layer3/layer3.7/relu/Relu_output_00': 224, '/backbone/layer3/layer3.7/conv2/Conv/Conv (op#118)\\\\n input0 /backbone/layer3/layer3.7/relu/Relu_output_0\\\\n input1 onnx': 225, '/backbone/layer3/layer3.7/conv2/Conv_output_00': 226, '/backbone/layer3/layer3.7/relu_1/Relu/Relu (op#119)\\\\n input0 /backbone/layer3/layer3.7/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.7/relu_1/Relu_output_0': 227, '/backbone/layer3/layer3.7/relu_1/Relu_output_00': 228, '/backbone/layer3/layer3.7/conv3/Conv/Conv (op#120)\\\\n input0 /backbone/layer3/layer3.7/relu_1/Relu_output_0\\\\n input1 onnx': 229, '/backbone/layer3/layer3.7/conv3/Conv_output_00': 230, '/backbone/layer3/layer3.7/Add/Add (op#121)\\\\n input0 /backbone/layer3/layer3.7/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.6/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.7/Add_output_0': 231, '/backbone/layer3/layer3.7/Add_output_00': 232, '/backbone/layer3/layer3.7/relu_2/Relu/Relu (op#122)\\\\n input0 /backbone/layer3/layer3.7/Add_output_0\\\\n output0 /backbone/layer3/layer3.7/relu_2/Relu_output_0': 233, '/backbone/layer3/layer3.7/relu_2/Relu_output_00': 234, '/backbone/layer3/layer3.8/conv1/Conv/Conv (op#123)\\\\n input0 /backbone/layer3/layer3.7/relu_2/Relu_output_0\\\\n input1 onnx': 235, '/backbone/layer3/layer3.8/conv1/Conv_output_00': 236, '/backbone/layer3/layer3.8/relu/Relu/Relu (op#124)\\\\n input0 /backbone/layer3/layer3.8/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.8/relu/Relu_output_0': 237, '/backbone/layer3/layer3.8/relu/Relu_output_00': 238, '/backbone/layer3/layer3.8/conv2/Conv/Conv (op#125)\\\\n input0 /backbone/layer3/layer3.8/relu/Relu_output_0\\\\n input1 onnx': 239, '/backbone/layer3/layer3.8/conv2/Conv_output_00': 240, '/backbone/layer3/layer3.8/relu_1/Relu/Relu (op#126)\\\\n input0 /backbone/layer3/layer3.8/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.8/relu_1/Relu_output_0': 241, '/backbone/layer3/layer3.8/relu_1/Relu_output_00': 242, '/backbone/layer3/layer3.8/conv3/Conv/Conv (op#127)\\\\n input0 /backbone/layer3/layer3.8/relu_1/Relu_output_0\\\\n input1 onnx': 243, '/backbone/layer3/layer3.8/conv3/Conv_output_00': 244, '/backbone/layer3/layer3.8/Add/Add (op#128)\\\\n input0 /backbone/layer3/layer3.8/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.7/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.8/Add_output_0': 245, '/backbone/layer3/layer3.8/Add_output_00': 246, '/backbone/layer3/layer3.8/relu_2/Relu/Relu (op#129)\\\\n input0 /backbone/layer3/layer3.8/Add_output_0\\\\n output0 /backbone/layer3/layer3.8/relu_2/Relu_output_0': 247, '/backbone/layer3/layer3.8/relu_2/Relu_output_00': 248, '/backbone/layer3/layer3.9/conv1/Conv/Conv (op#130)\\\\n input0 /backbone/layer3/layer3.8/relu_2/Relu_output_0\\\\n input1 onnx': 249, '/backbone/layer3/layer3.9/conv1/Conv_output_00': 250, '/backbone/layer3/layer3.9/relu/Relu/Relu (op#131)\\\\n input0 /backbone/layer3/layer3.9/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.9/relu/Relu_output_0': 251, '/backbone/layer3/layer3.9/relu/Relu_output_00': 252, '/backbone/layer3/layer3.9/conv2/Conv/Conv (op#132)\\\\n input0 /backbone/layer3/layer3.9/relu/Relu_output_0\\\\n input1 onnx': 253, '/backbone/layer3/layer3.9/conv2/Conv_output_00': 254, '/backbone/layer3/layer3.9/relu_1/Relu/Relu (op#133)\\\\n input0 /backbone/layer3/layer3.9/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.9/relu_1/Relu_output_0': 255, '/backbone/layer3/layer3.9/relu_1/Relu_output_00': 256, '/backbone/layer3/layer3.9/conv3/Conv/Conv (op#134)\\\\n input0 /backbone/layer3/layer3.9/relu_1/Relu_output_0\\\\n input1 onnx': 257, '/backbone/layer3/layer3.9/conv3/Conv_output_00': 258, '/backbone/layer3/layer3.9/Add/Add (op#135)\\\\n input0 /backbone/layer3/layer3.9/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.8/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.9/Add_output_0': 259, '/backbone/layer3/layer3.9/Add_output_00': 260, '/backbone/layer3/layer3.9/relu_2/Relu/Relu (op#136)\\\\n input0 /backbone/layer3/layer3.9/Add_output_0\\\\n output0 /backbone/layer3/layer3.9/relu_2/Relu_output_0': 261, '/backbone/layer3/layer3.9/relu_2/Relu_output_00': 262, '/backbone/layer3/layer3.10/conv1/Conv/Conv (op#137)\\\\n input0 /backbone/layer3/layer3.9/relu_2/Relu_output_0\\\\n input1 onnx': 263, '/backbone/layer3/layer3.10/conv1/Conv_output_00': 264, '/backbone/layer3/layer3.10/relu/Relu/Relu (op#138)\\\\n input0 /backbone/layer3/layer3.10/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.10/relu/Relu_output_0': 265, '/backbone/layer3/layer3.10/relu/Relu_output_00': 266, '/backbone/layer3/layer3.10/conv2/Conv/Conv (op#139)\\\\n input0 /backbone/layer3/layer3.10/relu/Relu_output_0\\\\n input1 onnx': 267, '/backbone/layer3/layer3.10/conv2/Conv_output_00': 268, '/backbone/layer3/layer3.10/relu_1/Relu/Relu (op#140)\\\\n input0 /backbone/layer3/layer3.10/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.10/relu_1/Relu_output_0': 269, '/backbone/layer3/layer3.10/relu_1/Relu_output_00': 270, '/backbone/layer3/layer3.10/conv3/Conv/Conv (op#141)\\\\n input0 /backbone/layer3/layer3.10/relu_1/Relu_output_0\\\\n input1 onnx': 271, '/backbone/layer3/layer3.10/conv3/Conv_output_00': 272, '/backbone/layer3/layer3.10/Add/Add (op#142)\\\\n input0 /backbone/layer3/layer3.10/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.9/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.10/Add_output_0': 273, '/backbone/layer3/layer3.10/Add_output_00': 274, '/backbone/layer3/layer3.10/relu_2/Relu/Relu (op#143)\\\\n input0 /backbone/layer3/layer3.10/Add_output_0\\\\n output0 /backbone/layer3/layer3.10/relu_2/Relu_output_0': 275, '/backbone/layer3/layer3.10/relu_2/Relu_output_00': 276, '/backbone/layer3/layer3.11/conv1/Conv/Conv (op#144)\\\\n input0 /backbone/layer3/layer3.10/relu_2/Relu_output_0\\\\n input1 onnx': 277, '/backbone/layer3/layer3.11/conv1/Conv_output_00': 278, '/backbone/layer3/layer3.11/relu/Relu/Relu (op#145)\\\\n input0 /backbone/layer3/layer3.11/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.11/relu/Relu_output_0': 279, '/backbone/layer3/layer3.11/relu/Relu_output_00': 280, '/backbone/layer3/layer3.11/conv2/Conv/Conv (op#146)\\\\n input0 /backbone/layer3/layer3.11/relu/Relu_output_0\\\\n input1 onnx': 281, '/backbone/layer3/layer3.11/conv2/Conv_output_00': 282, '/backbone/layer3/layer3.11/relu_1/Relu/Relu (op#147)\\\\n input0 /backbone/layer3/layer3.11/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.11/relu_1/Relu_output_0': 283, '/backbone/layer3/layer3.11/relu_1/Relu_output_00': 284, '/backbone/layer3/layer3.11/conv3/Conv/Conv (op#148)\\\\n input0 /backbone/layer3/layer3.11/relu_1/Relu_output_0\\\\n input1 onnx': 285, '/backbone/layer3/layer3.11/conv3/Conv_output_00': 286, '/backbone/layer3/layer3.11/Add/Add (op#149)\\\\n input0 /backbone/layer3/layer3.11/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.10/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.11/Add_output_0': 287, '/backbone/layer3/layer3.11/Add_output_00': 288, '/backbone/layer3/layer3.11/relu_2/Relu/Relu (op#150)\\\\n input0 /backbone/layer3/layer3.11/Add_output_0\\\\n output0 /backbone/layer3/layer3.11/relu_2/Relu_output_0': 289, '/backbone/layer3/layer3.11/relu_2/Relu_output_00': 290, '/backbone/layer3/layer3.12/conv1/Conv/Conv (op#151)\\\\n input0 /backbone/layer3/layer3.11/relu_2/Relu_output_0\\\\n input1 onnx': 291, '/backbone/layer3/layer3.12/conv1/Conv_output_00': 292, '/backbone/layer3/layer3.12/relu/Relu/Relu (op#152)\\\\n input0 /backbone/layer3/layer3.12/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.12/relu/Relu_output_0': 293, '/backbone/layer3/layer3.12/relu/Relu_output_00': 294, '/backbone/layer3/layer3.12/conv2/Conv/Conv (op#153)\\\\n input0 /backbone/layer3/layer3.12/relu/Relu_output_0\\\\n input1 onnx': 295, '/backbone/layer3/layer3.12/conv2/Conv_output_00': 296, '/backbone/layer3/layer3.12/relu_1/Relu/Relu (op#154)\\\\n input0 /backbone/layer3/layer3.12/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.12/relu_1/Relu_output_0': 297, '/backbone/layer3/layer3.12/relu_1/Relu_output_00': 298, '/backbone/layer3/layer3.12/conv3/Conv/Conv (op#155)\\\\n input0 /backbone/layer3/layer3.12/relu_1/Relu_output_0\\\\n input1 onnx': 299, '/backbone/layer3/layer3.12/conv3/Conv_output_00': 300, '/backbone/layer3/layer3.12/Add/Add (op#156)\\\\n input0 /backbone/layer3/layer3.12/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.11/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.12/Add_output_0': 301, '/backbone/layer3/layer3.12/Add_output_00': 302, '/backbone/layer3/layer3.12/relu_2/Relu/Relu (op#157)\\\\n input0 /backbone/layer3/layer3.12/Add_output_0\\\\n output0 /backbone/layer3/layer3.12/relu_2/Relu_output_0': 303, '/backbone/layer3/layer3.12/relu_2/Relu_output_00': 304, '/backbone/layer3/layer3.13/conv1/Conv/Conv (op#158)\\\\n input0 /backbone/layer3/layer3.12/relu_2/Relu_output_0\\\\n input1 onnx': 305, '/backbone/layer3/layer3.13/conv1/Conv_output_00': 306, '/backbone/layer3/layer3.13/relu/Relu/Relu (op#159)\\\\n input0 /backbone/layer3/layer3.13/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.13/relu/Relu_output_0': 307, '/backbone/layer3/layer3.13/relu/Relu_output_00': 308, '/backbone/layer3/layer3.13/conv2/Conv/Conv (op#160)\\\\n input0 /backbone/layer3/layer3.13/relu/Relu_output_0\\\\n input1 onnx': 309, '/backbone/layer3/layer3.13/conv2/Conv_output_00': 310, '/backbone/layer3/layer3.13/relu_1/Relu/Relu (op#161)\\\\n input0 /backbone/layer3/layer3.13/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.13/relu_1/Relu_output_0': 311, '/backbone/layer3/layer3.13/relu_1/Relu_output_00': 312, '/backbone/layer3/layer3.13/conv3/Conv/Conv (op#162)\\\\n input0 /backbone/layer3/layer3.13/relu_1/Relu_output_0\\\\n input1 onnx': 313, '/backbone/layer3/layer3.13/conv3/Conv_output_00': 314, '/backbone/layer3/layer3.13/Add/Add (op#163)\\\\n input0 /backbone/layer3/layer3.13/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.12/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.13/Add_output_0': 315, '/backbone/layer3/layer3.13/Add_output_00': 316, '/backbone/layer3/layer3.13/relu_2/Relu/Relu (op#164)\\\\n input0 /backbone/layer3/layer3.13/Add_output_0\\\\n output0 /backbone/layer3/layer3.13/relu_2/Relu_output_0': 317, '/backbone/layer3/layer3.13/relu_2/Relu_output_00': 318, '/backbone/layer3/layer3.14/conv1/Conv/Conv (op#165)\\\\n input0 /backbone/layer3/layer3.13/relu_2/Relu_output_0\\\\n input1 onnx': 319, '/backbone/layer3/layer3.14/conv1/Conv_output_00': 320, '/backbone/layer3/layer3.14/relu/Relu/Relu (op#166)\\\\n input0 /backbone/layer3/layer3.14/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.14/relu/Relu_output_0': 321, '/backbone/layer3/layer3.14/relu/Relu_output_00': 322, '/backbone/layer3/layer3.14/conv2/Conv/Conv (op#167)\\\\n input0 /backbone/layer3/layer3.14/relu/Relu_output_0\\\\n input1 onnx': 323, '/backbone/layer3/layer3.14/conv2/Conv_output_00': 324, '/backbone/layer3/layer3.14/relu_1/Relu/Relu (op#168)\\\\n input0 /backbone/layer3/layer3.14/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.14/relu_1/Relu_output_0': 325, '/backbone/layer3/layer3.14/relu_1/Relu_output_00': 326, '/backbone/layer3/layer3.14/conv3/Conv/Conv (op#169)\\\\n input0 /backbone/layer3/layer3.14/relu_1/Relu_output_0\\\\n input1 onnx': 327, '/backbone/layer3/layer3.14/conv3/Conv_output_00': 328, '/backbone/layer3/layer3.14/Add/Add (op#170)\\\\n input0 /backbone/layer3/layer3.14/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.13/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.14/Add_output_0': 329, '/backbone/layer3/layer3.14/Add_output_00': 330, '/backbone/layer3/layer3.14/relu_2/Relu/Relu (op#171)\\\\n input0 /backbone/layer3/layer3.14/Add_output_0\\\\n output0 /backbone/layer3/layer3.14/relu_2/Relu_output_0': 331, '/backbone/layer3/layer3.14/relu_2/Relu_output_00': 332, '/backbone/layer3/layer3.15/conv1/Conv/Conv (op#172)\\\\n input0 /backbone/layer3/layer3.14/relu_2/Relu_output_0\\\\n input1 onnx': 333, '/backbone/layer3/layer3.15/conv1/Conv_output_00': 334, '/backbone/layer3/layer3.15/relu/Relu/Relu (op#173)\\\\n input0 /backbone/layer3/layer3.15/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.15/relu/Relu_output_0': 335, '/backbone/layer3/layer3.15/relu/Relu_output_00': 336, '/backbone/layer3/layer3.15/conv2/Conv/Conv (op#174)\\\\n input0 /backbone/layer3/layer3.15/relu/Relu_output_0\\\\n input1 onnx': 337, '/backbone/layer3/layer3.15/conv2/Conv_output_00': 338, '/backbone/layer3/layer3.15/relu_1/Relu/Relu (op#175)\\\\n input0 /backbone/layer3/layer3.15/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.15/relu_1/Relu_output_0': 339, '/backbone/layer3/layer3.15/relu_1/Relu_output_00': 340, '/backbone/layer3/layer3.15/conv3/Conv/Conv (op#176)\\\\n input0 /backbone/layer3/layer3.15/relu_1/Relu_output_0\\\\n input1 onnx': 341, '/backbone/layer3/layer3.15/conv3/Conv_output_00': 342, '/backbone/layer3/layer3.15/Add/Add (op#177)\\\\n input0 /backbone/layer3/layer3.15/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.14/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.15/Add_output_0': 343, '/backbone/layer3/layer3.15/Add_output_00': 344, '/backbone/layer3/layer3.15/relu_2/Relu/Relu (op#178)\\\\n input0 /backbone/layer3/layer3.15/Add_output_0\\\\n output0 /backbone/layer3/layer3.15/relu_2/Relu_output_0': 345, '/backbone/layer3/layer3.15/relu_2/Relu_output_00': 346, '/backbone/layer3/layer3.16/conv1/Conv/Conv (op#179)\\\\n input0 /backbone/layer3/layer3.15/relu_2/Relu_output_0\\\\n input1 onnx': 347, '/backbone/layer3/layer3.16/conv1/Conv_output_00': 348, '/backbone/layer3/layer3.16/relu/Relu/Relu (op#180)\\\\n input0 /backbone/layer3/layer3.16/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.16/relu/Relu_output_0': 349, '/backbone/layer3/layer3.16/relu/Relu_output_00': 350, '/backbone/layer3/layer3.16/conv2/Conv/Conv (op#181)\\\\n input0 /backbone/layer3/layer3.16/relu/Relu_output_0\\\\n input1 onnx': 351, '/backbone/layer3/layer3.16/conv2/Conv_output_00': 352, '/backbone/layer3/layer3.16/relu_1/Relu/Relu (op#182)\\\\n input0 /backbone/layer3/layer3.16/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.16/relu_1/Relu_output_0': 353, '/backbone/layer3/layer3.16/relu_1/Relu_output_00': 354, '/backbone/layer3/layer3.16/conv3/Conv/Conv (op#183)\\\\n input0 /backbone/layer3/layer3.16/relu_1/Relu_output_0\\\\n input1 onnx': 355, '/backbone/layer3/layer3.16/conv3/Conv_output_00': 356, '/backbone/layer3/layer3.16/Add/Add (op#184)\\\\n input0 /backbone/layer3/layer3.16/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.15/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.16/Add_output_0': 357, '/backbone/layer3/layer3.16/Add_output_00': 358, '/backbone/layer3/layer3.16/relu_2/Relu/Relu (op#185)\\\\n input0 /backbone/layer3/layer3.16/Add_output_0\\\\n output0 /backbone/layer3/layer3.16/relu_2/Relu_output_0': 359, '/backbone/layer3/layer3.16/relu_2/Relu_output_00': 360, '/backbone/layer3/layer3.17/conv1/Conv/Conv (op#186)\\\\n input0 /backbone/layer3/layer3.16/relu_2/Relu_output_0\\\\n input1 onnx': 361, '/backbone/layer3/layer3.17/conv1/Conv_output_00': 362, '/backbone/layer3/layer3.17/relu/Relu/Relu (op#187)\\\\n input0 /backbone/layer3/layer3.17/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.17/relu/Relu_output_0': 363, '/backbone/layer3/layer3.17/relu/Relu_output_00': 364, '/backbone/layer3/layer3.17/conv2/Conv/Conv (op#188)\\\\n input0 /backbone/layer3/layer3.17/relu/Relu_output_0\\\\n input1 onnx': 365, '/backbone/layer3/layer3.17/conv2/Conv_output_00': 366, '/backbone/layer3/layer3.17/relu_1/Relu/Relu (op#189)\\\\n input0 /backbone/layer3/layer3.17/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.17/relu_1/Relu_output_0': 367, '/backbone/layer3/layer3.17/relu_1/Relu_output_00': 368, '/backbone/layer3/layer3.17/conv3/Conv/Conv (op#190)\\\\n input0 /backbone/layer3/layer3.17/relu_1/Relu_output_0\\\\n input1 onnx': 369, '/backbone/layer3/layer3.17/conv3/Conv_output_00': 370, '/backbone/layer3/layer3.17/Add/Add (op#191)\\\\n input0 /backbone/layer3/layer3.17/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.16/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.17/Add_output_0': 371, '/backbone/layer3/layer3.17/Add_output_00': 372, '/backbone/layer3/layer3.17/relu_2/Relu/Relu (op#192)\\\\n input0 /backbone/layer3/layer3.17/Add_output_0\\\\n output0 /backbone/layer3/layer3.17/relu_2/Relu_output_0': 373, '/backbone/layer3/layer3.17/relu_2/Relu_output_00': 374, '/backbone/layer3/layer3.18/conv1/Conv/Conv (op#193)\\\\n input0 /backbone/layer3/layer3.17/relu_2/Relu_output_0\\\\n input1 onnx': 375, '/backbone/layer3/layer3.18/conv1/Conv_output_00': 376, '/backbone/layer3/layer3.18/relu/Relu/Relu (op#194)\\\\n input0 /backbone/layer3/layer3.18/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.18/relu/Relu_output_0': 377, '/backbone/layer3/layer3.18/relu/Relu_output_00': 378, '/backbone/layer3/layer3.18/conv2/Conv/Conv (op#195)\\\\n input0 /backbone/layer3/layer3.18/relu/Relu_output_0\\\\n input1 onnx': 379, '/backbone/layer3/layer3.18/conv2/Conv_output_00': 380, '/backbone/layer3/layer3.18/relu_1/Relu/Relu (op#196)\\\\n input0 /backbone/layer3/layer3.18/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.18/relu_1/Relu_output_0': 381, '/backbone/layer3/layer3.18/relu_1/Relu_output_00': 382, '/backbone/layer3/layer3.18/conv3/Conv/Conv (op#197)\\\\n input0 /backbone/layer3/layer3.18/relu_1/Relu_output_0\\\\n input1 onnx': 383, '/backbone/layer3/layer3.18/conv3/Conv_output_00': 384, '/backbone/layer3/layer3.18/Add/Add (op#198)\\\\n input0 /backbone/layer3/layer3.18/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.17/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.18/Add_output_0': 385, '/backbone/layer3/layer3.18/Add_output_00': 386, '/backbone/layer3/layer3.18/relu_2/Relu/Relu (op#199)\\\\n input0 /backbone/layer3/layer3.18/Add_output_0\\\\n output0 /backbone/layer3/layer3.18/relu_2/Relu_output_0': 387, '/backbone/layer3/layer3.18/relu_2/Relu_output_00': 388, '/backbone/layer3/layer3.19/conv1/Conv/Conv (op#200)\\\\n input0 /backbone/layer3/layer3.18/relu_2/Relu_output_0\\\\n input1 onnx': 389, '/backbone/layer3/layer3.19/conv1/Conv_output_00': 390, '/backbone/layer3/layer3.19/relu/Relu/Relu (op#201)\\\\n input0 /backbone/layer3/layer3.19/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.19/relu/Relu_output_0': 391, '/backbone/layer3/layer3.19/relu/Relu_output_00': 392, '/backbone/layer3/layer3.19/conv2/Conv/Conv (op#202)\\\\n input0 /backbone/layer3/layer3.19/relu/Relu_output_0\\\\n input1 onnx': 393, '/backbone/layer3/layer3.19/conv2/Conv_output_00': 394, '/backbone/layer3/layer3.19/relu_1/Relu/Relu (op#203)\\\\n input0 /backbone/layer3/layer3.19/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.19/relu_1/Relu_output_0': 395, '/backbone/layer3/layer3.19/relu_1/Relu_output_00': 396, '/backbone/layer3/layer3.19/conv3/Conv/Conv (op#204)\\\\n input0 /backbone/layer3/layer3.19/relu_1/Relu_output_0\\\\n input1 onnx': 397, '/backbone/layer3/layer3.19/conv3/Conv_output_00': 398, '/backbone/layer3/layer3.19/Add/Add (op#205)\\\\n input0 /backbone/layer3/layer3.19/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.18/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.19/Add_output_0': 399, '/backbone/layer3/layer3.19/Add_output_00': 400, '/backbone/layer3/layer3.19/relu_2/Relu/Relu (op#206)\\\\n input0 /backbone/layer3/layer3.19/Add_output_0\\\\n output0 /backbone/layer3/layer3.19/relu_2/Relu_output_0': 401, '/backbone/layer3/layer3.19/relu_2/Relu_output_00': 402, '/backbone/layer3/layer3.20/conv1/Conv/Conv (op#207)\\\\n input0 /backbone/layer3/layer3.19/relu_2/Relu_output_0\\\\n input1 onnx': 403, '/backbone/layer3/layer3.20/conv1/Conv_output_00': 404, '/backbone/layer3/layer3.20/relu/Relu/Relu (op#208)\\\\n input0 /backbone/layer3/layer3.20/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.20/relu/Relu_output_0': 405, '/backbone/layer3/layer3.20/relu/Relu_output_00': 406, '/backbone/layer3/layer3.20/conv2/Conv/Conv (op#209)\\\\n input0 /backbone/layer3/layer3.20/relu/Relu_output_0\\\\n input1 onnx': 407, '/backbone/layer3/layer3.20/conv2/Conv_output_00': 408, '/backbone/layer3/layer3.20/relu_1/Relu/Relu (op#210)\\\\n input0 /backbone/layer3/layer3.20/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.20/relu_1/Relu_output_0': 409, '/backbone/layer3/layer3.20/relu_1/Relu_output_00': 410, '/backbone/layer3/layer3.20/conv3/Conv/Conv (op#211)\\\\n input0 /backbone/layer3/layer3.20/relu_1/Relu_output_0\\\\n input1 onnx': 411, '/backbone/layer3/layer3.20/conv3/Conv_output_00': 412, '/backbone/layer3/layer3.20/Add/Add (op#212)\\\\n input0 /backbone/layer3/layer3.20/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.19/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.20/Add_output_0': 413, '/backbone/layer3/layer3.20/Add_output_00': 414, '/backbone/layer3/layer3.20/relu_2/Relu/Relu (op#213)\\\\n input0 /backbone/layer3/layer3.20/Add_output_0\\\\n output0 /backbone/layer3/layer3.20/relu_2/Relu_output_0': 415, '/backbone/layer3/layer3.20/relu_2/Relu_output_00': 416, '/backbone/layer3/layer3.21/conv1/Conv/Conv (op#214)\\\\n input0 /backbone/layer3/layer3.20/relu_2/Relu_output_0\\\\n input1 onnx': 417, '/backbone/layer3/layer3.21/conv1/Conv_output_00': 418, '/backbone/layer3/layer3.21/relu/Relu/Relu (op#215)\\\\n input0 /backbone/layer3/layer3.21/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.21/relu/Relu_output_0': 419, '/backbone/layer3/layer3.21/relu/Relu_output_00': 420, '/backbone/layer3/layer3.21/conv2/Conv/Conv (op#216)\\\\n input0 /backbone/layer3/layer3.21/relu/Relu_output_0\\\\n input1 onnx': 421, '/backbone/layer3/layer3.21/conv2/Conv_output_00': 422, '/backbone/layer3/layer3.21/relu_1/Relu/Relu (op#217)\\\\n input0 /backbone/layer3/layer3.21/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.21/relu_1/Relu_output_0': 423, '/backbone/layer3/layer3.21/relu_1/Relu_output_00': 424, '/backbone/layer3/layer3.21/conv3/Conv/Conv (op#218)\\\\n input0 /backbone/layer3/layer3.21/relu_1/Relu_output_0\\\\n input1 onnx': 425, '/backbone/layer3/layer3.21/conv3/Conv_output_00': 426, '/backbone/layer3/layer3.21/Add/Add (op#219)\\\\n input0 /backbone/layer3/layer3.21/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.20/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.21/Add_output_0': 427, '/backbone/layer3/layer3.21/Add_output_00': 428, '/backbone/layer3/layer3.21/relu_2/Relu/Relu (op#220)\\\\n input0 /backbone/layer3/layer3.21/Add_output_0\\\\n output0 /backbone/layer3/layer3.21/relu_2/Relu_output_0': 429, '/backbone/layer3/layer3.21/relu_2/Relu_output_00': 430, '/backbone/layer3/layer3.22/conv1/Conv/Conv (op#221)\\\\n input0 /backbone/layer3/layer3.21/relu_2/Relu_output_0\\\\n input1 onnx': 431, '/backbone/layer3/layer3.22/conv1/Conv_output_00': 432, '/backbone/layer3/layer3.22/relu/Relu/Relu (op#222)\\\\n input0 /backbone/layer3/layer3.22/conv1/Conv_output_0\\\\n output0 /backbone/layer3/layer3.22/relu/Relu_output_0': 433, '/backbone/layer3/layer3.22/relu/Relu_output_00': 434, '/backbone/layer3/layer3.22/conv2/Conv/Conv (op#223)\\\\n input0 /backbone/layer3/layer3.22/relu/Relu_output_0\\\\n input1 onnx': 435, '/backbone/layer3/layer3.22/conv2/Conv_output_00': 436, '/backbone/layer3/layer3.22/relu_1/Relu/Relu (op#224)\\\\n input0 /backbone/layer3/layer3.22/conv2/Conv_output_0\\\\n output0 /backbone/layer3/layer3.22/relu_1/Relu_output_0': 437, '/backbone/layer3/layer3.22/relu_1/Relu_output_00': 438, '/backbone/layer3/layer3.22/conv3/Conv/Conv (op#225)\\\\n input0 /backbone/layer3/layer3.22/relu_1/Relu_output_0\\\\n input1 onnx': 439, '/backbone/layer3/layer3.22/conv3/Conv_output_00': 440, '/backbone/layer3/layer3.22/Add/Add (op#226)\\\\n input0 /backbone/layer3/layer3.22/conv3/Conv_output_0\\\\n input1 /backbone/layer3/layer3.21/relu_2/Relu_output_0\\\\n output0 /backbone/layer3/layer3.22/Add_output_0': 441, '/backbone/layer3/layer3.22/Add_output_00': 442, '/backbone/layer3/layer3.22/relu_2/Relu/Relu (op#227)\\\\n input0 /backbone/layer3/layer3.22/Add_output_0\\\\n output0 /backbone/layer3/layer3.22/relu_2/Relu_output_0': 443, '/backbone/layer3/layer3.22/relu_2/Relu_output_00': 444, '/backbone/layer4/layer4.0/conv1/Conv/Conv (op#228)\\\\n input0 /backbone/layer3/layer3.22/relu_2/Relu_output_0\\\\n input1 onnx': 445, '/backbone/layer4/layer4.0/conv1/Conv_output_00': 446, '/backbone/layer4/layer4.0/relu/Relu/Relu (op#229)\\\\n input0 /backbone/layer4/layer4.0/conv1/Conv_output_0\\\\n output0 /backbone/layer4/layer4.0/relu/Relu_output_0': 447, '/backbone/layer4/layer4.0/relu/Relu_output_00': 448, '/backbone/layer4/layer4.0/conv2/Conv/Conv (op#230)\\\\n input0 /backbone/layer4/layer4.0/relu/Relu_output_0\\\\n input1 onnx': 449, '/backbone/layer4/layer4.0/conv2/Conv_output_00': 450, '/backbone/layer4/layer4.0/relu_1/Relu/Relu (op#231)\\\\n input0 /backbone/layer4/layer4.0/conv2/Conv_output_0\\\\n output0 /backbone/layer4/layer4.0/relu_1/Relu_output_0': 451, '/backbone/layer4/layer4.0/relu_1/Relu_output_00': 452, '/backbone/layer4/layer4.0/conv3/Conv/Conv (op#232)\\\\n input0 /backbone/layer4/layer4.0/relu_1/Relu_output_0\\\\n input1 onnx': 453, '/backbone/layer4/layer4.0/conv3/Conv_output_00': 454, '/backbone/layer4/layer4.0/downsample/downsample.0/Conv/Conv (op#233)\\\\n input0 /backbone/layer3/layer3.22/relu_2/Relu_output_0\\\\n input1 onnx': 455, '/backbone/layer4/layer4.0/downsample/downsample.0/Conv_output_00': 456, '/backbone/layer4/layer4.0/Add/Add (op#234)\\\\n input0 /backbone/layer4/layer4.0/conv3/Conv_output_0\\\\n input1 /backbone/layer4/layer4.0/downsample/downsample.0/Conv_output_0\\\\n output0 /backbone/layer4/layer4.0/Add_output_0': 457, '/backbone/layer4/layer4.0/Add_output_00': 458, '/backbone/layer4/layer4.0/relu_2/Relu/Relu (op#235)\\\\n input0 /backbone/layer4/layer4.0/Add_output_0\\\\n output0 /backbone/layer4/layer4.0/relu_2/Relu_output_0': 459, '/backbone/layer4/layer4.0/relu_2/Relu_output_00': 460, '/backbone/layer4/layer4.1/conv1/Conv/Conv (op#236)\\\\n input0 /backbone/layer4/layer4.0/relu_2/Relu_output_0\\\\n input1 onnx': 461, '/backbone/layer4/layer4.1/conv1/Conv_output_00': 462, '/backbone/layer4/layer4.1/relu/Relu/Relu (op#237)\\\\n input0 /backbone/layer4/layer4.1/conv1/Conv_output_0\\\\n output0 /backbone/layer4/layer4.1/relu/Relu_output_0': 463, '/backbone/layer4/layer4.1/relu/Relu_output_00': 464, '/backbone/layer4/layer4.1/conv2/Conv/Conv (op#238)\\\\n input0 /backbone/layer4/layer4.1/relu/Relu_output_0\\\\n input1 onnx': 465, '/backbone/layer4/layer4.1/conv2/Conv_output_00': 466, '/backbone/layer4/layer4.1/relu_1/Relu/Relu (op#239)\\\\n input0 /backbone/layer4/layer4.1/conv2/Conv_output_0\\\\n output0 /backbone/layer4/layer4.1/relu_1/Relu_output_0': 467, '/backbone/layer4/layer4.1/relu_1/Relu_output_00': 468, '/backbone/layer4/layer4.1/conv3/Conv/Conv (op#240)\\\\n input0 /backbone/layer4/layer4.1/relu_1/Relu_output_0\\\\n input1 onnx': 469, '/backbone/layer4/layer4.1/conv3/Conv_output_00': 470, '/backbone/layer4/layer4.1/Add/Add (op#241)\\\\n input0 /backbone/layer4/layer4.1/conv3/Conv_output_0\\\\n input1 /backbone/layer4/layer4.0/relu_2/Relu_output_0\\\\n output0 /backbone/layer4/layer4.1/Add_output_0': 471, '/backbone/layer4/layer4.1/Add_output_00': 472, '/backbone/layer4/layer4.1/relu_2/Relu/Relu (op#242)\\\\n input0 /backbone/layer4/layer4.1/Add_output_0\\\\n output0 /backbone/layer4/layer4.1/relu_2/Relu_output_0': 473, '/backbone/layer4/layer4.1/relu_2/Relu_output_00': 474, '/backbone/layer4/layer4.2/conv1/Conv/Conv (op#243)\\\\n input0 /backbone/layer4/layer4.1/relu_2/Relu_output_0\\\\n input1 onnx': 475, '/backbone/layer4/layer4.2/conv1/Conv_output_00': 476, '/backbone/layer4/layer4.2/relu/Relu/Relu (op#244)\\\\n input0 /backbone/layer4/layer4.2/conv1/Conv_output_0\\\\n output0 /backbone/layer4/layer4.2/relu/Relu_output_0': 477, '/backbone/layer4/layer4.2/relu/Relu_output_00': 478, '/backbone/layer4/layer4.2/conv2/Conv/Conv (op#245)\\\\n input0 /backbone/layer4/layer4.2/relu/Relu_output_0\\\\n input1 onnx': 479, '/backbone/layer4/layer4.2/conv2/Conv_output_00': 480, '/backbone/layer4/layer4.2/relu_1/Relu/Relu (op#246)\\\\n input0 /backbone/layer4/layer4.2/conv2/Conv_output_0\\\\n output0 /backbone/layer4/layer4.2/relu_1/Relu_output_0': 481, '/backbone/layer4/layer4.2/relu_1/Relu_output_00': 482, '/backbone/layer4/layer4.2/conv3/Conv/Conv (op#247)\\\\n input0 /backbone/layer4/layer4.2/relu_1/Relu_output_0\\\\n input1 onnx': 483, '/backbone/layer4/layer4.2/conv3/Conv_output_00': 484, '/backbone/layer4/layer4.2/Add/Add (op#248)\\\\n input0 /backbone/layer4/layer4.2/conv3/Conv_output_0\\\\n input1 /backbone/layer4/layer4.1/relu_2/Relu_output_0\\\\n output0 /backbone/layer4/layer4.2/Add_output_0': 485, '/backbone/layer4/layer4.2/Add_output_00': 486, '/backbone/layer4/layer4.2/relu_2/Relu/Relu (op#249)\\\\n input0 /backbone/layer4/layer4.2/Add_output_0\\\\n output0 /backbone/layer4/layer4.2/relu_2/Relu_output_0': 487, '/backbone/layer4/layer4.2/relu_2/Relu_output_00': 488, '/classifier/classifier.0/convs.0/convs.0.0/Conv/Conv (op#250)\\\\n input0 /backbone/layer4/layer4.2/relu_2/Relu_output_0\\\\n input1 onnx': 489, '/classifier/classifier.0/convs.0/convs.0.0/Conv_output_00': 490, '/classifier/classifier.0/convs.0/convs.0.2/Relu/Relu (op#251)\\\\n input0 /classifier/classifier.0/convs.0/convs.0.0/Conv_output_0\\\\n output0 /classifier/classifier.0/convs.0/convs.0.2/Relu_output_0': 491, '/classifier/classifier.0/convs.0/convs.0.2/Relu_output_00': 492, '/classifier/classifier.0/convs.1/convs.1.0/Conv/Conv (op#252)\\\\n input0 /backbone/layer4/layer4.2/relu_2/Relu_output_0\\\\n input1 onnx': 493, '/classifier/classifier.0/convs.1/convs.1.0/Conv_output_00': 494, '/classifier/classifier.0/convs.1/convs.1.2/Relu/Relu (op#253)\\\\n input0 /classifier/classifier.0/convs.1/convs.1.0/Conv_output_0\\\\n output0 /classifier/classifier.0/convs.1/convs.1.2/Relu_output_0': 495, '/classifier/classifier.0/convs.1/convs.1.2/Relu_output_00': 496, '/classifier/classifier.0/convs.2/convs.2.0/Conv/Conv (op#254)\\\\n input0 /backbone/layer4/layer4.2/relu_2/Relu_output_0\\\\n input1 onnx': 497, '/classifier/classifier.0/convs.2/convs.2.0/Conv_output_00': 498, '/classifier/classifier.0/convs.2/convs.2.2/Relu/Relu (op#255)\\\\n input0 /classifier/classifier.0/convs.2/convs.2.0/Conv_output_0\\\\n output0 /classifier/classifier.0/convs.2/convs.2.2/Relu_output_0': 499, '/classifier/classifier.0/convs.2/convs.2.2/Relu_output_00': 500, '/classifier/classifier.0/convs.3/convs.3.0/Conv/Conv (op#256)\\\\n input0 /backbone/layer4/layer4.2/relu_2/Relu_output_0\\\\n input1 onnx': 501, '/classifier/classifier.0/convs.3/convs.3.0/Conv_output_00': 502, '/classifier/classifier.0/convs.3/convs.3.2/Relu/Relu (op#257)\\\\n input0 /classifier/classifier.0/convs.3/convs.3.0/Conv_output_0\\\\n output0 /classifier/classifier.0/convs.3/convs.3.2/Relu_output_0': 503, '/classifier/classifier.0/convs.3/convs.3.2/Relu_output_00': 504, '/classifier/classifier.0/convs.4/Shape/Shape (op#258)\\\\n input0 /backbone/layer4/layer4.2/relu_2/Relu_output_0\\\\n output0 /classifier/classifier.0/convs.4/Shape_output_0': 505, '/classifier/classifier.0/convs.4/Shape_output_00': 506, '/classifier/classifier.0/convs.4/Constant/Constant (op#259)\\\\n output0 /classifier/classifier.0/convs.4/Constant_output_0': 507, '/classifier/classifier.0/convs.4/Constant_output_00': 508, '/classifier/classifier.0/convs.4/Gather/Gather (op#260)\\\\n input0 /classifier/classifier.0/convs.4/Shape_output_0\\\\n input1 /classifier/classifier.0/convs.4/Constant_output_0\\\\n output0 /classifier/classifier.0/convs.4/Gather_output_0': 509, '/classifier/classifier.0/convs.4/Gather_output_00': 510, '/classifier/classifier.0/convs.4/Shape_1/Shape (op#261)\\\\n input0 /backbone/layer4/layer4.2/relu_2/Relu_output_0\\\\n output0 /classifier/classifier.0/convs.4/Shape_1_output_0': 511, '/classifier/classifier.0/convs.4/Shape_1_output_00': 512, '/classifier/classifier.0/convs.4/Constant_1/Constant (op#262)\\\\n output0 /classifier/classifier.0/convs.4/Constant_1_output_0': 513, '/classifier/classifier.0/convs.4/Constant_1_output_00': 514, '/classifier/classifier.0/convs.4/Gather_1/Gather (op#263)\\\\n input0 /classifier/classifier.0/convs.4/Shape_1_output_0\\\\n input1 /classifier/classifier.0/convs.4/Constant_1_output_0\\\\n output0 /classifier/classifier.0/convs.4/Gather_1_output_0': 515, '/classifier/classifier.0/convs.4/Gather_1_output_00': 516, '/classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool/GlobalAveragePool (op#264)\\\\n input0 /backbone/layer4/layer4.2/relu_2/Relu_output_0\\\\n output0 /classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool_output_0': 517, '/classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool_output_00': 518, '/classifier/classifier.0/convs.4/convs.4.1/Conv/Conv (op#265)\\\\n input0 /classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool_output_0\\\\n input1 onnx': 519, '/classifier/classifier.0/convs.4/convs.4.1/Conv_output_00': 520, '/classifier/classifier.0/convs.4/convs.4.3/Relu/Relu (op#266)\\\\n input0 /classifier/classifier.0/convs.4/convs.4.1/Conv_output_0\\\\n output0 /classifier/classifier.0/convs.4/convs.4.3/Relu_output_0': 521, '/classifier/classifier.0/convs.4/convs.4.3/Relu_output_00': 522, 'Constant_281/Constant (op#267)\\\\n output0 onnx': 523, '/classifier/classifier.0/convs.4/Unsqueeze/Unsqueeze (op#268)\\\\n input0 /classifier/classifier.0/convs.4/Gather_output_0\\\\n input1 onnx': 524, '/classifier/classifier.0/convs.4/Unsqueeze_output_00': 525, 'Constant_283/Constant (op#269)\\\\n output0 onnx': 526, '/classifier/classifier.0/convs.4/Unsqueeze_1/Unsqueeze (op#270)\\\\n input0 /classifier/classifier.0/convs.4/Gather_1_output_0\\\\n input1 onnx': 527, '/classifier/classifier.0/convs.4/Unsqueeze_1_output_00': 528, '/classifier/classifier.0/convs.4/Concat/Concat (op#271)\\\\n input0 /classifier/classifier.0/convs.4/Unsqueeze_output_0\\\\n input1 /classifier/classifier.0/convs.4/Unsqueeze_1_output_0\\\\n output0 /classifier/classifier.0/convs.4/Concat_output_0': 529, '/classifier/classifier.0/convs.4/Concat_output_00': 530, '/classifier/classifier.0/convs.4/Shape_2/Shape (op#272)\\\\n input0 /classifier/classifier.0/convs.4/convs.4.3/Relu_output_0\\\\n output0 /classifier/classifier.0/convs.4/Shape_2_output_0': 531, '/classifier/classifier.0/convs.4/Shape_2_output_00': 532, '/classifier/classifier.0/convs.4/Constant_2/Constant (op#273)\\\\n output0 /classifier/classifier.0/convs.4/Constant_2_output_0': 533, '/classifier/classifier.0/convs.4/Constant_2_output_00': 534, '/classifier/classifier.0/convs.4/Constant_3/Constant (op#274)\\\\n output0 /classifier/classifier.0/convs.4/Constant_3_output_0': 535, '/classifier/classifier.0/convs.4/Constant_3_output_00': 536, '/classifier/classifier.0/convs.4/Constant_4/Constant (op#275)\\\\n output0 /classifier/classifier.0/convs.4/Constant_4_output_0': 537, '/classifier/classifier.0/convs.4/Constant_4_output_00': 538, '/classifier/classifier.0/convs.4/Slice/Slice (op#276)\\\\n input0 /classifier/classifier.0/convs.4/Shape_2_output_0\\\\n input1 /classifier/classifier.0/convs.4/Constant_3_output_0\\\\n input2 /classifier/classifier.0/convs.4/Constant_4_output_0\\\\n input3 /classifier/classifier.0/convs.4/Constant_2_output_0\\\\n output0 /classifier/classifier.0/convs.4/Slice_output_0': 539, '/classifier/classifier.0/convs.4/Slice_output_00': 540, '/classifier/classifier.0/convs.4/Cast/Cast (op#277)\\\\n input0 /classifier/classifier.0/convs.4/Concat_output_0\\\\n output0 /classifier/classifier.0/convs.4/Cast_output_0': 541, '/classifier/classifier.0/convs.4/Cast_output_00': 542, '/classifier/classifier.0/convs.4/Concat_1/Concat (op#278)\\\\n input0 /classifier/classifier.0/convs.4/Slice_output_0\\\\n input1 /classifier/classifier.0/convs.4/Cast_output_0\\\\n output0 /classifier/classifier.0/convs.4/Concat_1_output_0': 543, '/classifier/classifier.0/convs.4/Concat_1_output_00': 544, '/classifier/classifier.0/convs.4/Resize/Resize (op#279)\\\\n input0 /classifier/classifier.0/convs.4/convs.4.3/Relu_output_0\\\\n input1 \\\\n input2 \\\\n input3 /classifier/classifier.0/convs.4/Concat_1_output_0\\\\n output0 /classifier/classifier.0/convs.4/Resize_output_0': 545, '0': 546, '/classifier/classifier.0/convs.4/Resize_output_00': 547, '/classifier/classifier.0/Concat/Concat (op#280)\\\\n input0 /classifier/classifier.0/convs.0/convs.0.2/Relu_output_0\\\\n input1 /classifier/classifier.0/convs.1/convs.1.2/Relu_output_0\\\\n input2 /classifier/classifier.0/convs.2/convs.2.2/Relu_output_0\\\\n input3 /classifier/classifier.0/convs.3/convs.3.2/Relu_output_0\\\\n input4 /classifier/classifier.0/convs.4/Resize_output_0\\\\n output0 /classifier/classifier.0/Concat_output_0': 548, '/classifier/classifier.0/Concat_output_00': 549, '/classifier/classifier.0/project/project.0/Conv/Conv (op#281)\\\\n input0 /classifier/classifier.0/Concat_output_0\\\\n input1 onnx': 550, '/classifier/classifier.0/project/project.0/Conv_output_00': 551, '/classifier/classifier.0/project/project.2/Relu/Relu (op#282)\\\\n input0 /classifier/classifier.0/project/project.0/Conv_output_0\\\\n output0 /classifier/classifier.0/project/project.2/Relu_output_0': 552, '/classifier/classifier.0/project/project.2/Relu_output_00': 553, '/classifier/classifier.1/Conv/Conv (op#283)\\\\n input0 /classifier/classifier.0/project/project.2/Relu_output_0\\\\n input1 onnx': 554, '/classifier/classifier.1/Conv_output_00': 555, '/classifier/classifier.3/Relu/Relu (op#284)\\\\n input0 /classifier/classifier.1/Conv_output_0\\\\n output0 /classifier/classifier.3/Relu_output_0': 556, '/classifier/classifier.3/Relu_output_00': 557, '/classifier/classifier.4/Conv/Conv (op#285)\\\\n input0 /classifier/classifier.3/Relu_output_0\\\\n input1 classifier.4.weight\\\\n input2 classifier.4.bias\\\\n output0 /classifier/classifier.4/Conv_output_0': 558, 'classifier.4.weight0': 559, 'classifier.4.bias0': 560, '/classifier/classifier.4/Conv_output_00': 561, 'Constant_300/Constant (op#286)\\\\n output0 onnx': 562, '/Unsqueeze/Unsqueeze (op#287)\\\\n input0 /Gather_output_0\\\\n input1 onnx': 563, '/Unsqueeze_output_00': 564, 'Constant_302/Constant (op#288)\\\\n output0 onnx': 565, '/Unsqueeze_1/Unsqueeze (op#289)\\\\n input0 /Gather_1_output_0\\\\n input1 onnx': 566, '/Unsqueeze_1_output_00': 567, '/Concat/Concat (op#290)\\\\n input0 /Unsqueeze_output_0\\\\n input1 /Unsqueeze_1_output_0\\\\n output0 /Concat_output_0': 568, '/Concat_output_00': 569, '/Shape_2/Shape (op#291)\\\\n input0 /classifier/classifier.4/Conv_output_0\\\\n output0 /Shape_2_output_0': 570, '/Shape_2_output_00': 571, '/Constant_2/Constant (op#292)\\\\n output0 /Constant_2_output_0': 572, '/Constant_2_output_00': 573, '/Constant_3/Constant (op#293)\\\\n output0 /Constant_3_output_0': 574, '/Constant_3_output_00': 575, '/Constant_4/Constant (op#294)\\\\n output0 /Constant_4_output_0': 576, '/Constant_4_output_00': 577, '/Slice/Slice (op#295)\\\\n input0 /Shape_2_output_0\\\\n input1 /Constant_3_output_0\\\\n input2 /Constant_4_output_0\\\\n input3 /Constant_2_output_0\\\\n output0 /Slice_output_0': 578, '/Slice_output_00': 579, '/Cast/Cast (op#296)\\\\n input0 /Concat_output_0\\\\n output0 /Cast_output_0': 580, '/Cast_output_00': 581, '/Concat_1/Concat (op#297)\\\\n input0 /Slice_output_0\\\\n input1 /Cast_output_0\\\\n output0 /Concat_1_output_0': 582, '/Concat_1_output_00': 583, '/Resize/Resize (op#298)\\\\n input0 /classifier/classifier.4/Conv_output_0\\\\n input1 \\\\n input2 \\\\n input3 /Concat_1_output_0\\\\n output0 gemm_1': 584, 'gemm_10': 585}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585]\n"
     ]
    }
   ],
   "source": [
    "onnx_nxs_bak = copy.deepcopy(onnx_nxs)\n",
    "for onnx_nx in onnx_nxs_bak:\n",
    "    relabel_dict ={}\n",
    "    for n,node in enumerate(onnx_nx.nodes(data=True)):\n",
    "        # print(node[0])\n",
    "        relabel_dict.update({node[0]:n})\n",
    "        # print(type(node))\n",
    "        # node[1]['index'] = n\n",
    "        # print(node)\n",
    "    nx.relabel_nodes(onnx_nx, relabel_dict, copy=False)\n",
    "    # onnx_nx.adjacency_matrix\n",
    "    \n",
    "print(relabel_dict)\n",
    "    \n",
    "print(onnx_nx.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(onnx_nx)\n",
    "# onnx_nx.adjacency\n",
    "# onnx_nx.adj\n",
    "nx.adjacency_matrix(onnx_nx).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/conv1/Conv/Conv (op#0)\\\\n input0 input_1\\\\n input1 onnx', 'input_10', '/conv1/Conv_output_00', '/relu/Relu/Relu (op#1)\\\\n input0 /conv1/Conv_output_0\\\\n output0 /relu/Relu_output_0', '/relu/Relu_output_00', '/maxpool/MaxPool/MaxPool (op#2)\\\\n input0 /relu/Relu_output_0\\\\n output0 /maxpool/MaxPool_output_0', '/maxpool/MaxPool_output_00', '/layer1/layer1.0/conv1/Conv/Conv (op#3)\\\\n input0 /maxpool/MaxPool_output_0\\\\n input1 onnx', '/layer1/layer1.0/conv1/Conv_output_00', '/layer1/layer1.0/relu/Relu/Relu (op#4)\\\\n input0 /layer1/layer1.0/conv1/Conv_output_0\\\\n output0 /layer1/layer1.0/relu/Relu_output_0', '/layer1/layer1.0/relu/Relu_output_00', '/layer1/layer1.0/conv2/Conv/Conv (op#5)\\\\n input0 /layer1/layer1.0/relu/Relu_output_0\\\\n input1 onnx', '/layer1/layer1.0/conv2/Conv_output_00', '/layer1/layer1.0/Add/Add (op#6)\\\\n input0 /layer1/layer1.0/conv2/Conv_output_0\\\\n input1 /maxpool/MaxPool_output_0\\\\n output0 /layer1/layer1.0/Add_output_0', '/layer1/layer1.0/Add_output_00', '/layer1/layer1.0/relu_1/Relu/Relu (op#7)\\\\n input0 /layer1/layer1.0/Add_output_0\\\\n output0 /layer1/layer1.0/relu_1/Relu_output_0', '/layer1/layer1.0/relu_1/Relu_output_00', '/layer1/layer1.1/conv1/Conv/Conv (op#8)\\\\n input0 /layer1/layer1.0/relu_1/Relu_output_0\\\\n input1 onnx', '/layer1/layer1.1/conv1/Conv_output_00', '/layer1/layer1.1/relu/Relu/Relu (op#9)\\\\n input0 /layer1/layer1.1/conv1/Conv_output_0\\\\n output0 /layer1/layer1.1/relu/Relu_output_0', '/layer1/layer1.1/relu/Relu_output_00', '/layer1/layer1.1/conv2/Conv/Conv (op#10)\\\\n input0 /layer1/layer1.1/relu/Relu_output_0\\\\n input1 onnx', '/layer1/layer1.1/conv2/Conv_output_00', '/layer1/layer1.1/Add/Add (op#11)\\\\n input0 /layer1/layer1.1/conv2/Conv_output_0\\\\n input1 /layer1/layer1.0/relu_1/Relu_output_0\\\\n output0 /layer1/layer1.1/Add_output_0', '/layer1/layer1.1/Add_output_00', '/layer1/layer1.1/relu_1/Relu/Relu (op#12)\\\\n input0 /layer1/layer1.1/Add_output_0\\\\n output0 /layer1/layer1.1/relu_1/Relu_output_0', '/layer1/layer1.1/relu_1/Relu_output_00', '/layer2/layer2.0/conv1/Conv/Conv (op#13)\\\\n input0 /layer1/layer1.1/relu_1/Relu_output_0\\\\n input1 onnx', '/layer2/layer2.0/conv1/Conv_output_00', '/layer2/layer2.0/relu/Relu/Relu (op#14)\\\\n input0 /layer2/layer2.0/conv1/Conv_output_0\\\\n output0 /layer2/layer2.0/relu/Relu_output_0', '/layer2/layer2.0/relu/Relu_output_00', '/layer2/layer2.0/conv2/Conv/Conv (op#15)\\\\n input0 /layer2/layer2.0/relu/Relu_output_0\\\\n input1 onnx', '/layer2/layer2.0/conv2/Conv_output_00', '/layer2/layer2.0/downsample/downsample.0/Conv/Conv (op#16)\\\\n input0 /layer1/layer1.1/relu_1/Relu_output_0\\\\n input1 onnx', '/layer2/layer2.0/downsample/downsample.0/Conv_output_00', '/layer2/layer2.0/Add/Add (op#17)\\\\n input0 /layer2/layer2.0/conv2/Conv_output_0\\\\n input1 /layer2/layer2.0/downsample/downsample.0/Conv_output_0\\\\n output0 /layer2/layer2.0/Add_output_0', '/layer2/layer2.0/Add_output_00', '/layer2/layer2.0/relu_1/Relu/Relu (op#18)\\\\n input0 /layer2/layer2.0/Add_output_0\\\\n output0 /layer2/layer2.0/relu_1/Relu_output_0', '/layer2/layer2.0/relu_1/Relu_output_00', '/layer2/layer2.1/conv1/Conv/Conv (op#19)\\\\n input0 /layer2/layer2.0/relu_1/Relu_output_0\\\\n input1 onnx', '/layer2/layer2.1/conv1/Conv_output_00', '/layer2/layer2.1/relu/Relu/Relu (op#20)\\\\n input0 /layer2/layer2.1/conv1/Conv_output_0\\\\n output0 /layer2/layer2.1/relu/Relu_output_0', '/layer2/layer2.1/relu/Relu_output_00', '/layer2/layer2.1/conv2/Conv/Conv (op#21)\\\\n input0 /layer2/layer2.1/relu/Relu_output_0\\\\n input1 onnx', '/layer2/layer2.1/conv2/Conv_output_00', '/layer2/layer2.1/Add/Add (op#22)\\\\n input0 /layer2/layer2.1/conv2/Conv_output_0\\\\n input1 /layer2/layer2.0/relu_1/Relu_output_0\\\\n output0 /layer2/layer2.1/Add_output_0', '/layer2/layer2.1/Add_output_00', '/layer2/layer2.1/relu_1/Relu/Relu (op#23)\\\\n input0 /layer2/layer2.1/Add_output_0\\\\n output0 /layer2/layer2.1/relu_1/Relu_output_0', '/layer2/layer2.1/relu_1/Relu_output_00', '/layer3/layer3.0/conv1/Conv/Conv (op#24)\\\\n input0 /layer2/layer2.1/relu_1/Relu_output_0\\\\n input1 onnx', '/layer3/layer3.0/conv1/Conv_output_00', '/layer3/layer3.0/relu/Relu/Relu (op#25)\\\\n input0 /layer3/layer3.0/conv1/Conv_output_0\\\\n output0 /layer3/layer3.0/relu/Relu_output_0', '/layer3/layer3.0/relu/Relu_output_00', '/layer3/layer3.0/conv2/Conv/Conv (op#26)\\\\n input0 /layer3/layer3.0/relu/Relu_output_0\\\\n input1 onnx', '/layer3/layer3.0/conv2/Conv_output_00', '/layer3/layer3.0/downsample/downsample.0/Conv/Conv (op#27)\\\\n input0 /layer2/layer2.1/relu_1/Relu_output_0\\\\n input1 onnx', '/layer3/layer3.0/downsample/downsample.0/Conv_output_00', '/layer3/layer3.0/Add/Add (op#28)\\\\n input0 /layer3/layer3.0/conv2/Conv_output_0\\\\n input1 /layer3/layer3.0/downsample/downsample.0/Conv_output_0\\\\n output0 /layer3/layer3.0/Add_output_0', '/layer3/layer3.0/Add_output_00', '/layer3/layer3.0/relu_1/Relu/Relu (op#29)\\\\n input0 /layer3/layer3.0/Add_output_0\\\\n output0 /layer3/layer3.0/relu_1/Relu_output_0', '/layer3/layer3.0/relu_1/Relu_output_00', '/layer3/layer3.1/conv1/Conv/Conv (op#30)\\\\n input0 /layer3/layer3.0/relu_1/Relu_output_0\\\\n input1 onnx', '/layer3/layer3.1/conv1/Conv_output_00', '/layer3/layer3.1/relu/Relu/Relu (op#31)\\\\n input0 /layer3/layer3.1/conv1/Conv_output_0\\\\n output0 /layer3/layer3.1/relu/Relu_output_0', '/layer3/layer3.1/relu/Relu_output_00', '/layer3/layer3.1/conv2/Conv/Conv (op#32)\\\\n input0 /layer3/layer3.1/relu/Relu_output_0\\\\n input1 onnx', '/layer3/layer3.1/conv2/Conv_output_00', '/layer3/layer3.1/Add/Add (op#33)\\\\n input0 /layer3/layer3.1/conv2/Conv_output_0\\\\n input1 /layer3/layer3.0/relu_1/Relu_output_0\\\\n output0 /layer3/layer3.1/Add_output_0', '/layer3/layer3.1/Add_output_00', '/layer3/layer3.1/relu_1/Relu/Relu (op#34)\\\\n input0 /layer3/layer3.1/Add_output_0\\\\n output0 /layer3/layer3.1/relu_1/Relu_output_0', '/layer3/layer3.1/relu_1/Relu_output_00', '/layer4/layer4.0/conv1/Conv/Conv (op#35)\\\\n input0 /layer3/layer3.1/relu_1/Relu_output_0\\\\n input1 onnx', '/layer4/layer4.0/conv1/Conv_output_00', '/layer4/layer4.0/relu/Relu/Relu (op#36)\\\\n input0 /layer4/layer4.0/conv1/Conv_output_0\\\\n output0 /layer4/layer4.0/relu/Relu_output_0', '/layer4/layer4.0/relu/Relu_output_00', '/layer4/layer4.0/conv2/Conv/Conv (op#37)\\\\n input0 /layer4/layer4.0/relu/Relu_output_0\\\\n input1 onnx', '/layer4/layer4.0/conv2/Conv_output_00', '/layer4/layer4.0/downsample/downsample.0/Conv/Conv (op#38)\\\\n input0 /layer3/layer3.1/relu_1/Relu_output_0\\\\n input1 onnx', '/layer4/layer4.0/downsample/downsample.0/Conv_output_00', '/layer4/layer4.0/Add/Add (op#39)\\\\n input0 /layer4/layer4.0/conv2/Conv_output_0\\\\n input1 /layer4/layer4.0/downsample/downsample.0/Conv_output_0\\\\n output0 /layer4/layer4.0/Add_output_0', '/layer4/layer4.0/Add_output_00', '/layer4/layer4.0/relu_1/Relu/Relu (op#40)\\\\n input0 /layer4/layer4.0/Add_output_0\\\\n output0 /layer4/layer4.0/relu_1/Relu_output_0', '/layer4/layer4.0/relu_1/Relu_output_00', '/layer4/layer4.1/conv1/Conv/Conv (op#41)\\\\n input0 /layer4/layer4.0/relu_1/Relu_output_0\\\\n input1 onnx', '/layer4/layer4.1/conv1/Conv_output_00', '/layer4/layer4.1/relu/Relu/Relu (op#42)\\\\n input0 /layer4/layer4.1/conv1/Conv_output_0\\\\n output0 /layer4/layer4.1/relu/Relu_output_0', '/layer4/layer4.1/relu/Relu_output_00', '/layer4/layer4.1/conv2/Conv/Conv (op#43)\\\\n input0 /layer4/layer4.1/relu/Relu_output_0\\\\n input1 onnx', '/layer4/layer4.1/conv2/Conv_output_00', '/layer4/layer4.1/Add/Add (op#44)\\\\n input0 /layer4/layer4.1/conv2/Conv_output_0\\\\n input1 /layer4/layer4.0/relu_1/Relu_output_0\\\\n output0 /layer4/layer4.1/Add_output_0', '/layer4/layer4.1/Add_output_00', '/layer4/layer4.1/relu_1/Relu/Relu (op#45)\\\\n input0 /layer4/layer4.1/Add_output_0\\\\n output0 /layer4/layer4.1/relu_1/Relu_output_0', '/layer4/layer4.1/relu_1/Relu_output_00', '/avgpool/GlobalAveragePool/GlobalAveragePool (op#46)\\\\n input0 /layer4/layer4.1/relu_1/Relu_output_0\\\\n output0 /avgpool/GlobalAveragePool_output_0', '/avgpool/GlobalAveragePool_output_00', '/Flatten/Flatten (op#47)\\\\n input0 /avgpool/GlobalAveragePool_output_0\\\\n output0 /Flatten_output_0', '/Flatten_output_00', 'gemm_10']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = nx.newman_watts_strogatz_graph(100, 20, 0.05)\n",
    "# print(g.nodes)\n",
    "print(onnx_nx.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n",
      "INFO:collecting all words and their counts\n",
      "INFO:PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "INFO:collected 83 word types and 9 unique tags from a corpus of 9 examples and 9897 words\n",
      "INFO:Creating a fresh vocabulary\n",
      "INFO:Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 52 unique words (62.65% of original 83, drops 31)', 'datetime': '2024-05-22T15:45:01.410183', 'gensim': '4.3.2', 'python': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]', 'platform': 'Linux-5.15.0-1045-aws-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "INFO:Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 9820 word corpus (99.22% of original 9897, drops 77)', 'datetime': '2024-05-22T15:45:01.411168', 'gensim': '4.3.2', 'python': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]', 'platform': 'Linux-5.15.0-1045-aws-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "INFO:deleting the raw counts dictionary of 83 items\n",
      "INFO:sample=0.0001 downsamples 52 most-common words\n",
      "INFO:Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 498.2705630251911 word corpus (5.1%% of prior 9820)', 'datetime': '2024-05-22T15:45:01.414159', 'gensim': '4.3.2', 'python': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]', 'platform': 'Linux-5.15.0-1045-aws-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "INFO:estimated required memory for 52 words and 128 dimensions: 85656 bytes\n",
      "INFO:resetting layer weights\n",
      "INFO:Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 52 vocabulary and 128 features, using sg=1 hs=0 sample=0.0001 negative=5 window=0 shrink_windows=True', 'datetime': '2024-05-22T15:45:01.420003', 'gensim': '4.3.2', 'python': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]', 'platform': 'Linux-5.15.0-1045-aws-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "INFO:EPOCH 0: training on 9897 raw words (515 effective words) took 0.0s, 158693 effective words/s\n",
      "INFO:EPOCH 1: training on 9897 raw words (498 effective words) took 0.0s, 150286 effective words/s\n",
      "INFO:EPOCH 2: training on 9897 raw words (485 effective words) took 0.0s, 88021 effective words/s\n",
      "INFO:EPOCH 3: training on 9897 raw words (502 effective words) took 0.0s, 155726 effective words/s\n",
      "INFO:EPOCH 4: training on 9897 raw words (531 effective words) took 0.0s, 213317 effective words/s\n",
      "INFO:EPOCH 5: training on 9897 raw words (527 effective words) took 0.0s, 175172 effective words/s\n",
      "INFO:EPOCH 6: training on 9897 raw words (523 effective words) took 0.0s, 143753 effective words/s\n",
      "INFO:EPOCH 7: training on 9897 raw words (508 effective words) took 0.0s, 157273 effective words/s\n",
      "INFO:EPOCH 8: training on 9897 raw words (493 effective words) took 0.0s, 161003 effective words/s\n",
      "INFO:EPOCH 9: training on 9897 raw words (525 effective words) took 0.0s, 171682 effective words/s\n",
      "INFO:Doc2Vec lifecycle event {'msg': 'training on 98970 raw words (5107 effective words) took 0.1s, 88617 effective words/s', 'datetime': '2024-05-22T15:45:01.478876', 'gensim': '4.3.2', 'python': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]', 'platform': 'Linux-5.15.0-1045-aws-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "INFO:Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d128,n5,mc5,s0.0001,t4>', 'datetime': '2024-05-22T15:45:01.479729', 'gensim': '4.3.2', 'python': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]', 'platform': 'Linux-5.15.0-1045-aws-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import karateclub\n",
    "g2v = karateclub.graph2vec.Graph2Vec()\n",
    "# g2v.fit(onnx_nxs_bak)\n",
    "# g2v.fit(g)\n",
    "from modlee.model_metafeatures import ModelEncoder\n",
    "g2v_mfe = ModelEncoder()\n",
    "g2v_mfe.fit(onnx_nxs_bak)\n",
    "g2v_mfe.save('./g2v.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of modlee.model_metafeatures failed: Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/.conda/envs/modlee312/lib/python3.12/importlib/__init__.py\", line 131, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 866, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/modlee/model_metafeatures.py\", line 11, in <module>\n",
      "    converter = modlee.converter.Converter()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'modlee' has no attribute 'converter'\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wl_iterations': 2,\n",
       " 'use_node_attribute': None,\n",
       " 'dimensions': 128,\n",
       " 'workers': 4,\n",
       " 'down_sampling': 0.0001,\n",
       " 'epochs': 10,\n",
       " 'learning_rate': 0.025,\n",
       " 'min_count': 5,\n",
       " 'seed': 42,\n",
       " 'erase_base_features': False,\n",
       " 'model': <gensim.models.doc2vec.Doc2Vec at 0x7f2ca4f6fb90>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<karateclub.graph_embedding.graph2vec.Graph2Vec at 0x7f2cac250b30>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def save(self, path):\n",
      "        with open(path, 'wb') as _file:\n",
      "            _file.write(pickle.dumps(self))\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "modlee.model_metafeatures.ModelEncoder"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/modlee312/lib/python3.12/site-packages/karateclub/estimator.py:66: UserWarning: Please do be advised that the graph you have provided does not contain (some) edges in the main diagonal, for instance the self-loop constitued of (0, 0). These selfloops are necessary to ensure that the graph is traversable, and for this reason we create a copy of the graph and add therein the missing edges. Since we are creating a copy, this will immediately duplicate the memory requirements. To avoid this double allocation, you can provide the graph with the selfloops.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.22545156, -0.09464288, -0.17315903, ..., -0.00821528,\n",
       "        -0.02875592, -0.00988017],\n",
       "       [ 0.22960028, -0.09654257, -0.17630087, ..., -0.00852752,\n",
       "        -0.02949054, -0.01046936],\n",
       "       [ 0.233899  , -0.09961917, -0.17999695, ..., -0.01243607,\n",
       "        -0.02978834, -0.01627886],\n",
       "       ...,\n",
       "       [ 0.38982266, -0.17631257, -0.31545722, ..., -0.02178403,\n",
       "        -0.04004664, -0.01922835],\n",
       "       [ 0.34374988, -0.14821137, -0.25971365, ..., -0.01220447,\n",
       "        -0.0451714 , -0.0208948 ],\n",
       "       [ 0.3110027 , -0.13364235, -0.23361671, ..., -0.00931154,\n",
       "        -0.04302771, -0.01586122]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# g2v_rl = ModelEncoder.from_pkl('./g2v.pkl')\n",
    "g2v_mfe.get_params()\n",
    "g2v.set_params(**g2v_mfe.get_params())\n",
    "import modlee\n",
    "from modlee.model_metafeatures import ModelEncoder\n",
    "import inspect\n",
    "import pickle\n",
    "print(inspect.getsource(ModelEncoder.from_pkl))\n",
    "# g2v_me = ModelEncoder.from_pkl('./g2v.pkl')\n",
    "with open('./g2v.pkl', 'rb') as _file:\n",
    "    g2v_rl = pickle.load(_file)\n",
    "type(g2v_rl)\n",
    "g2v_rl.infer(onnx_nxs_bak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['model_metafeatures.py',\n",
       " '__pycache__',\n",
       " 'retriever.py',\n",
       " 'g2v.pkl',\n",
       " 'model_text_converter.py',\n",
       " 'config.py',\n",
       " 'client.py',\n",
       " 'trainer.py',\n",
       " 'loss_sweeper.py',\n",
       " 'model',\n",
       " '__init__.py',\n",
       " 'utils.py',\n",
       " 'exp_loss_logger.py',\n",
       " 'modlee_image_model.py',\n",
       " 'converter.py',\n",
       " 'recommender',\n",
       " 'data_metafeatures.py']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'modlee' has no attribute 'converter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(modlee\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mG2V_PKL)\n\u001b[1;32m      3\u001b[0m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(modlee\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mG2V_PKL))\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_metafeatures\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelEncoder\n\u001b[1;32m      5\u001b[0m t \u001b[39m=\u001b[39m ModelEncoder\u001b[39m.\u001b[39mfrom_pkl(modlee\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mG2V_PKL)\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/modlee312/lib/python3.12/site-packages/modlee/model_metafeatures.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m G2V_PKL\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodlee\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_model_size\n\u001b[0;32m---> 12\u001b[0m converter \u001b[39m=\u001b[39m modlee\u001b[39m.\u001b[39;49mconverter\u001b[39m.\u001b[39mConverter()\n\u001b[1;32m     14\u001b[0m \u001b[39m# g2v = ModelEncoder.from()\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mModelMetafeatures\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'modlee' has no attribute 'converter'"
     ]
    }
   ],
   "source": [
    "import modlee\n",
    "os.path.exists(modlee.config.G2V_PKL)\n",
    "os.listdir(os.path.dirname(modlee.config.G2V_PKL))\n",
    "from modlee.model_metafeatures import ModelEncoder\n",
    "t = ModelEncoder.from_pkl(modlee.config.G2V_PKL)\n",
    "import inspect\n",
    "print(inspect.getsource(ModelEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# pickle.dumps(g2v)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m g2v_rl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mloads(pickle\u001b[39m.\u001b[39mdumps(g2v))\n\u001b[1;32m      4\u001b[0m \u001b[39mdir\u001b[39m(g2v)\n\u001b[1;32m      5\u001b[0m \u001b[39m# g2v_rl.get_params()\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'g2v' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# pickle.dumps(g2v)\n",
    "g2v_rl = pickle.loads(pickle.dumps(g2v))\n",
    "dir(g2v)\n",
    "# g2v_rl.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 128)\n",
      "[[-0.00105674  0.00207241]\n",
      " [ 0.00077086  0.00120153]\n",
      " [ 0.00212177  0.00226101]\n",
      " [-0.00295678 -0.00129032]\n",
      " [ 0.00299434 -0.00307984]\n",
      " [ 0.0028862  -0.00365495]\n",
      " [ 0.00366727 -0.00284002]\n",
      " [ 0.00161454 -0.00362909]\n",
      " [ 0.00329536  0.00059563]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0020924 , 0.00233757, 0.00243714, 0.00171691, 0.00210903,\n",
       "       0.00205651, 0.0019765 , 0.00207881, 0.00183127, 0.00234839,\n",
       "       0.00150817, 0.00188816, 0.00205166, 0.00180361, 0.00203067,\n",
       "       0.00204342, 0.0014617 , 0.00201847, 0.00248629, 0.00265794,\n",
       "       0.00245506, 0.00221734, 0.00243728, 0.00224482, 0.00204721,\n",
       "       0.00193488, 0.00168973, 0.00131468, 0.00150243, 0.00254576,\n",
       "       0.00188076, 0.00229063, 0.00222308, 0.00196838, 0.0016687 ,\n",
       "       0.00215539, 0.00212319, 0.00206592, 0.0020287 , 0.00228454,\n",
       "       0.00200407, 0.00228356, 0.00180469, 0.00162153, 0.00184982,\n",
       "       0.00238861, 0.00240034, 0.00169113, 0.00210505, 0.00264343,\n",
       "       0.00135907, 0.00178642, 0.00231827, 0.00177731, 0.00199053,\n",
       "       0.00246064, 0.00167716, 0.00167195, 0.00232026, 0.00191732,\n",
       "       0.00250698, 0.00181417, 0.00221422, 0.00192077, 0.00231814,\n",
       "       0.0016966 , 0.00252831, 0.0019067 , 0.00212087, 0.00192985,\n",
       "       0.00212536, 0.00205462, 0.00250567, 0.00261688, 0.00203479,\n",
       "       0.00226262, 0.0021024 , 0.00221311, 0.00123317, 0.00156574,\n",
       "       0.00241584, 0.00229791, 0.00170057, 0.00138433, 0.00192214,\n",
       "       0.00201068, 0.00248485, 0.00210771, 0.00119216, 0.00210022,\n",
       "       0.002755  , 0.00252189, 0.00226851, 0.00222313, 0.0018686 ,\n",
       "       0.00238563, 0.00244579, 0.00216622, 0.00242574, 0.00235148,\n",
       "       0.00202508, 0.00152623, 0.00213347, 0.00205323, 0.00194334,\n",
       "       0.00239114, 0.00167787, 0.00244015, 0.00198126, 0.00166503,\n",
       "       0.0020915 , 0.00202189, 0.0027429 , 0.00236907, 0.00207783,\n",
       "       0.00167527, 0.00186973, 0.00252509, 0.00233339, 0.00235777,\n",
       "       0.00206699, 0.00234423, 0.00253185, 0.00236389, 0.00214822,\n",
       "       0.00175921, 0.00225675, 0.00227196], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for onnx_nx in onnx_nxs_bak:\n",
    "#     print(onnx_nx)\n",
    "#     g2v.infer([onnx_nx])\n",
    "graph_embds = g2v.infer(onnx_nxs_bak)\n",
    "graph_embds = np.array(graph_embds)\n",
    "print(graph_embds.shape)\n",
    "print(graph_embds[...,:2])\n",
    "graph_embds.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dir(onnx_nx)\n",
    "import matplotlib as mpl\n",
    "import copy\n",
    "nodes_to_prune = [k for k in onnx_nx.nodes.keys() if filter_node(k)]\n",
    "# help(onnx_nx.remove_node)\n",
    "onnx_nx_layers_only = copy.deepcopy(onnx_nx)\n",
    "for node in nodes_to_prune:\n",
    "    onnx_nx_layers_only.remove_node(node)\n",
    "print(onnx_nx_layers_only.nodes)\n",
    "# pc = mpl.collections.PatchCollection(edges, cmap=cmap)\n",
    "# pc.set_array(edge_colors)\n",
    "# ax.show()\n",
    "plt.show()\n",
    "dir(onnx_nx_layers_only.edges)\n",
    "# print(onnx_nx_layers_only.edges.keys())\n",
    "e0 = onnx_nx_layers_only.edges.items()\n",
    "print(e0)\n",
    "onnx_nx.is_directed()\n",
    "# print(onnx_nx.selfloop_edges)\n",
    "n0 = list(onnx_nx.nodes.items())[0]\n",
    "# print(n0[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_to_remove = []\n",
    "for node_name, node_data in onnx_nx_layers_only.nodes.items():\n",
    "    print(node_name)\n",
    "    print(node_data)\n",
    "    # if 'fontcolor' not in node_data:\n",
    "    # if 'label' not in node_data:\n",
    "    # if 'style' in node_data:\n",
    "    #     nodes_to_remove.append(node_name)\n",
    "        # onnx_nx_layers_only.remove_node(node_name)\n",
    "    print('\\n')\n",
    "\n",
    "print(nodes_to_remove)\n",
    "for node_to_remove in nodes_to_remove:\n",
    "    onnx_nx_layers_only.remove_node(node_to_remove)\n",
    "# n0 = onnx_nx.nodes[onnx_nx.nodes.keys()]\n",
    "# edge_colors = range(2,onnx_nx_layers_only.number_of_edges()+2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nx_drawing = nx.draw_networkx(onnx_nx_layers_only,\n",
    "    pos=nx.spring_layout(onnx_nx_layers_only, seed=64),\n",
    "    # pos=nx.bipartite_layout(onnx_nx),\n",
    "    with_labels=False,\n",
    "    node_size=10,\n",
    "    # edge_color=edge_colors,\n",
    "    # edge_cmap=plt.cm.plasma\n",
    "    # ax=ax\n",
    ")\n",
    "print(onnx_nx_layers_only.edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(onnx_nx)\n",
    "# dir(onnx_nx.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_name, node_data in onnx_nx.nodes.items():\n",
    "    # type(node_data)\n",
    "    print(onnx_nx.nodes[node_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch_geometric as pyg\n",
    "import numpy as np\n",
    "import torch_geometric as pyg\n",
    "# print(pyg.__version__)\n",
    "# dir(pyg)\n",
    "# dir(torch_geometric.torch_geometric)\n",
    "# from torch_geometric.utils import convert\n",
    "onnx_test = copy.deepcopy(onnx_nx_layers_only)\n",
    "# nx.set_node_attributes(onnx_test, None, \"label\")\n",
    "edge_dict = {'shape': 'box', 'color': '#0F9D58', 'style': 'filled', 'fontcolor': '#FFFFFF', 'label': None}\n",
    "for k in edge_dict.keys():\n",
    "    # nx.set_node_attributes(onnx_test, None, k)\n",
    "    # nx.set_node_attributes(onnx_test, np.random.rand(98)*100, k)\n",
    "    nx.set_node_attributes(onnx_test, np.random.rand()*100, k)\n",
    "    nx.set_node_attributes(onnx_test, np.random.rand()*100, f\"edge_{k}\")\n",
    "# dir(onnx_test.edges.items()[0])\n",
    "onnx_test.edges\n",
    "# for edge_name,edge_data in onnx_test.edges.items():\n",
    "#     print(edge_data)\n",
    "# nx.get_edge_attributes(onnx_test)\n",
    "nx.draw_networkx(onnx_test,\n",
    "    with_labels=False,\n",
    "        node_size=10,\n",
    "    )\n",
    "# for node,node_data in onnx_test.nodes.items():\n",
    "#     print(node_data)\n",
    "onnx_pyg = pyg.utils.convert.from_networkx(\n",
    "    onnx_test,\n",
    "    group_node_attrs=['label'],\n",
    "    group_edge_attrs=['shape']\n",
    "    )\n",
    "# !ls\n",
    "# onnx_pyg.label\n",
    "# dir(onnx_pyg)\n",
    "# onnx_pyg.fully_specify()\n",
    "# onnx_pyg.x\n",
    "# onnx_pyg.get_tensor()\n",
    "# onnx_pyg.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# dir(onnx_pyg)\n",
    "onnx_pyg.edge_attrs()\n",
    "onnx_pyg.is_directed()\n",
    "# onnx_pyg.num_nodes  \n",
    "# onnx_pyg.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GraphormerForGraphClassification\n",
    "\n",
    "model = GraphormerForGraphClassification.from_pretrained(\n",
    "    \"clefourrier/pcqm4mv2_graphormer_base\",\n",
    "    num_classes=1, # num_classes for the downstream task \n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(onnx_pyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "# dataset = DataLoader([onnx_pyg])\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        # self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        # self.conv1 = GCNConv(98, 16)\n",
    "        # self.conv1 = GCNConv(98, 1)\n",
    "        self.conv1 = GCNConv(1, 16)\n",
    "        # self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        self.conv2 = GCNConv(16, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "gcn = GCN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)\n",
    "type(onnx_pyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0].__dict__\n",
    "# dir(dataset[0])\n",
    "# dataset=dataset[0]\n",
    "len(dataset)\n",
    "d0 = dataset[0]\n",
    "# dir(d0)\n",
    "d0.keys()\n",
    "# d0.num_nodes\n",
    "# d0.edge_index = d0.edge_index[...,:-4]\n",
    "d0.num_node_features\n",
    "d0.get_all_tensor_attrs()\n",
    "d0.node_attrs()\n",
    "d0.edge_attrs()\n",
    "d0.edge_attr\n",
    "len(d0.edge_index[0])\n",
    "# d0.pos.shape\n",
    "d0.x.shape\n",
    "d0.y.shape\n",
    "d0_nx = pyg.utils.convert.to_networkx(\n",
    "    d0\n",
    ")\n",
    "d0_sub = d0_nx.subgraph(list(range(1000)))\n",
    "layout_type = 'random'\n",
    "layout_type = 'spectral'\n",
    "layout_type = 'spring'\n",
    "nx.draw_networkx(\n",
    "    d0_sub,\n",
    "    pos=getattr(nx, f\"{layout_type}_layout\")(d0_sub),\n",
    "    font_color=\"white\",\n",
    "    # font_size=0,\n",
    "    arrows=False,\n",
    "    with_labels=False,\n",
    "    node_size=2,\n",
    "    edge_color=(0,0,0,0.23)\n",
    "    )\n",
    "# d0.x\n",
    "# d0.edge_index\n",
    "len(d0.edge_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORA Citation network\n",
    "Nodes are papers, edges are citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(pyg.nn.models)\n",
    "# pyg_unet = pyg.nn.models.GraphUNet()\n",
    "pyg_models = pyg.nn.models\n",
    "for pyg_model in dir(pyg_models):\n",
    "    # print(pyg_model)\n",
    "    # dir(pyg_model)\n",
    "    if 'pretrained' in ' '.join((dir(getattr(pyg_models,pyg_model)))):\n",
    "        print(pyg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import DimeNet, DimeNetPlusPlus\n",
    "\n",
    "Model = DimeNetPlusPlus\n",
    "\n",
    "# path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'QM9')\n",
    "path = osp.join(osp.dirname(osp.abspath('')), '..', 'data', 'QM9')\n",
    "qm9_dataset = QM9(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(qm9_dataset)\n",
    "q0 = pyg.utils.convert.to_networkx(qm9_dataset[10])\n",
    "# # print(q0.node_attrs())\n",
    "# for q in qm9_dataset[:10]:\n",
    "    # print(q.x)\n",
    "nx.draw_networkx(q0,\n",
    "    font_color=\"white\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QM9 Quantum chemical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DimeNet uses the atomization energy for targets U0, U, H, and G, i.e.:\n",
    "# 7 -> 12, 8 -> 13, 9 -> 14, 10 -> 15\n",
    "idx = torch.tensor([0, 1, 2, 3, 4, 5, 6, 12, 13, 14, 15, 11])\n",
    "qm9_dataset.data.y = qm9_dataset.data.y[:, idx]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for target in range(12):\n",
    "for target in range(1):\n",
    "    # Skip target \\delta\\epsilon, since it can be computed via\n",
    "    # \\epsilon_{LUMO} - \\epsilon_{HOMO}:\n",
    "    if target == 4:\n",
    "        continue\n",
    "\n",
    "    # model, datasets = pyg.nn.SchNet.from_qm9_pretrained(path, qm9_dataset, target)\n",
    "    model, datasets = Model.from_qm9_pretrained(path, qm9_dataset, target)\n",
    "    train_dataset, val_dataset, test_dataset = datasets\n",
    "\n",
    "    model = model.to(device)\n",
    "    loader = DataLoader(test_dataset, batch_size=2)\n",
    "\n",
    "    maes = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(data.z, data.pos, data.batch)\n",
    "        mae = (pred.view(-1) - data.y[:, target]).abs()\n",
    "        maes.append(mae)\n",
    "\n",
    "    mae = torch.cat(maes, dim=0)\n",
    "\n",
    "    # Report meV instead of eV:\n",
    "    mae = 1000 * mae if target in [2, 3, 4, 6, 7, 8, 9, 10] else mae\n",
    "\n",
    "    print(f'Target: {target:02d}, MAE: {mae.mean():.5f} ± {mae.std():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = next(iter(DataLoader(train_dataset,batch_size=3)))\n",
    "x_tr[0]\n",
    "x_tr[1]\n",
    "nx.draw_networkx(pyg.utils.convert.to_networkx(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tr0 = train_dataset[0]\n",
    "import random\n",
    "from random import shuffle\n",
    "len(train_dataset)\n",
    "x_tr0 = random.choice(train_dataset)\n",
    "# dir(x_tr0)\n",
    "x_tr0\n",
    "x_tr0.num_features\n",
    "nx.draw_networkx(pyg.utils.convert.to_networkx(x_tr0), font_color=\"white\")\n",
    "#_tr0.z\n",
    "# x_tr0.pos\n",
    "print(x_tr0.z.shape)\n",
    "print(x_tr0.pos.shape)\n",
    "print(x_tr0.batch)\n",
    "bs = 10\n",
    "z_dummy = torch.randint(low=0,high=7,size=(bs,bs,))\n",
    "model(\n",
    "    z_dummy.to(device),\n",
    "    # torch.randint((bs),dtype=torch.int64).to(device),\n",
    "    torch.randn((bs,bs,3)).to(device),\n",
    "    None\n",
    ")\n",
    "# The {Dime,Sch}Nets take as input the QM9 dataset:\n",
    "# http://quantum-machine.org/datasets/\n",
    "# - z (num_nodes) - the classes of the nodes?\n",
    "# - pos (num_nodes, 3) - 3D positions. Why is this not the features (num_features=11)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(qm9_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0].num_node_features\n",
    "dataset[0].edge_index\n",
    "# dataset[0].num_features\n",
    "# dataset[0].x\n",
    "onnx_pyg.edge_index\n",
    "# onnx_pyg.x\n",
    "type(dataset[0]); type(onnx_pyg)\n",
    "onnx_pyg.x.max()\n",
    "onnx_pyg.num_nodes\n",
    "# onnx_pyg.num_node_features = onnx_pyg.num_nodes\n",
    "onnx_pyg.num_node_features\n",
    "# [onnx_pyg].num_node_features\n",
    "# type(dataset)\n",
    "# help(torch_geometric.datasets)\n",
    "# gcn(dataset[0])\n",
    "# pyg_data = onnx_pyg.unsqueeze(-1)\n",
    "BATCH_SIZE = 32\n",
    "class PyGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return BATCH_SIZE\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return onnx_pyg\n",
    "\n",
    "\n",
    "pyg_dataset = DataLoader(PyGDataset(), batch_size=BATCH_SIZE)\n",
    "# pyg_batch = next(iter(pyg_dataset))\n",
    "# [torch.Tensor(onnx_pyg)]*10\n",
    "# onnx_pyg*10\n",
    "pyg_batch_list = pyg.data.Batch.from_data_list([onnx_pyg]*32)\n",
    "gcn_out = gcn(pyg_batch_list)\n",
    "# gcn_out = gcn(torch.Tensor(onnx_pyg))\n",
    "gcn_out.shape\n",
    "gcn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX -> PyDot -> NetworkX -> PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_pyg_nx = pyg.utils.convert.to_networkx(\n",
    "    onnx_pyg,\n",
    "    \n",
    ")\n",
    "\n",
    "nx.draw_networkx(onnx_pyg_nx,\n",
    "    pos=nx.spring_layout(onnx_pyg_nx, seed=64),\n",
    "    with_labels=False,\n",
    "    node_size=10)\n",
    "\n",
    "# for node_name, node_data in onnx_pyg_nx.nodes.items():\n",
    "#     print(node_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph from ONNX -> PyDot -> NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nx.draw_networkx(onnx_pyg_nx,\n",
    "    pos=nx.spring_layout(onnx_pyg_nx, seed=64),\n",
    "    with_labels=False,\n",
    "    node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph from ONNX -> PyDot -> NetworkX -> PyG -> NetworkX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modlee3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
