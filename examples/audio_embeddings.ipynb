{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/mansiagr4/gifs/raw/main/new_small_logo.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Audio Embeddings With Tabular Classification Model\n",
    "\n",
    "In this example, we will build an audio classification model using `PyTorch` and `Wav2Vec2`, a pretrained model for processing audio data. This guide will walk you through each step of the process, including setting up the environment, loading and preprocessing data, defining and training a model, and evaluating its performance.\n",
    "\n",
    "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/modlee/modlee-audio-embeddings)\n",
    "\n",
    "\n",
    "First, we will import the the necessary libraries and set up the environment. \n",
    "\n",
    "```python\n",
    "import torchaudio\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import Wav2Vec2Model\n",
    "import torch\n",
    "import os\n",
    "import modlee\n",
    "import lightning.pytorch as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "torchaudio.set_audio_backend(\"sox_io\")\n",
    "```\n",
    "Now we will set our Modlee API key and initialize the Modlee package.\n",
    "Make sure that you have a Modlee account and an API key [from the dashboard](https://www.dashboard.modlee.ai/).\n",
    "Replace `replace-with-your-api-key` with your API key.\n",
    "\n",
    "```python\n",
    "os.environ['MODLEE_API_KEY'] = \"replace-with-your-api-key\"\n",
    "modlee.init(api_key=os.environ['MODLEE_API_KEY'])\n",
    "\n",
    "```\n",
    "Now, we will prepare our data. For this example, we will manually download the `Human Words Audio` dataset from Kaggle and upload it to the environment.\n",
    "\n",
    "Visit the [Human Words Audio dataset page](https://www.kaggle.com/datasets/warcoder/cats-vs-dogs-vs-birds-audio-classification?resource=download) on Kaggle and click the **Download** button to save the `Animals` directory to your local machine. \n",
    "\n",
    "Copy the path to that donwloaded file, which will be used later. \n",
    "This snippet loads the `Wav2Vec2` model. We'll use it to convert audio into embeddings.\n",
    "\n",
    "\n",
    "This snippet loads the `Wav2Vec2` model. `Wav2Vec2` is a model designed for speech processing. We'll use it to convert audio into embeddings.\n",
    "\n",
    "```python\n",
    "# Set device to GPU if available, otherwise use CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the pre-trained Wav2Vec2 model and move it to the specified device.\n",
    "wav2vec = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\").to(device)\n",
    "```\n",
    "This function converts raw audio waveforms into embeddings using the `Wav2Vec2` model.\n",
    "\n",
    "```python\n",
    "def get_wav2vec_embeddings(waveforms):\n",
    "    with torch.no_grad():  \n",
    "        inputs = torch.tensor(waveforms).to(device)\n",
    "        embeddings = wav2vec(inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "```\n",
    "\n",
    "The `AudioDataset` class handles loading and preprocessing of audio files. \n",
    "\n",
    "```python\n",
    "class AudioDataset(TensorDataset):\n",
    "    def __init__(self, audio_paths, labels, target_length=16000):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.labels = labels \n",
    "        self.target_length = target_length  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_paths[idx] \n",
    "        label = self.labels[idx]  \n",
    "        waveform, sample_rate = torchaudio.load(audio_path, normalize=True) \n",
    "        waveform = waveform.mean(dim=0) \n",
    "\n",
    "        # Pad or truncate the waveform to the target length\n",
    "        if waveform.size(0) < self.target_length:\n",
    "            waveform = torch.cat([waveform, torch.zeros(self.target_length - waveform.size(0))])\n",
    "        else:\n",
    "            waveform = waveform[:self.target_length]\n",
    "\n",
    "        return waveform, label \n",
    "```\n",
    "This function loads audio files and their corresponding labels from a directory structure.\n",
    "\n",
    "```python\n",
    "def load_dataset(data_dir):\n",
    "    audio_paths = []  \n",
    "    labels = []  \n",
    "\n",
    "    # Loop through each subdirectory in the data directory\n",
    "    for label_dir in os.listdir(data_dir):\n",
    "        label_dir_path = os.path.join(data_dir, label_dir)\n",
    "        if os.path.isdir(label_dir_path): \n",
    "            # Loop through each file in the directory\n",
    "            for file_name in os.listdir(label_dir_path):\n",
    "                if file_name.endswith('.wav'):  \n",
    "                    audio_paths.append(os.path.join(label_dir_path, file_name))  \n",
    "                    labels.append(label_dir)  \n",
    "\n",
    "    return audio_paths, labels \n",
    "\n",
    "```\n",
    "We define a simple Multi-Layer Perceptron (MLP) model for classification. This model takes the embeddings from `Wav2Vec2` as input.\n",
    "\n",
    "```python\n",
    "class MLP(modlee.model.TabularClassificationModleeModel):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 256),  \n",
    "            torch.nn.ReLU(),                \n",
    "            torch.nn.Linear(256, 128),          \n",
    "            torch.nn.ReLU(),                   \n",
    "            torch.nn.Linear(128, num_classes)   \n",
    "        )\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_target = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss_fn(y_pred, y_target) \n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y_target = val_batch\n",
    "        y_pred = self(x)\n",
    "        val_loss = self.loss_fn(y_pred, y_target)  \n",
    "        return {'val_loss': val_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9) \n",
    "        return optimizer\n",
    "```\n",
    "\n",
    "`Wav2Vec2` transforms raw audio data into numerical embeddings that a model can interpret. We preprocess the audio by normalizing and padding it to a fixed length. Then, `Wav2Vec2` generates embeddings for each audio clip.\n",
    "\n",
    "```python\n",
    "def precompute_embeddings(dataloader):\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        embeddings = get_wav2vec_embeddings(inputs)\n",
    "        embeddings_list.append(embeddings.cpu())\n",
    "        labels_list.append(labels)\n",
    "    embeddings_list = torch.cat(embeddings_list, dim=0) \n",
    "    labels_list = torch.cat(labels_list, dim=0)  \n",
    "    return embeddings_list, labels_list\n",
    "\n",
    "```\n",
    "We create a function to train and evaluate our model.\n",
    "\n",
    "```python\n",
    "def train_model(modlee_model, train_dataloader, val_dataloader, num_epochs=1):\n",
    "    \n",
    "    with modlee.start_run() as run:\n",
    "        # Create a PyTorch Lightning trainer\n",
    "        trainer = pl.Trainer(max_epochs=num_epochs)\n",
    "\n",
    "        # Train the model using the training and validation data loaders\n",
    "        trainer.fit(\n",
    "            model=modlee_model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader\n",
    "        )\n",
    "```\n",
    "\n",
    "Finally, we load the dataset, preprocess it, and train the model.\n",
    "\n",
    "Add your path to the dataset in `data_dir`.\n",
    "\n",
    "```python\n",
    "# Path to dataset\n",
    "data_dir = 'path-to-dataset'  \n",
    "\n",
    "# Load dataset\n",
    "audio_paths, labels = load_dataset(data_dir)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(audio_paths, labels, \n",
    "                                                            test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "target_length = 16000  \n",
    "train_dataset = AudioDataset(train_paths, train_labels, target_length=target_length)\n",
    "val_dataset = AudioDataset(val_paths, val_labels, target_length=target_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Precompute embeddings\n",
    "print(\"Precomputing embeddings for training and validation data...\")\n",
    "train_embeddings, train_labels = precompute_embeddings(train_dataloader)\n",
    "val_embeddings, val_labels = precompute_embeddings(val_dataloader)\n",
    "\n",
    "# Create TensorDataset for precomputed embeddings and labels\n",
    "train_embedding_dataset = TensorDataset(train_embeddings, train_labels)\n",
    "val_embedding_dataset = TensorDataset(val_embeddings, val_labels)\n",
    "\n",
    "# Create DataLoaders for the precomputed embeddings\n",
    "train_embedding_loader = DataLoader(train_embedding_dataset, batch_size=4, shuffle=True)\n",
    "val_embedding_loader = DataLoader(val_embedding_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Define number of classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "mlp_audio = MLP(input_size=768, num_classes=num_classes).to(device)\n",
    "\n",
    "# Train and evaluate the model\n",
    "train_model(mlp_audio, train_embedding_loader,val_embedding_loader)\n",
    "\n",
    "```\n",
    "\n",
    "Finally, we can view the saved assets from training. With Modlee, your training assets are automatically saved, preserving valuable insights for future reference and collaboration.\n",
    "\n",
    "```python\n",
    "last_run_path = modlee.last_run_path()\n",
    "print(f\"Run path: {last_run_path}\")\n",
    "artifacts_path = os.path.join(last_run_path, 'artifacts')\n",
    "artifacts = sorted(os.listdir(artifacts_path))\n",
    "print(f\"Saved artifacts: {artifacts}\")\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
