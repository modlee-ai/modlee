{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example notebook uses the `modlee` package to train a recommended model.\n",
        "We will perform image classification on CIFAR10 from `torchvision`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, import `torch`- and `modlee`-related packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import modlee\n",
        "modlee.init(api_key=\"my-api-key\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we create a dataloader from CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gdA4rn4JyQc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/projects/.venv/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Using downloaded and verified file: ./data/VOCtest_06-Nov-2007.tar\n",
            "Extracting ./data/VOCtest_06-Nov-2007.tar to ./data\n"
          ]
        }
      ],
      "source": [
        "transforms = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transforms)\n",
        "val_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "   )\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=16\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a `modlee` recommender object and fit to the dataset.\n",
        "The recommended `ModleeModel` object will be assigned to `recommender.model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Modlee] -> Just a moment, analyzing your dataset ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "recommender = modlee.recommender.from_modality_task(\n",
        "    modality='image',\n",
        "    task='classification',\n",
        "    )\n",
        "recommender.fit(train_dataloader)\n",
        "modlee_model = recommender.model \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can train the model as we would a basic `ModleeModel`, with documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with modlee.start_run() as run:\n",
        "    trainer = pl.Trainer(max_epochs=1)\n",
        "    trainer.fit(\n",
        "        model=modlee_model,\n",
        "        train_dataloaders=train_dataloader\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can view the saved assets from training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_run_path = modlee.last_run_path()\n",
        "print(last_run_path)\n",
        "artifacts = os.listdir(os.path.join(last_run_path, 'artifacts'))\n",
        "print(artifacts)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
