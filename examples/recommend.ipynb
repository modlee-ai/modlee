{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automate model recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example notebook uses the `modlee` package to train a recommended model.\n",
        "We will perform image classification on CIFAR10 from `torchvision`.\n",
        "\n",
        "Here is a video explanation of this [exercise](https://www.youtube.com/watch?v=3m5pNudQ1TA).\n",
        "\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3m5pNudQ1TA\" frameborder=\"0\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1oA9p6_Tm50beZC8_BPkKA44Gsx35Vzb5#scrollTo=lGmrerY-7OlO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "First, import `torch`- and `modlee`-related packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "import os\n",
        "import lightning.pytorch as pl\n",
        "os.environ['MODLEE_API_KEY'] = \"replace-with-your-api-key\"\n",
        "import torch, torchvision\n",
        "import torchvision.transforms as transforms\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, initialize the package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "import modlee\n",
        "modlee.init(api_key=os.environ.get('MODLEE_API_KEY'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we create a dataloader from CIFAR10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "transforms = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transforms)\n",
        "val_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "   )\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=16\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a `modlee` recommender object and fit to the dataset.\n",
        "This process will calculate the dataset metafeatures to send to the server.\n",
        "The server will return a recommended model for the dataset assigned to `recommender.model`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "recommender = modlee.recommender.from_modality_task(\n",
        "    modality='image',\n",
        "    task='classification',\n",
        "    )\n",
        "recommender.fit(train_dataloader)\n",
        "modlee_model = recommender.model \n",
        "print(f\"\\nRecommended model: \\n{modlee_model}\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "INFO:Analyzing dataset based on data metafeatures...\n",
        "INFO:Finished analyzing dataset.\n",
        "INFO:The model is available at the recommender object's `model` attribute.\n",
        "\n",
        "Recommended model: \n",
        "RecommendedModel(\n",
        "  (model): GraphModule(\n",
        "    (Conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
        "    (Conv_1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
        "    (Relu): ReLU()\n",
        "    (MaxPool): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], dilation=[1, 1], ceil_mode=False)\n",
        "    (Conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (Relu_1): ReLU()\n",
        "    (Conv_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (Add): OnnxBinaryMathOperation()\n",
        "    (Relu_2): ReLU()\n",
        "    (Conv_4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (Relu_3): ReLU()\n",
        "    (Conv_5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can train the model as we would a basic `ModleeModel`, with automatic documentation of metafeatures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "with modlee.start_run() as run:\n",
        "    trainer = pl.Trainer(max_epochs=1)\n",
        "    trainer.fit(\n",
        "        model=modlee_model,\n",
        "        train_dataloaders=train_dataloader\n",
        "    )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "  | Name  | Type        | Params\n",
        "--------------------------------------\n",
        "0 | model | GraphModule | 11.7 M\n",
        "--------------------------------------\n",
        "11.7 M    Trainable params\n",
        "0         Non-trainable params\n",
        "11.7 M    Total params\n",
        "46.779    Total estimated model params size (MB)\n",
        "Epoch 0: 100%|██████████| 3125/3125 [01:14<00:00, 41.86it/s, v_num=0]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can view the saved assets from training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "last_run_path = modlee.last_run_path()\n",
        "print(f\"Run path: {last_run_path}\")\n",
        "artifacts_path = os.path.join(last_run_path, 'artifacts')\n",
        "artifacts = sorted(os.listdir(artifacts_path))\n",
        "print(f\"Saved artifacts: {artifacts}\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Run path: /home/ubuntu/projects/modlee_pypi/examples/mlruns/0/ff1e754d6401438fba506a0d98ca1f91\n",
        "Saved artifacts: ['cached_vars', 'checkpoints', 'model', 'model.py', 'model_graph.py', 'model_graph.txt', 'model_size', 'model_summary.txt', 'stats_rep', 'transforms.txt']\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
