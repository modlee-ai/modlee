{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition guidelines\n",
    "\n",
    "Here we show pseudo code to illustrate how to define a ModleeModel that is compatible with **Modlee Auto Experiment Documentation**. Following these guidelines will ensure your model architecture is preserved, and can be shared with your collaborators in a way that it can be reloaded, *without having to share your model weights*.\n",
    "\n",
    "## TLDR\n",
    "- Define all custom objects as `nn.module` PyTorch classes within the same file as your ModleeModel.\n",
    "- Define all parameters used by PyTorch classes as hard coded variables within each class.\n",
    "\n",
    "## Define example custom ModleeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import modlee\n",
    "\n",
    "# Define custom activation function\n",
    "class CustomActivation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomActivation, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.log(torch.abs(x) + 1)\n",
    "\n",
    "# Define the CNN model with custom activation\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.kernel_size = 3 # --- Hard coded parameter to define network paramters\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=self.kernel_size, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=self.kernel_size, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=self.kernel_size, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.activation = CustomActivation()  # Custom activation\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.activation(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the ModleeModel\n",
    "class CNNModleeModel(modlee.model.ModleeModel):\n",
    "    def __init__(self):\n",
    "        super(CNNModleeModel, self).__init__()\n",
    "        self.cnn = CNNModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize the ModleeModel\n",
    "model = CNNModleeModel()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODLEE_GUIDELINE\n",
    "\n",
    "Define all custom objects, layers, activations, etc .. as `nn.module` PyTorch classes within the same file as your ModleeModel. Doing so ensures we can retrieve the necessary information to preserve the model architecture.\n",
    "\n",
    "Define all parameters, batch size, number of layers, learning rate, etc ..., used by PyTorch classes as hard coded variables within each class. Avoid using YAMLs or other config files as inputs to your Pytorch classes, because this makes it hard for us to retrieve parameter values needed to preserve the model architecture.\n",
    "\n",
    "Modlee preserves the architecture of your models so your experiments can be used in aggregate analysis alongside your collaborators data, to improve Modlee's model recommendation technology **without sharing your model weights**. This helps Modlee users protect parts of their IP, trained models, while allowing them the freedom to share aspects of their experiments to collaborate more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modality & task compatibility\n",
    "\n",
    "We're working on making modlee compatible with any data modality and machine learning task which drove us to create the above stated MODLEE_GUIDELINES.\n",
    "\n",
    "Check out our [Github Repo](https://github.com/modlee-ai/modlee) to see which have been tested for auto documentation to date, and if you don't see one you need, test it out yourself and contribute!\n",
    "\n",
    "Reach out on our [Discord](https://discord.com/invite/m8YDbWDvrF) to let us know what modality & tasks you want to use next, or give us feedback on these guidelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
