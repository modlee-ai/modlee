{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZlD9MHpyLdn"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZE0CHU9SkIC"
      },
      "source": [
        "In this exercise, you will implement the `modlee` package to:\n",
        "- Document an image segmentation experiment with a pretrained model from `torchvision`.\n",
        "- Receive and train a recommended model.\n",
        "\n",
        "It may be helpful to [keep the API documentation open](https://www.documentation.modlee.ai/index.html).\n",
        "\n",
        "For best performance, ensure that the runtime is set to use a GPU (`Runtime > Change runtime type > T4 GPU`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBfCjnQCtL_6"
      },
      "source": [
        "# **Installation**\n",
        "\n",
        "First, we need to install `modlee` and its related packages.\n",
        "Make sure that you have an account and API key [from the dashboard](https://www.dashboard.modlee.ai/).\n",
        "This process may take a few minutes, so you can [review the examples](https://www.documentation.modlee.ai/notebooks/document.html) while waiting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZfOmEtoZJuu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['MODLEE_API_KEY'] = \"replace-with-your-api-key\"\n",
        "!curl -H X-API-KEY:$MODLEE_API_KEY https://server.modlee.ai:7070/get_wheel/requirements.txt -O\n",
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M69SyWAlr6M-"
      },
      "outputs": [],
      "source": [
        "!curl -H X-API-KEY:$MODLEE_API_KEY https://server.modlee.ai:7070/get_wheel/modlee-0.0.1.post6-py3-none-any.whl -O\n",
        "!curl -H X-API-KEY:$MODLEE_API_KEY https://server.modlee.ai:7070/get_wheel/onnx2torch-1.5.11-py3-none-any.whl -O\n",
        "!curl -H X-API-KEY:$MODLEE_API_KEY https://server.modlee.ai:7070/get_wheel/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl -O\n",
        "!pip3 install --force-reinstall --no-deps modlee-0.0.1.post6-py3-none-any.whl onnx2torch-1.5.11-py3-none-any.whl onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl \\\n",
        "    lightning==2.0.7 pytorch-lightning==2.0.7 lightning-utilities lightning-cloud torchmetrics==1.3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66FxwqH_SkID"
      },
      "outputs": [],
      "source": [
        "# Boilerplate imports\n",
        "import os\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "import lightning.pytorch as pl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwn0XDvaSkH8"
      },
      "source": [
        "# **Documentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_TQ6gHgSkIE"
      },
      "source": [
        "We're ready to implement modlee to document an image segmentation experiment.\n",
        "Please [review the documentation example](https://www.documentation.modlee.ai/notebooks/document.html) before continuing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4vnRZuooyh-"
      },
      "source": [
        "In the next cell, import `modlee` and initialize with an API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EewhsqCbSkIE"
      },
      "outputs": [],
      "source": [
        "# Your code goes here. Import the modlee package and initialize with your API key.\n",
        "# Import\n",
        "import\n",
        "# Initialize\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "898vf1RhSkIF"
      },
      "source": [
        "Load the training data. This cell requires no modifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAA-tr1ySkIF"
      },
      "outputs": [],
      "source": [
        "imagenet_mean = [0.485, 0.456, 0.406]  # mean of the imagenet dataset for normalizing\n",
        "imagenet_std = [0.229, 0.224, 0.225]  # std of the imagenet dataset for normalizing\n",
        "\n",
        "def replace_tensor_value_(tensor, a, b):\n",
        "    tensor[tensor == a] = b\n",
        "    return tensor\n",
        "\n",
        "input_resize = transforms.Resize((224, 224))\n",
        "input_transform = transforms.Compose(\n",
        "    [\n",
        "        input_resize,\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "    ]\n",
        ")\n",
        "\n",
        "target_resize = transforms.Resize((224, 224), interpolation=InterpolationMode.NEAREST)\n",
        "target_transform = transforms.Compose(\n",
        "    [\n",
        "        target_resize,\n",
        "        transforms.PILToTensor(),\n",
        "        transforms.Lambda(lambda x: replace_tensor_value_(x.squeeze(0).long(), 255, 21)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Creating the dataset\n",
        "train_dataset = torchvision.datasets.VOCSegmentation(\n",
        "    './datasets/',\n",
        "    year='2007',\n",
        "    download=True,\n",
        "    image_set='val',\n",
        "    transform=input_transform,\n",
        "    target_transform=target_transform,\n",
        ")\n",
        "val_dataset = torchvision.datasets.VOCSegmentation(\n",
        "    './datasets/',\n",
        "    year='2007',\n",
        "    download=True,\n",
        "    image_set='val',\n",
        "    transform=input_transform,\n",
        "    target_transform=target_transform,\n",
        ")\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klsHMWCySkIG"
      },
      "source": [
        "In the next cell, we will construct the model.\n",
        "We initialize the model from a [pretrained fully connected network](https://pytorch.org/vision/main/models/generated/torchvision.models.segmentation.fcn_resnet50.html#torchvision.models.segmentation.fcn_resnet50).\n",
        "We subclass the `modlee.model.ModleeModel` parent class so that the experiment will automatically document.\n",
        "At minimum, you must define the `__init__()`, `forward()`, `training_step()`, and `configure_optimizers()` functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGwOhASRSkIG"
      },
      "outputs": [],
      "source": [
        "# Use a prerained torchvision Fully Connected Network\n",
        "fcn_model = torchvision.models.segmentation.fcn_resnet50(num_classes=22)\n",
        "\n",
        "# Subclass the correct modlee class\n",
        "class ModleeFCN( ''' Replace this with the correct modlee parent class '''):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.model = # Set the above fcn object to self.model\n",
        "        self.loss_fn = F.cross_entropy\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Fill out the forward pass\n",
        "        # Should return a tensor after it has passed through the model\n",
        "        pass\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Fill out the training step\n",
        "        x, y_target = # Get the input and output from the batch\n",
        "        y_pred = self(x)['out']\n",
        "        loss = # Calculate the loss between the prediction and target\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Fill out the optimizer configuration\n",
        "        pass\n",
        "\n",
        "# Create the model object\n",
        "modlee_model = ModleeFCN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GHkRWeoSkIH"
      },
      "source": [
        "In the next cell, start training within a `modlee.start_run()` context manager."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt-dAnpYSkIH"
      },
      "outputs": [],
      "source": [
        "# Your code goes here. Start training within a modlee.start_run() context manager\n",
        "# Create the context manager (with ... as ... :)\n",
        "with # Fill in the context manager (with ... as ...)\n",
        "    # Create the trainer object\n",
        "    trainer =\n",
        "    # Fit the trainer to the model and the training dataloader\n",
        "    trainer.fit(\n",
        "        # Fill in the arguments for training\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MevJ9kOdSkIH"
      },
      "source": [
        "Rebuild the saved model.\n",
        "First, determine the path to the most recent run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7TkXsQgSkIH"
      },
      "outputs": [],
      "source": [
        "last_run_path = # Get the last run path\n",
        "artifacts_path = os.path.join(last_run_path, 'artifacts')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csK3gO0uSkII"
      },
      "source": [
        "Next, reload the model from the assets saved in the `artifacts/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POvZhC2LSkII"
      },
      "outputs": [],
      "source": [
        "# Change directories\n",
        "exercise_dir = os.path.abspath(os.getcwd())\n",
        "os.chdir(artifacts_path)\n",
        "\n",
        "# Import the model graph:\n",
        "\n",
        "rebuilt_model = # Construct the model from the model graph module\n",
        "# Set the model to evaluation mode to turn off gradients\n",
        "rebuilt_model.eval()\n",
        "\n",
        "os.chdir(exercise_dir)\n",
        "# Pass an input through the model\n",
        "x, _ = next(iter(train_loader))\n",
        "with torch.no_grad():\n",
        "    y_rebuilt = rebuilt_model(x)\n",
        "\n",
        "print(f\"Rebuilt output shape: {y_rebuilt.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76Z3ESkxoDuc"
      },
      "source": [
        "You have completed the documentation example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8dxupD3wxI4"
      },
      "source": [
        "# **Recommendation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzWbfSnppKUU"
      },
      "source": [
        "We're ready to implement a modlee-recommended model in an experiment. Please [review the recommendation example](https://www.documentation.modlee.ai/notebooks/recommend.html) before continuing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFvlvRvkxemu"
      },
      "source": [
        "We can skip the `modlee` initialization steps assuming we did so in the documentation example.\n",
        "First, we create a dataloader from CIFAR10.\n",
        "This cell does not need any modifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebZDsx7xw0Rg"
      },
      "outputs": [],
      "source": [
        "transforms = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transforms)\n",
        "val_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        ")\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=16\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DV_M16DxYJL"
      },
      "source": [
        "Create a `modlee` recommender object for an image classification task and fit to the dataset.\n",
        "This process will calculate the dataset metafeatures to send to the server.\n",
        "The server will return a recommended model for the dataset assigned to `recommender.model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c69_xrPdxNk5"
      },
      "outputs": [],
      "source": [
        "recommender = # Create a recommender object for Image Classification\n",
        "recommender.fit(train_dataloader)\n",
        "modlee_model = # Extract the model from the recommender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPXiDgHoxXXK"
      },
      "source": [
        "We can train the model as we would a basic `ModleeModel`, with automatic documentation of metafeatures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va6b1o6qxQKW"
      },
      "outputs": [],
      "source": [
        "# Create and train the trainer\n",
        "with # ... as ...:\n",
        "    trainer = # Create the trainer\n",
        "    trainer.fit(\n",
        "        # Fill in the arguments\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxxYwqBbxSxq"
      },
      "source": [
        "Finally, we can view the saved assets from training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSBJqO0HxQ2x"
      },
      "outputs": [],
      "source": [
        "last_run_path = # Get the last run path\n",
        "print(f\"Run path: {last_run_path}\")\n",
        "artifacts_path = os.path.join(last_run_path, 'artifacts')\n",
        "artifacts = os.listdir(artifacts_path)\n",
        "print(f\"Saved artifacts: {artifacts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7RTL8TWx0hV"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SVL6IkVSkII"
      },
      "source": [
        "You've reached the end of the tutorial and can now implement `modlee` into your machine learning experiments.\n",
        "Congratulations!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}