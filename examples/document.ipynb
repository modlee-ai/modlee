<<<<<<< HEAD
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Automate experiment documentation"]},{"cell_type":"markdown","metadata":{},"source":["This example notebook uses the `modlee` package to document a machine learning experiment with a user-built model.\n","We train a simple convolutional classifier on the simple Fashion MNIST dataset.\n","After training, we can reuse the model from the auto-documented model class.\n","Prerequisites for this tutorial include familiarity with [PyTorch](https://pytorch.org/docs/stable/index.html) and [Lightning](https://lightning.ai/docs/pytorch/stable/)."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Boilerplate imports\n","import os, sys\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision"]},{"cell_type":"markdown","metadata":{},"source":["Import `modlee` and initialize with an API key."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/.conda/envs/modlee/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# Set the API key to an environment variable,\n","# to simulate setting this in your shell profile\n","os.environ['MODLEE_API_KEY'] = \"replace-with-your-api-key\"\n","# Modlee-specific imports\n","import modlee\n","modlee.init(api_key=os.environ['MODLEE_API_KEY'])"]},{"cell_type":"markdown","metadata":{},"source":["Load the training data; we'll use `torch`'s Fashion MNIST dataset."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Get Fashion MNIST, and convert from grayscale to RGB for compatibility with the model\n","train_dataloader, val_dataloader = modlee.utils.get_fashion_mnist(num_output_channels=3)\n","num_classes = len(train_dataloader.dataset.classes)"]},{"cell_type":"markdown","metadata":{},"source":["Next, we build the model from a pretrained torchvision ResNet model.\n","To enable automatic documentation, wrap the model in the `modlee.model.ModleeModel` class.\n","`ModleeModel` subclassees [`lightning.pytorch.LightningModule`](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html) and uses the same structure for the `training_step`, `validation_step`, and `configure_optimizers` functions.\n","Under the hood, `ModleeModel` also contains the callbacks to document the experiment metafeatures."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Use a pretrained torchvision ResNet\n","classifier_model = torchvision.models.resnet18(num_classes=10)\n","\n","# Subclass the ModleeModel class to enable automatic documentation\n","class ModleeClassifier(modlee.model.ModleeModel):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.model = classifier_model\n","        self.loss_fn = F.cross_entropy\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y_target = batch\n","        y_pred = self(x)\n","        loss = self.loss_fn(y_pred, y_target)\n","        return {\"loss\": loss}\n","\n","    def validation_step(self, val_batch, batch_idx):\n","        x, y_target = val_batch\n","        y_pred = self(x)\n","        val_loss = self.loss_fn(y_pred, y_target)\n","        return {'val_loss': val_loss}\n","        \n","    def configure_optimizers(self):\n","        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n","        return optimizer\n","\n","# Create the model object\n","modlee_model = ModleeClassifier()"]},{"cell_type":"markdown","metadata":{},"source":["Run the training loop, just for one epoch."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type   | Params\n","---------------------------------\n","0 | model | ResNet | 11.2 M\n","---------------------------------\n","11.2 M    Trainable params\n","0         Non-trainable params\n","11.2 M    Total params\n","44.727    Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 938/938 [00:36<00:00, 25.82it/s, v_num=0]        \n","Error reading file /home/ubuntu/projects/modlee_pypi/examples/mlruns/0/f4f917a600b9483ab24720b7b820fca0/artifacts/lightning_logs/version_0/checkpoints/epoch=0-loss=0.37.ckpt: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte\n","Error processing the following files: ['/home/ubuntu/projects/modlee_pypi/examples/mlruns/0/f4f917a600b9483ab24720b7b820fca0/artifacts/lightning_logs/version_0/checkpoints/epoch=0-loss=0.37.ckpt']\n"]}],"source":["with modlee.start_run() as run:\n","    trainer = modlee.Trainer(max_epochs=1)\n","    trainer.fit(\n","        model=modlee_model,\n","        train_dataloaders=train_dataloader,\n","        val_dataloaders=val_dataloader\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["```\n","  | Name  | Type       | Params\n","-------------------------------------\n","0 | model | Classifier | 44.4 K\n","-------------------------------------\n","44.4 K    Trainable params\n","0         Non-trainable params\n","44.4 K    Total params\n","0.178     Total estimated model params size (MB)\n","Epoch 0: 100%|██████████| 938/938 [00:16<00:00, 57.47it/s, v_num=0]  \n","```"]},{"cell_type":"markdown","metadata":{},"source":["`modlee` with `mlflow` underneath will document the experiment in an automatically generated `assets` folder. "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Run path: /home/ubuntu/projects/modlee_pypi/examples/mlruns/0/f4f917a600b9483ab24720b7b820fca0\n","Saved artifacts: ['transforms.txt', 'model_graph.py', 'model_graph.txt', 'model_size', 'model', 'cached_vars', 'stats_rep', 'snapshot_1.npy', 'lightning_logs', 'snapshot_0.npy', 'model.py', 'model_summary.txt']\n"]}],"source":["last_run_path = modlee.last_run_path()\n","print(f\"Run path: {last_run_path}\")\n","\n","artifacts_path = os.path.join(last_run_path, 'artifacts')\n","artifacts = os.listdir(artifacts_path)\n","print(f\"Saved artifacts: {artifacts}\")\n","\n","os.environ['ARTIFACTS_PATH'] = artifacts_path\n","# Add the artifacts directory to the path, \n","# so we can import the model\n","sys.path.insert(0, artifacts_path)\n"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Run path: /home/ubuntu/projects/modlee_pypi/examples/mlruns/0/7a47086681324d0e924f9076a1262de9/artifacts/model_graph.py\n","Saved artifacts: ['transforms.txt', 'model_graph.py', 'model_graph.txt', 'model_size', 'model', 'cached_vars', 'stats_rep', 'snapshot_1.npy', 'lightning_logs', 'snapshot_0.npy', 'model.py', 'loss_calls.txt', 'model_summary.txt']\n","```"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model graph:\n","\n","import torch, onnx2torch\n","from torch import tensor\n","\n","class Model(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        setattr(self,'Conv', torch.nn.modules.conv.Conv2d(**{'in_channels':3,'out_channels':64,'kernel_size':(7, 7),'stride':(2, 2),'padding':(3, 3),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Relu', torch.nn.modules.activation.ReLU(**{'inplace':False}))\n","        setattr(self,'MaxPool', torch.nn.modules.pooling.MaxPool2d(**{'kernel_size':[3, 3],'stride':[2, 2],'padding':[1, 1],'dilation':[1, 1],'return_indices':False,'ceil_mode':False}))\n","        setattr(self,'Conv_1', torch.nn.modules.conv.Conv2d(**{'in_channels':64,'out_channels':64,'kernel_size':(3, 3),'stride':(1, 1),'padding':(1, 1),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Relu_1', torch.nn.modules.activation.ReLU(**{'inplace':False}))\n","        setattr(self,'Conv_2', torch.nn.modules.conv.Conv2d(**{'in_channels':64,'out_channels':64,'kernel_size':(3, 3),'stride':(1, 1),'padding':(1, 1),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Add', onnx2torch.node_converters.binary_math_operations.OnnxBinaryMathOperation(**{'operation_type':'Add','broadcast':None,'axis':None}))\n","        ...\n","\n","    def forward(self, input_1):\n","        conv = self.Conv(input_1);  input_1 = None\n","        relu = self.Relu(conv);  conv = None\n","        max_pool = self.MaxPool(relu);  relu = None\n","        conv_1 = self.Conv_1(max_pool)\n","        relu_1 = self.Relu_1(conv_1);  conv_1 = None\n","        conv_2 = self.Conv_2(relu_1);  relu_1 = None\n","        add = self.Add(conv_2, max_pool);  conv_2 = max_pool = None\n","        relu_2 = self.Relu_2(add);  add = None\n","        conv_3 = self.Conv_3(relu_2)\n","        ...\n"]}],"source":["# Print out the first few lines of the model \n","print(\"Model graph:\")\n","!sed -n -e 1,15p $ARTIFACTS_PATH/model_graph.py\n","!echo \"        ...\"\n","!sed -n -e 58,68p $ARTIFACTS_PATH/model_graph.py\n","!echo \"        ...\""]},{"cell_type":"markdown","metadata":{},"source":["```\n","Model graph:\n","\n","import torch, onnx2torch\n","from torch import tensor\n","\n","class Model(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        setattr(self,'Conv', torch.nn.modules.conv.Conv2d(**{'in_channels':3,'out_channels':64,'kernel_size':(7, 7),'stride':(2, 2),'padding':(3, 3),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Relu', torch.nn.modules.activation.ReLU(**{'inplace':False}))\n","        setattr(self,'MaxPool', torch.nn.modules.pooling.MaxPool2d(**{'kernel_size':[3, 3],'stride':[2, 2],'padding':[1, 1],'dilation':[1, 1],'return_indices':False,'ceil_mode':False}))\n","        setattr(self,'Conv_1', torch.nn.modules.conv.Conv2d(**{'in_channels':64,'out_channels':64,'kernel_size':(3, 3),'stride':(1, 1),'padding':(1, 1),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Relu_1', torch.nn.modules.activation.ReLU(**{'inplace':False}))\n","        setattr(self,'Conv_2', torch.nn.modules.conv.Conv2d(**{'in_channels':64,'out_channels':64,'kernel_size':(3, 3),'stride':(1, 1),'padding':(1, 1),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Add', onnx2torch.node_converters.binary_math_operations.OnnxBinaryMathOperation(**{'operation_type':'Add','broadcast':None,'axis':None}))\n","        ...\n","\n","    def forward(self, input_1):\n","        conv = self.Conv(input_1);  input_1 = None\n","        relu = self.Relu(conv);  conv = None\n","        max_pool = self.MaxPool(relu);  relu = None\n","        conv_1 = self.Conv_1(max_pool)\n","        relu_1 = self.Relu_1(conv_1);  conv_1 = None\n","        conv_2 = self.Conv_2(relu_1);  relu_1 = None\n","        add = self.Add(conv_2, max_pool);  conv_2 = max_pool = None\n","        relu_2 = self.Relu_2(add);  add = None\n","        conv_3 = self.Conv_3(relu_2)\n","        ...\n","```"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data metafeatures:\n"]},{"name":"stdout","output_type":"stream","text":["{\n","  \"dataset_size\": 60032,\n","  \"num_sample\": 1000,\n","  \"batch_element_0\": {\n","    \"raw\": {\n","      \"feature_shape\": [\n","        960,\n","        3,\n","        28,\n","        28\n","      ],\n","      \"stats\": {\n","        \"kmeans\": {\n","          \"2\": {\n","            \"inertia\": \"154039.35607031966\",\n","            \"silhouette_score\": \"0.19075799\",\n","            \"calinski_harabasz_score\": \"252.0884224218105\",\n","            \"davies_bouldin_score\": \"1.8935099754339417\",\n","            \"time_taken\": \"0.7911794185638428\"\n","          },\n"]}],"source":["# Print the first lines of the data metafeatures\n","print(\"Data metafeatures:\")\n","!head -20 $ARTIFACTS_PATH/stats_rep"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Data metafeatures:\n","{\n","  \"dataset_size\": 60032,\n","  \"num_sample\": 1000,\n","  \"batch_element_0\": {\n","    \"raw\": {\n","      \"feature_shape\": [\n","        960,\n","        3,\n","        28,\n","        28\n","      ],\n","      \"stats\": {\n","        \"kmeans\": {\n","          \"2\": {\n","            \"inertia\": \"155588.50824155417\",\n","            \"silhouette_score\": \"0.19201575\",\n","            \"calinski_harabasz_score\": \"248.3331975601121\",\n","            \"davies_bouldin_score\": \"1.9090644142081366\",\n","            \"time_taken\": \"0.6537415981292725\"\n","          },\n","```"]},{"cell_type":"markdown","metadata":{},"source":["We can build the model from the cached `model_graph.Model` class and confirm that we can pass an input through it.\n","Note that this model's weights will be uninitialized.\n","To load the model from the last checkpoint, we can load it directly from the cached `model.pth`."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original input and output shapes: torch.Size([64, 3, 28, 28]), torch.Size([64, 10])\n","Output shapes from module-rebuilt and checkpoint-reloaded models: torch.Size([64, 10]), torch.Size([64, 10])\n"]}],"source":["\n","# Rebuilding from the object\n","import model_graph\n","rebuilt_model = model_graph.Model()\n","\n","# Set models to inference\n","modlee_model.eval(); rebuilt_model.eval()\n","\n","# Get a batch from the training loader\n","x, y = next(iter(train_dataloader))\n","with torch.no_grad():\n","    y_original = modlee_model(x)\n","    y_rebuilt = rebuilt_model(x)\n","assert y_original.shape == y_rebuilt.shape\n","\n","# Reloading from the checkpoint\n","reloaded_model = torch.load(os.path.join(artifacts_path, 'model', 'data','model.pth'))\n","y_reloaded = reloaded_model(x)\n","assert y_original.shape == y_reloaded.shape\n","print(f\"Original input and output shapes: {x.shape}, {y_original.shape}\")\n","print(f\"Output shapes from module-rebuilt and checkpoint-reloaded models: {y_rebuilt.shape}, {y_reloaded.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Original input and output shapes: torch.Size([64, 1, 28, 28]), torch.Size([64, 10])\n","Output shapes from module-rebuilt and checkpoint-reloaded models: torch.Size([64, 10]), torch.Size([64, 10])\n","```"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":2}
=======
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Automate experiment documentation"]},{"cell_type":"markdown","metadata":{},"source":["This example notebook uses the `modlee` package to document a machine learning experiment with a user-built model.\n","We train a simple convolutional classifier on the simple Fashion MNIST dataset.\n","After training, we can reuse the model from the auto-documented model class.\n","Prerequisites for this tutorial include familiarity with [PyTorch](https://pytorch.org/docs/stable/index.html) and [Lightning](https://lightning.ai/docs/pytorch/stable/)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Boilerplate imports\n","import os, sys\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision"]},{"cell_type":"markdown","metadata":{},"source":["Import `modlee` and initialize with an API key."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set the API key to an environment variable,\n","# to simulate setting this in your shell profile\n","os.environ['MODLEE_API_KEY'] = \"replace-with-your-api-key\"\n","# Modlee-specific imports\n","import modlee\n","modlee.init(api_key=os.environ['MODLEE_API_KEY'])"]},{"cell_type":"markdown","metadata":{},"source":["Load the training data; we'll use `torch`'s Fashion MNIST dataset."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get Fashion MNIST, and convert from grayscale to RGB for compatibility with the model\n","train_dataloader, val_dataloader = modlee.utils.get_fashion_mnist(num_output_channels=3)\n","num_classes = len(train_dataloader.dataset.classes)"]},{"cell_type":"markdown","metadata":{},"source":["Next, we build the model from a pretrained torchvision ResNet model.\n","To enable automatic documentation, wrap the model in the `modlee.model.ModleeModel` class.\n","`ModleeModel` subclassees [`lightning.pytorch.LightningModule`](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html) and uses the same structure for the `training_step`, `validation_step`, and `configure_optimizers` functions.\n","Under the hood, `ModleeModel` also contains the callbacks to document the experiment metafeatures."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use a pretrained torchvision ResNet\n","classifier_model = torchvision.models.resnet18(num_classes=10)\n","\n","# Subclass the ModleeModel class to enable automatic documentation\n","class ModleeClassifier(modlee.model.ModleeModel):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.model = classifier_model\n","        self.loss_fn = F.cross_entropy\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y_target = batch\n","        y_pred = self(x)\n","        loss = self.loss_fn(y_pred, y_target)\n","        return {\"loss\": loss}\n","\n","    def validation_step(self, val_batch, batch_idx):\n","        x, y_target = val_batch\n","        y_pred = self(x)\n","        val_loss = self.loss_fn(y_pred, y_target)\n","        return {'val_loss': val_loss}\n","        \n","    def configure_optimizers(self):\n","        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n","        return optimizer\n","\n","# Create the model object\n","modlee_model = ModleeClassifier()"]},{"cell_type":"markdown","metadata":{},"source":["Run the training loop, just for one epoch."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with modlee.start_run() as run:\n","    trainer = modlee.Trainer(max_epochs=1)\n","    trainer.fit(\n","        model=modlee_model,\n","        train_dataloaders=train_dataloader,\n","        val_dataloaders=val_dataloader\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["```\n","  | Name  | Type       | Params\n","-------------------------------------\n","0 | model | Classifier | 44.4 K\n","-------------------------------------\n","44.4 K    Trainable params\n","0         Non-trainable params\n","44.4 K    Total params\n","0.178     Total estimated model params size (MB)\n","Epoch 0: 100%|██████████| 938/938 [00:16<00:00, 57.47it/s, v_num=0]  \n","```"]},{"cell_type":"markdown","metadata":{},"source":["`modlee` with `mlflow` underneath will document the experiment in an automatically generated `assets` folder. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["last_run_path = modlee.last_run_path()\n","print(f\"Run path: {last_run_path}\")\n","\n","artifacts_path = os.path.join(last_run_path, 'artifacts')\n","artifacts = os.listdir(artifacts_path)\n","print(f\"Saved artifacts: {artifacts}\")\n","\n","os.environ['ARTIFACTS_PATH'] = artifacts_path\n","# Add the artifacts directory to the path, \n","# so we can import the model\n","sys.path.insert(0, artifacts_path)"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Run path: /home/ubuntu/projects/modlee_pypi/examples/mlruns/0/7a47086681324d0e924f9076a1262de9/artifacts/model_graph.py\n","Saved artifacts: ['transforms.txt', 'model_graph.py', 'model_graph.txt', 'model_size', 'model', 'cached_vars', 'stats_rep', 'snapshot_1.npy', 'lightning_logs', 'snapshot_0.npy', 'model.py', 'loss_calls.txt', 'model_summary.txt']\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Print out the first few lines of the model \n","print(\"Model graph:\")\n","!sed -n -e 1,15p $ARTIFACTS_PATH/model_graph.py\n","!echo \"        ...\"\n","!sed -n -e 58,68p $ARTIFACTS_PATH/model_graph.py\n","!echo \"        ...\""]},{"cell_type":"markdown","metadata":{},"source":["```\n","Model graph:\n","\n","import torch, onnx2torch\n","from torch import tensor\n","\n","class Model(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        setattr(self,'Conv', torch.nn.modules.conv.Conv2d(**{'in_channels':3,'out_channels':64,'kernel_size':(7, 7),'stride':(2, 2),'padding':(3, 3),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Relu', torch.nn.modules.activation.ReLU(**{'inplace':False}))\n","        setattr(self,'MaxPool', torch.nn.modules.pooling.MaxPool2d(**{'kernel_size':[3, 3],'stride':[2, 2],'padding':[1, 1],'dilation':[1, 1],'return_indices':False,'ceil_mode':False}))\n","        setattr(self,'Conv_1', torch.nn.modules.conv.Conv2d(**{'in_channels':64,'out_channels':64,'kernel_size':(3, 3),'stride':(1, 1),'padding':(1, 1),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Relu_1', torch.nn.modules.activation.ReLU(**{'inplace':False}))\n","        setattr(self,'Conv_2', torch.nn.modules.conv.Conv2d(**{'in_channels':64,'out_channels':64,'kernel_size':(3, 3),'stride':(1, 1),'padding':(1, 1),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Add', onnx2torch.node_converters.binary_math_operations.OnnxBinaryMathOperation(**{'operation_type':'Add','broadcast':None,'axis':None}))\n","        ...\n","\n","    def forward(self, input_1):\n","        conv = self.Conv(input_1);  input_1 = None\n","        relu = self.Relu(conv);  conv = None\n","        max_pool = self.MaxPool(relu);  relu = None\n","        conv_1 = self.Conv_1(max_pool)\n","        relu_1 = self.Relu_1(conv_1);  conv_1 = None\n","        conv_2 = self.Conv_2(relu_1);  relu_1 = None\n","        add = self.Add(conv_2, max_pool);  conv_2 = max_pool = None\n","        relu_2 = self.Relu_2(add);  add = None\n","        conv_3 = self.Conv_3(relu_2)\n","        ...\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Print the first lines of the data metafeatures\n","print(\"Data metafeatures:\")\n","!head -20 $ARTIFACTS_PATH/stats_rep\n","!echo \"        ...\""]},{"cell_type":"markdown","metadata":{},"source":["```\n","Data metafeatures:\n","{\n","  \"dataset_size\": 60032,\n","  \"num_sample\": 1000,\n","  \"batch_element_0\": {\n","    \"raw\": {\n","      \"feature_shape\": [\n","        960,\n","        3,\n","        28,\n","        28\n","      ],\n","      \"stats\": {\n","        \"kmeans\": {\n","          \"2\": {\n","            \"inertia\": \"155588.50824155417\",\n","            \"silhouette_score\": \"0.19201575\",\n","            \"calinski_harabasz_score\": \"248.3331975601121\",\n","            \"davies_bouldin_score\": \"1.9090644142081366\",\n","            \"time_taken\": \"0.6537415981292725\"\n","          },\n","          ...\n","```"]},{"cell_type":"markdown","metadata":{},"source":["We can build the model from the cached `model_graph.Model` class and confirm that we can pass an input through it.\n","Note that this model's weights will be uninitialized."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Rebuilding from the object\n","import model_graph\n","rebuilt_model = model_graph.Model()\n","\n","# Set models to inference\n","modlee_model.eval(); rebuilt_model.eval()\n","\n","# Get a batch from the training loader\n","x, y = next(iter(train_dataloader))\n","with torch.no_grad():\n","    y_original = modlee_model(x)\n","    y_rebuilt = rebuilt_model(x)\n","assert y_original.shape == y_rebuilt.shape\n","\n","print(f\"Original input and output shapes: {x.shape}, {y_original.shape}\")\n","print(f\"Output shape from module-rebuilt model: {y_rebuilt.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["To load the model from the last checkpoint, we can load it directly from the cached `model.pth`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reloading from the checkpoint\n","reloaded_model = torch.load(os.path.join(artifacts_path, 'model', 'data','model.pth'))\n","y_reloaded = reloaded_model(x)\n","assert y_original.shape == y_reloaded.shape\n","print(f\"Output shape from checkpoint-reloaded model: {y_reloaded.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Original input and output shapes: torch.Size([64, 3, 28, 28]), torch.Size([64, 10])\n","Output shapes from module-rebuilt and checkpoint-reloaded models: torch.Size([64, 10]), torch.Size([64, 10])\n","```"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":2}
>>>>>>> 9e2f20e... Beta polishes
