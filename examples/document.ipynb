{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Automate experiment documentation"]},{"cell_type":"markdown","metadata":{},"source":["This example notebook uses the `modlee` package to document a machine learning experiment with a user-built model.\n","We train a simple convolutional classifier on the simple Fashion MNIST dataset.\n","After training, we can reuse the model from the auto-documented model class.\n","Prerequisites for this tutorial include familiarity with [PyTorch](https://pytorch.org/docs/stable/index.html) and [Lightning](https://lightning.ai/docs/pytorch/stable/).\n","\n","Here is a video explanation of this [exercise](https://www.youtube.com/watch?v=2TE5--ZuFCc).\n","\n","<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2TE5--ZuFCc\" frameborder=\"0\" allowfullscreen></iframe>"]},{"cell_type":"markdown","metadata":{},"source":["[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/105yLGrdlqZeIFELNUAEKNmHNCQFJx9pe#scrollTo=NuJ4wSp6cshn)\n"]},{"cell_type":"markdown","metadata":{},"source":["```python\n","# Boilerplate imports\n","import os, sys\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","import lightning.pytorch as pl\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Import `modlee` and initialize with an API key."]},{"cell_type":"markdown","metadata":{},"source":["```python\n","# Set the API key to an environment variable,\n","# to simulate setting this in your shell profile\n","os.environ['MODLEE_API_KEY'] = \"replace-with-your-api-key\"\n","# Modlee-specific imports\n","import modlee\n","modlee.init(api_key=os.environ['MODLEE_API_KEY'])\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Load the training data; we'll use `torch`'s Fashion MNIST dataset."]},{"cell_type":"markdown","metadata":{},"source":["```python\n","# Get Fashion MNIST, and convert from grayscale to RGB for compatibility with the model\n","train_dataloader, val_dataloader = modlee.utils.get_fashion_mnist(num_output_channels=3)\n","num_classes = len(train_dataloader.dataset.classes)\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Next, we build the model from a pretrained torchvision ResNet model.\n","To enable automatic documentation, wrap the model in the `modlee.model.ModleeModel` class.\n","`ModleeModel` subclasses `lightning.pytorch.LightningModule` and uses the same structure for the `training_step`, `validation_step`, and `configure_optimizers` functions.\n","Under the hood, `ModleeModel` also contains the callbacks to document the experiment metafeatures."]},{"cell_type":"markdown","metadata":{},"source":["```python\n","# Use a pretrained torchvision ResNet\n","classifier_model = torchvision.models.resnet18(num_classes=10)\n","\n","# Subclass the ModleeModel class to enable automatic documentation\n","class ModleeClassifier(modlee.model.ModleeModel):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.model = classifier_model\n","        self.loss_fn = F.cross_entropy\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y_target = batch\n","        y_pred = self(x)\n","        loss = self.loss_fn(y_pred, y_target)\n","        return {\"loss\": loss}\n","\n","    def validation_step(self, val_batch, batch_idx):\n","        x, y_target = val_batch\n","        y_pred = self(x)\n","        val_loss = self.loss_fn(y_pred, y_target)\n","        return {'val_loss': val_loss}\n","        \n","    def configure_optimizers(self):\n","        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n","        return optimizer\n","\n","# Create the model object\n","modlee_model = ModleeClassifier()\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Run the training loop, just for one epoch."]},{"cell_type":"markdown","metadata":{},"source":["```python\n","with modlee.start_run() as run:\n","    trainer = pl.Trainer(max_epochs=1)\n","    trainer.fit(\n","        model=modlee_model,\n","        train_dataloaders=train_dataloader,\n","        val_dataloaders=val_dataloader\n","    )\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```\n","  | Name  | Type       | Params\n","-------------------------------------\n","0 | model | Classifier | 44.4 K\n","-------------------------------------\n","44.4 K    Trainable params\n","0         Non-trainable params\n","44.4 K    Total params\n","0.178     Total estimated model params size (MB)\n","Epoch 0: 100%|██████████| 938/938 [00:16<00:00, 57.47it/s, v_num=0]  \n","```"]},{"cell_type":"markdown","metadata":{},"source":["`modlee` with `mlflow` underneath will document the experiment in an automatically generated `assets` folder. "]},{"cell_type":"markdown","metadata":{},"source":["```python\n","last_run_path = modlee.last_run_path()\n","print(f\"Run path: {last_run_path}\")\n","\n","artifacts_path = os.path.join(last_run_path, 'artifacts')\n","artifacts = os.listdir(artifacts_path)\n","print(f\"Saved artifacts: {artifacts}\")\n","\n","os.environ['ARTIFACTS_PATH'] = artifacts_path\n","# Add the artifacts directory to the path, \n","# so we can import the model\n","sys.path.insert(0, artifacts_path)\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Run path: /home/ubuntu/projects/modlee_pypi/examples/mlruns/0/7a47086681324d0e924f9076a1262de9/artifacts/model_graph.py\n","Saved artifacts: ['transforms.txt', 'model_graph.py', 'model_graph.txt', 'model_size', 'model', 'cached_vars', 'stats_rep', 'snapshot_1.npy', 'lightning_logs', 'snapshot_0.npy', 'model.py', 'loss_calls.txt', 'model_summary.txt']\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```python\n","# Print out the first few lines of the model \n","print(\"Model graph:\")\n","```\n","\n","```shell\n","!sed -n -e 1,15p $ARTIFACTS_PATH/model_graph.py\n","!echo \"        ...\"\n","!sed -n -e 58,68p $ARTIFACTS_PATH/model_graph.py\n","!echo \"        ...\"\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Model graph:\n","\n","import torch, onnx2torch\n","from torch import tensor\n","\n","class Model(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        setattr(self,'Conv', torch.nn.modules.conv.Conv2d(**{'in_channels':3,'out_channels':64,'kernel_size':(7, 7),'stride':(2, 2),'padding':(3, 3),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Relu', torch.nn.modules.activation.ReLU(**{'inplace':False}))\n","        setattr(self,'MaxPool', torch.nn.modules.pooling.MaxPool2d(**{'kernel_size':[3, 3],'stride':[2, 2],'padding':[1, 1],'dilation':[1, 1],'return_indices':False,'ceil_mode':False}))\n","        setattr(self,'Conv_1', torch.nn.modules.conv.Conv2d(**{'in_channels':64,'out_channels':64,'kernel_size':(3, 3),'stride':(1, 1),'padding':(1, 1),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Relu_1', torch.nn.modules.activation.ReLU(**{'inplace':False}))\n","        setattr(self,'Conv_2', torch.nn.modules.conv.Conv2d(**{'in_channels':64,'out_channels':64,'kernel_size':(3, 3),'stride':(1, 1),'padding':(1, 1),'dilation':(1, 1),'groups':1,'padding_mode':'zeros'}))\n","        setattr(self,'Add', onnx2torch.node_converters.binary_math_operations.OnnxBinaryMathOperation(**{'operation_type':'Add','broadcast':None,'axis':None}))\n","        ...\n","\n","    def forward(self, input_1):\n","        conv = self.Conv(input_1);  input_1 = None\n","        relu = self.Relu(conv);  conv = None\n","        max_pool = self.MaxPool(relu);  relu = None\n","        conv_1 = self.Conv_1(max_pool)\n","        relu_1 = self.Relu_1(conv_1);  conv_1 = None\n","        conv_2 = self.Conv_2(relu_1);  relu_1 = None\n","        add = self.Add(conv_2, max_pool);  conv_2 = max_pool = None\n","        relu_2 = self.Relu_2(add);  add = None\n","        conv_3 = self.Conv_3(relu_2)\n","        ...\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```python\n","# Print the first lines of the data metafeatures\n","print(\"Data metafeatures:\")\n","```\n","\n","```shell\n","!head -20 $ARTIFACTS_PATH/stats_rep\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Data metafeatures:\n","{\n","  \"dataset_size\": 60032,\n","  \"num_sample\": 1000,\n","  \"batch_element_0\": {\n","    \"raw\": {\n","      \"feature_shape\": [\n","        960,\n","        3,\n","        28,\n","        28\n","      ],\n","      \"stats\": {\n","        \"kmeans\": {\n","          \"2\": {\n","            \"inertia\": \"155588.50824155417\",\n","            \"silhouette_score\": \"0.19201575\",\n","            \"calinski_harabasz_score\": \"248.3331975601121\",\n","            \"davies_bouldin_score\": \"1.9090644142081366\",\n","            \"time_taken\": \"0.6537415981292725\"\n","          },\n","```"]},{"cell_type":"markdown","metadata":{},"source":["We can build the model from the cached `model_graph.Model` class and confirm that we can pass an input through it.\n","Note that this model's weights will be uninitialized."]},{"cell_type":"markdown","metadata":{},"source":["```python\n","# Rebuilding from the object\n","import model_graph\n","rebuilt_model = model_graph.Model()\n","\n","# Set models to inference\n","modlee_model.eval(); rebuilt_model.eval()\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Next, pass an input from the train dataloader through the rebuilt network and check that the output shape is equal to the original data."]},{"cell_type":"markdown","metadata":{},"source":["```python\n","# Get a batch from the training loader\n","x, y = next(iter(train_dataloader))\n","with torch.no_grad():\n","    y_original = modlee_model(x)\n","    y_rebuilt = rebuilt_model(x)\n","assert y_original.shape == y_rebuilt.shape\n","\n","print(f\"Original input and output shapes: {x.shape}, {y_original.shape}\")\n","print(f\"Output shape from module-rebuilt model: {y_rebuilt.shape}\")\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Alternatively, to load the model from the last checkpoint, we can load it directly from the cached `model.pth`."]},{"cell_type":"markdown","metadata":{},"source":["```python\n","# Reloading from the checkpoint\n","reloaded_model = torch.load(os.path.join(artifacts_path, 'model', 'data','model.pth'))\n","y_reloaded = reloaded_model(x)\n","assert y_original.shape == y_reloaded.shape\n","print(f\"Output shape from checkpoint-reloaded model: {y_reloaded.shape}\")\n","```"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Original input and output shapes: torch.Size([64, 3, 28, 28]), torch.Size([64, 10])\n","Output shape from module-rebuilt model: torch.Size([64, 10])\n","Output shape from checkpoint-reloaded model: torch.Size([64, 10])\n","```"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":2}
