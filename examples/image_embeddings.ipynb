{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/mansiagr4/gifs/raw/main/new_small_logo.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Image Embeddings With Tabular Classification Model\n",
    "\n",
    "In this example, we will walk through the process of building an image classifier using embeddings from a pre-trained `ResNet` model combined with a custom Multi-Layer Perceptron (MLP). We'll train the MLP on embeddings extracted from `ResNet`, which will handle feature extraction from the `CIFAR-10` dataset.\n",
    "\n",
    "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/modlee/modlee-image-embeddings)\n",
    "\n",
    "\n",
    "First, we import the necessary libraries from `PyTorch` and `Torchvision`.\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import cv2\n",
    "from torchvision import datasets, models, transforms\n",
    "import modlee\n",
    "import lightning.pytorch as pl\n",
    "from torch.utils.data import DataLoader, Subset, random_split, TensorDataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "```\n",
    "Now we will set our Modlee API key and initialize the Modlee package.\n",
    "Make sure that you have a Modlee account and an API key [from the dashboard](https://www.dashboard.modlee.ai/).\n",
    "Replace `replace-with-your-api-key` with your API key.\n",
    "\n",
    "```python\n",
    "os.environ['MODLEE_API_KEY'] = \"replace-with-your-api-key\"\n",
    "modlee.init(api_key=os.environ['MODLEE_API_KEY'])\n",
    "```\n",
    "Next, we define a sequence of transformations to preprocess the images. Images are resized to (224, 224) to match the input size required by the pre-trained `ResNet-50` model.\n",
    "\n",
    "```python\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "```\n",
    "\n",
    "We load the `CIFAR-10` dataset and create a subset of 1,000 images for faster experimentation. We then split it into training (80%) and validation (20%) datasets using `random_split`.\n",
    "\n",
    "```python\n",
    "# Load the CIFAR-10 dataset with the specified transformations\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create a subset of the dataset for quicker experimentation\n",
    "subset_size = 1000\n",
    "indices = list(range(subset_size))\n",
    "subset_dataset = Subset(train_dataset, indices)\n",
    "\n",
    "# Split the subset into training and validation sets\n",
    "train_size = int(0.8 * len(subset_dataset))\n",
    "val_size = len(subset_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(subset_dataset, [train_size, val_size])\n",
    "```\n",
    "\n",
    "We define `DataLoaders` for both the training and validation datasets, setting the batch size to 64. \n",
    "\n",
    "```python\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "```\n",
    "\n",
    "We load a pre-trained `ResNet-50` model from `torchvision.models` and modify it to output image embeddings instead of predictions by removing its fully connected (classification) layer.\n",
    "\n",
    "```python\n",
    "# Load a pre-trained ResNet-50 model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "# Remove the final fully connected layer to get feature embeddings\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1]).to(device)\n",
    "```\n",
    "\n",
    "We define a custom Multi-Layer Perceptron (MLP) classifier using fully connected layers, batch normalization, and dropout for regularization. \n",
    "\n",
    "```python\n",
    "class MLP(modlee.model.TabularClassificationModleeModel):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  \n",
    "\n",
    "    def training_step(self, batch):\n",
    "        embeddings, labels = batch\n",
    "        logits = self.forward(embeddings)  \n",
    "        loss = self.loss_fn(logits, labels)  \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        embeddings, labels = batch\n",
    "        logits = self.forward(embeddings)  \n",
    "        loss = self.loss_fn(logits, labels)  \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "```\n",
    "We  initialize our MLP model by passing the `input_size` of the embeddings produced by `ResNet-50` and the `num_classes` for classification. This model will map the 2048-dimensional embeddings to the 10 class labels.\n",
    "\n",
    "```python\n",
    "# Define the number of output classes for the classification task\n",
    "num_classes = 10\n",
    "\n",
    "# Initialize the MLP model with the specified input size and number of classes\n",
    "mlp_image = MLP(input_size=2048, num_classes=num_classes).to(device)\n",
    "```\n",
    "We pass the raw images through the pre-trained `ResNet-50` model, which extracts high-level features from each image.\n",
    "\n",
    "```python\n",
    "# Precompute embeddings using ResNet-50\n",
    "def precompute_embeddings(dataloader, model, device):\n",
    "    model.eval()\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            embeddings = model(images).squeeze()  # Extract features using ResNet\n",
    "            embeddings_list.append(embeddings)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    return torch.cat(embeddings_list), torch.cat(labels_list)\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "# Precompute embeddings for training and validation datasets\n",
    "print(\"Precomputing embeddings for training and validation data\")\n",
    "train_embeddings, train_labels = precompute_embeddings(train_loader, resnet, device)\n",
    "val_embeddings, val_labels = precompute_embeddings(val_loader, resnet, device)\n",
    "\n",
    "# Create TensorDataset for precomputed embeddings and labels\n",
    "train_embedding_dataset = TensorDataset(train_embeddings, train_labels)\n",
    "val_embedding_dataset = TensorDataset(val_embeddings, val_labels)\n",
    "\n",
    "# Create DataLoaders for the precomputed embeddings\n",
    "train_embedding_loader = DataLoader(train_embedding_dataset, batch_size=64, shuffle=True)\n",
    "val_embedding_loader = DataLoader(val_embedding_dataset, batch_size=64, shuffle=False)\n",
    "```\n",
    "We define the `train_model` function, which handles the training loop. We also evaluate the model's performance on the validation set.\n",
    "\n",
    "```python\n",
    "def train_model(modlee_model, train_dataloader, val_dataloader, num_epochs=1):\n",
    "    with modlee.start_run() as run:\n",
    "        # Create a PyTorch Lightning trainer \n",
    "        trainer = pl.Trainer(max_epochs=num_epochs)\n",
    "\n",
    "        # Train the model using the training and validation data loaders\n",
    "        trainer.fit(\n",
    "            model=modlee_model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader\n",
    "        )\n",
    "\n",
    "# Train and evaluate the model\n",
    "train_model(mlp_image, train_embedding_loader, val_embedding_loader, num_epochs=5)\n",
    "```\n",
    "\n",
    "Finally, we can view the saved assets from training. With Modlee, your training assets are automatically saved, preserving valuable insights for future reference and collaboration.\n",
    "\n",
    "```python\n",
    "last_run_path = modlee.last_run_path()\n",
    "print(f\"Run path: {last_run_path}\")\n",
    "artifacts_path = os.path.join(last_run_path, 'artifacts')\n",
    "artifacts = sorted(os.listdir(artifacts_path))\n",
    "print(f\"Saved artifacts: {artifacts}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
