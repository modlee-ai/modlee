{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/mansiagr4/gifs/raw/main/new_small_logo.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation\n",
    "\n",
    "In this tutorial, we will build an image segmentation model using the `Pascal VOC 2012` dataset, leveraging the Modlee package for experimentation.\n",
    "\n",
    "Steps Overview:\n",
    "\n",
    "1. Setup and Initialization\n",
    "2. Dataset Preparation\n",
    "3. Model Definition\n",
    "4. Model Training\n",
    "5. Results and Artifacts Retrieval\n",
    "\n",
    "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/modlee/modle-image-segmentation)\n",
    "\n",
    "First, we will import the the necessary libraries and set up the environment. \n",
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import lightning.pytorch as pl\n",
    "import modlee\n",
    "import os\n",
    "```\n",
    "Now, we will set up the `modlee` API key and initialize the `modlee` package. You can access your `modlee` API key [from the dashboard](https://www.dashboard.modlee.ai/).\n",
    "\n",
    "Replace `replace-with-your-api-key` with your API key.\n",
    "```python\n",
    "modlee.init(api_key=\"replace-with-your-api-key\")\n",
    "```\n",
    "Now, we will define transformations for the input images and segmentation masks. Both will be resized to 256x256 pixels for standardization.\n",
    "\n",
    "```python\n",
    "# Define the transformations applied to the images and masks\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256, 256)),  # Resize all images to 256x256\n",
    "    torchvision.transforms.ToTensor()           # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "target_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256, 256)),  # Resize the masks to match the image size\n",
    "    torchvision.transforms.ToTensor()           # Convert masks to PyTorch tensors\n",
    "])\n",
    "```\n",
    "\n",
    "Next, we will load the `Pascal VOC 2012` dataset using the `VOCSegmentation` class. \n",
    "\n",
    "```python\n",
    "# Prepare the VOC 2012 dataset for segmentation tasks\n",
    "train_dataset = torchvision.datasets.VOCSegmentation(\n",
    "    root='./data', year='2012', image_set='train', download=True, \n",
    "    transform=transform, #`transform` applies to input images\n",
    "    target_transform=target_transform #`target_transform` applies to segmentation masks\n",
    ")\n",
    "\n",
    "val_dataset = torchvision.datasets.VOCSegmentation(\n",
    "    root='./data', year='2012', image_set='val', download=True, \n",
    "    transform=transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "```\n",
    "\n",
    "To accelerate the training process, we will create smaller subsets of the training and validation datasets. We will define a subset of 500 samples for training and 100 samples for validation.\n",
    "\n",
    "```python\n",
    "# Use only a subset of the training and validation data to speed up training\n",
    "train_indices = torch.arange(500)  # Subset of 500 samples from training data\n",
    "val_indices = torch.arange(100)    # Subset of 100 samples from validation data\n",
    "\n",
    "# Create subsets of the datasets based on the indices we defined above\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(val_dataset, val_indices)\n",
    "```\n",
    "\n",
    "We will now create `DataLoader` instances for both the training and validation subsets. \n",
    "\n",
    "```python\n",
    "# Create DataLoader for both training and validation data\n",
    "train_dataloader = DataLoader(train_subset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_subset, batch_size=8, shuffle=False)\n",
    "```\n",
    "\n",
    "Next, we will create the image segmentation model within Modlee's framework, featuring an encoder for extracting relevant features and a decoder for generating the segmentation mask. \n",
    "\n",
    "```python\n",
    "# Define the image segmentation model\n",
    "class ImageSegmentation(modlee.model.ImageSegmentationModleeModel):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        # Encoder: A small convolutional neural network that processes the input image\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),  # Activation function to introduce non-linearity\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),  # Another layer of convolution and activation\n",
    "        )\n",
    "        # Decoder: Upsampling to match the input size, producing a segmentation mask\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),  # Upsampling\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 21, kernel_size=1),  \n",
    "        )\n",
    "        # Loss function: Cross-entropy loss, commonly used for segmentation tasks\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Forward pass: Process the input through the encoder and decoder\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)  # Apply encoder to input image\n",
    "        decoded = self.decoder(encoded)  # Apply decoder to the encoded output\n",
    "        output_size = x.shape[2:]  # Get the original image size to ensure the output matches it\n",
    "        decoded = torch.nn.functional.interpolate(decoded, size=output_size, mode='bilinear', align_corners=False)\n",
    "        return decoded  # Return the final segmentation mask\n",
    "\n",
    "    # Training step: Called during each iteration of training\n",
    "    def training_step(self, batch):\n",
    "        x, y = batch  # Unpack the input images (x) and ground truth masks (y)\n",
    "        logits = self.forward(x)  # Forward pass through the model\n",
    "        loss = self.loss_fn(logits, y.squeeze(1).long())  # Compute the loss\n",
    "        return loss  # Return the loss value for this batch\n",
    "\n",
    "    # Validation step: Similar to training step but used for validation\n",
    "    def validation_step(self, batch):\n",
    "        x, y = batch  # Unpack the input images (x) and ground truth masks (y)\n",
    "        logits = self.forward(x)  # Forward pass through the model\n",
    "        loss = self.loss_fn(logits, y.squeeze(1).long())  # Compute the validation loss\n",
    "        return loss  # Return the validation loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "model = ImageSegmentation(in_channels=3)  # Initialize the model\n",
    "```\n",
    "\n",
    "Now, we can train and evaluate our model using `PyTorch Lightning` for one epoch.\n",
    "\n",
    "```python\n",
    "# Train the model using Modlee and PyTorch Lightning\n",
    "with modlee.start_run() as run:\n",
    "    # Set `max_epochs=1` to train for 1 epoch\n",
    "    trainer = pl.Trainer(max_epochs=1)\n",
    "    \n",
    "    # Fit the model on the training and validation data\n",
    "    trainer.fit(model=model, \n",
    "                train_dataloaders=train_dataloader, \n",
    "                val_dataloaders=val_dataloader)\n",
    "```\n",
    "\n",
    "After training, we will examine the artifacts saved by Modlee, such as the model graph and various statistics. Modlee automatically preserves your training assets, ensuring that valuable insights are available for future reference and collaboration.\n",
    "\n",
    "```python\n",
    "# Retrieve the path where Modlee saved the results of this run\n",
    "last_run_path = modlee.last_run_path()\n",
    "print(f\"Run path: {last_run_path}\")\n",
    "artifacts_path = os.path.join(last_run_path, 'artifacts')\n",
    "artifacts = sorted(os.listdir(artifacts_path))\n",
    "print(f\"Saved artifacts: {artifacts}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
