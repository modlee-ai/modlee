{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Documentation"]},{"cell_type":"markdown","metadata":{},"source":["In this exercise, you will implement the `modlee` package to document an image segmentation experiment with a pretrained model from `torchvision`."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Boilerplate imports\n","import lightning.pytorch as pl\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import transforms\n","from torchvision.transforms.functional import InterpolationMode\n","import os\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context"]},{"cell_type":"markdown","metadata":{},"source":["In the next cell, import `modlee` and initialize with an API key."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Your code goes here. Import the modlee package and initialize with your API key.\n","import modlee\n","modlee.init(api_key=\"modleemichael\")"]},{"cell_type":"markdown","metadata":{},"source":["Load the training data."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using downloaded and verified file: ./datasets/VOCtrainval_06-Nov-2007.tar\n","Extracting ./datasets/VOCtrainval_06-Nov-2007.tar to ./datasets/\n","Using downloaded and verified file: ./datasets/VOCtrainval_06-Nov-2007.tar\n","Extracting ./datasets/VOCtrainval_06-Nov-2007.tar to ./datasets/\n"]}],"source":["imagenet_mean = [0.485, 0.456, 0.406]  # mean of the imagenet dataset for normalizing\n","imagenet_std = [0.229, 0.224, 0.225]  # std of the imagenet dataset for normalizing\n","\n","def replace_tensor_value_(tensor, a, b):\n","    tensor[tensor == a] = b\n","    return tensor\n","\n","input_resize = transforms.Resize((224, 224))\n","input_transform = transforms.Compose(\n","    [\n","        input_resize,\n","        transforms.ToTensor(),\n","        transforms.Normalize(imagenet_mean, imagenet_std),\n","    ]\n",")\n","\n","target_resize = transforms.Resize((224, 224), interpolation=InterpolationMode.NEAREST)\n","target_transform = transforms.Compose(\n","    [\n","        target_resize,\n","        transforms.PILToTensor(),\n","        transforms.Lambda(lambda x: replace_tensor_value_(x.squeeze(0).long(), 255, 21)),\n","    ]\n",")\n","\n","# Creating the dataset\n","train_dataset = torchvision.datasets.VOCSegmentation(\n","    './datasets/',\n","    year='2007',\n","    download=True,\n","    image_set='val',\n","    transform=input_transform,\n","    target_transform=target_transform,\n",")\n","val_dataset = torchvision.datasets.VOCSegmentation(\n","    './datasets/',\n","    year='2007',\n","    download=True,\n","    image_set='val',\n","    transform=input_transform,\n","    target_transform=target_transform,\n",")\n","\n","BATCH_SIZE = 16\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["Create the image segmentation model using a [pretrained fully connected network](https://pytorch.org/vision/main/models/generated/torchvision.models.segmentation.fcn_resnet50.html#torchvision.models.segmentation.fcn_resnet50). "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["model = torchvision.models.segmentation.fcn_resnet50(num_classes=22)"]},{"cell_type":"markdown","metadata":{},"source":["In the next cell, wrap the model defined above in a `modlee.model.ModleeModel` object.\n","At minimum, you must define the `__init__()`, `forward()`, `training_step()`, and `configure_optimizers()` functions.\n","Refer to the [Lightning documentation](https://lightning.ai/docs/pytorch/stable/starter/introduction.html) for a refresher."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class ModleeFCN(modlee.model.ModleeModel):\n","    def __init__(self):                # Fill out the constructor\n","        # Fill out the constructor\n","        super().__init__()\n","        self.model = model\n","        pass\n","    \n","    def forward(self, x):\n","        # Fill out the forward pass\n","        return self.model(x)\n","        pass\n","    \n","    def training_step(self, batch, batch_idx):\n","        # Fill out the training step\n","        x, y_target = batch\n","        \n","        y_pred = self(x)['out']\n","        # print(y_pred)\n","        loss = F.cross_entropy(y_pred, y_target)\n","        return loss\n","        pass\n","    \n","    def configure_optimizers(self):\n","        # Fill out the optimizer configuration\n","        return torch.optim.Adam(\n","            self.parameters(), \n","            lr=0.001,\n","        )\n","        pass\n","    \n","model = ModleeFCN()"]},{"cell_type":"markdown","metadata":{},"source":["In the next cell, start training within a `modlee.start_run()` [context manager](https://realpython.com/python-with-statement/).\n","Refer to [`mlflow`'s implementation](https://mlflow.org/docs/latest/python_api/mlflow.html) as a refresher. "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type | Params\n","-------------------------------\n","0 | model | FCN  | 33.0 M\n","-------------------------------\n","33.0 M    Trainable params\n","0         Non-trainable params\n","33.0 M    Total params\n","131.830   Total estimated model params size (MB)\n","/opt/conda/envs/modlee/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","  rank_zero_warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c996b2b46674d538eb652a56a7089fb","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:root:Cannot log output shape, could not pass batch through network\n","/opt/conda/envs/modlee/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:359: UserWarning: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['loss', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n","  warning_cache.warn(m)\n"]}],"source":["# Your code goes here. Star training within a modlee.start_run() context manager\n","with modlee.start_run() as run:\n","    trainer = pl.Trainer(max_epochs=1)\n","    trainer.fit(\n","        model=model,\n","        train_dataloaders=train_loader,\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["Rebuild the saved model.\n","First, determine the path to the most recent run."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['model_graph.py', 'model_graph.txt', 'model_size', 'model', 'cached_vars', 'stats_rep', 'snapshot_1.npy', 'snapshot_0.npy', 'model.py', 'loss_calls.txt', 'model_summary.txt']\n","/home/ubuntu/projects/modlee_pypi/examples/mlruns/0/c3e9164a46da44d287da0732dce373ef/artifacts/model_graph.py\n"]}],"source":["last_run_path = modlee.last_run_path()\n","artifacts_path = os.path.join(last_run_path, 'artifacts')\n","print(os.listdir(artifacts_path))\n","print(os.path.join(artifacts_path,'model_graph.py'))"]},{"cell_type":"markdown","metadata":{},"source":["Next, import the model from the assets saved in the `artifacts/` directory."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["exercise_dir = os.path.abspath(os.getcwd())\n","os.chdir(artifacts_path)\n","\n","import model_graph\n","rebuilt_model = model_graph.Model()\n","rebuilt_model.eval()\n","\n","os.chdir(exercise_dir)\n","# Pass an input through the model\n","x, _ = next(iter(train_loader))\n","with torch.no_grad():\n","    y_rebuilt = rebuilt_model(x)"]},{"cell_type":"markdown","metadata":{},"source":["You've reached the end of the tutorial and can now implement `modlee` into your machine learning experiments.\n","Congratulations!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":2}
