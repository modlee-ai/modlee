<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Recommendation &mdash; modlee 0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=ca37922a" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=ca37922a" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=8dde47fa"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Documentation" href="document.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            modlee
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../README.html">modlee</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../py-modindex.html">Module Index</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="document.html">Documentation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Recommendation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#why-use-modlee">Why use Modlee?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#heres-how-it-works-in-pytorch">Here’s how it works in Pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lets-see-what-modlee-recommends-for-mnist-5-mins">Let’s see what Modlee recommends for MNIST … (~5 mins)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#you-prepare-your-dataset">1. You prepare your dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#modlee-recommends-a-model-close-to-your-target-solution-by-analyzing-your-dataset-and-solution-requirements">2. Modlee recommends a model close to your target solution by analyzing your dataset and solution requirements:</a></li>
<li class="toctree-l3"><a class="reference internal" href="#while-you-train-the-model-modlee-prepares-everything-you-need-for-your-convenience">3. While you train the model, Modlee prepares everything you need for your convenience:</a></li>
<li class="toctree-l3"><a class="reference internal" href="#modlee-auto-documents-your-experiment-locally-and-learns-from-non-sensitive-details">4. Modlee auto-documents your experiment locally and learns from non-sensitive details:</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">modlee</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Recommendation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notebooks/recommend.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="recommendation">
<h1>Recommendation<a class="headerlink" href="#recommendation" title="Link to this heading"></a></h1>
<section id="why-use-modlee">
<h2>Why use Modlee?<a class="headerlink" href="#why-use-modlee" title="Link to this heading"></a></h2>
<blockquote>
<div><p>At Modlee, we’re on a mission to ensure that everyone, everywhere has
access to top-tier machine learning solutions. We’re flipping the
script on how ML knowledge is shared, going beyond the realms of
Hugging Face, GitHub, and Papers with Code. Let’s be honest, we’re
all diving into similar models, right? Modlee is your turbocharged
ticket to effortlessly and swiftly connect with the ideal models for
your datasets, making your journey smoother, faster, and with minimal
effort on your part.</p>
</div></blockquote>
<p>[image]</p>
<p>We’re working towards this vision, and would love give you a sneak peak
of our technology. Some of the below features in this demo are at
different stages of development.</p>
</section>
<section id="heres-how-it-works-in-pytorch">
<h2>Here’s how it works in Pytorch<a class="headerlink" href="#heres-how-it-works-in-pytorch" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p>You prepare your dataset:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">training_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Modlee recommends a model close to your target solution by analyzing
your dataset and solution requirements:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">modlee_model</span> <span class="o">=</span> <span class="n">modlee</span><span class="o">.</span><span class="n">Recommender</span><span class="p">(</span><span class="n">training_dataloader</span><span class="p">,</span><span class="n">max_model_size_MB</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>While you train the model, Modlee prepares everything you need for
your convenience:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">modlee_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Modlee auto-documents your experiment locally and learns from
non-sensitive details to enhance ML model recommendations for the
community:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">modlee_model</span><span class="o">.</span><span class="n">train_documentation_locations</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="lets-see-what-modlee-recommends-for-mnist-5-mins">
<h2>Let’s see what Modlee recommends for MNIST … (~5 mins)<a class="headerlink" href="#lets-see-what-modlee-recommends-for-mnist-5-mins" title="Link to this heading"></a></h2>
<p>First let’s quickly install the modlee package, should take ~10 seconds.
Thanks for your patience!</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">SERVER_ENDPOINT</span> <span class="o">=</span> <span class="s1">&#39;http://ec2-3-84-155-233.compute-1.amazonaws.com:7070&#39;</span>

<span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="n">demo_header</span><span class="o">=</span><span class="s1">&#39;demos_demo04_&#39;</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;curl -o modlee-0.0.1.post6-py3-none-any.whl </span><span class="si">{</span><span class="n">SERVER_ENDPOINT</span><span class="si">}</span><span class="s1">/get_wheel/</span><span class="si">{</span><span class="n">demo_header</span><span class="si">}</span><span class="s1">modlee-0.0.1.post6-py3-none-any.whl -O&#39;</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;curl -o modleesurvey-0.0.1-py3-none-any.whl </span><span class="si">{</span><span class="n">SERVER_ENDPOINT</span><span class="si">}</span><span class="s1">/get_wheel/</span><span class="si">{</span><span class="n">demo_header</span><span class="si">}</span><span class="s1">modleesurvey-0.0.1-py3-none-any.whl -O  &gt; /dev/null 2&gt;&amp;1&#39;</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;curl -o onnx2torch-1.5.11-py3-none-any.whl </span><span class="si">{</span><span class="n">SERVER_ENDPOINT</span><span class="si">}</span><span class="s1">/get_wheel/</span><span class="si">{</span><span class="n">demo_header</span><span class="si">}</span><span class="s1">onnx2torch-1.5.11-py3-none-any.whl -O  &gt; /dev/null 2&gt;&amp;1&#39;</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">&quot;pip3 install -q &#39;modlee-0.0.1.post6-py3-none-any.whl&#39; &#39;modleesurvey-0.0.1-py3-none-any.whl&#39; &#39;onnx2torch-1.5.11-py3-none-any.whl&#39; torch==2.1.0 torchsummary==1.5.1 ipywidgets==7.7.1  &gt; /dev/null 2&gt;&amp;1&quot;</span><span class="p">)</span>
    <span class="c1"># os.system(&quot;pip3 install -q &#39;modleesurvey-0.0.1-py3-none-any.whl&#39; &#39;onnx2torch-1.5.11-py3-none-any.whl&#39; torchsummary==1.5.1 ipywidgets  &gt; /dev/null 2&gt;&amp;1&quot;)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">&quot;pip3 install -q onnx_graphsurgeon==0.3.27 --index-url https://pypi.ngc.nvidia.com  &gt; /dev/null 2&gt;&amp;1&quot;</span><span class="p">)</span>
<span class="n">setup</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">modlee</span>
<span class="n">modlee</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;community&quot;</span><span class="p">,</span><span class="n">run_dir</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="o">%</span> <span class="n">Total</span>    <span class="o">%</span> <span class="n">Received</span> <span class="o">%</span> <span class="n">Xferd</span>  <span class="n">Average</span> <span class="n">Speed</span>   <span class="n">Time</span>    <span class="n">Time</span>     <span class="n">Time</span>  <span class="n">Current</span>
                                 <span class="n">Dload</span>  <span class="n">Upload</span>   <span class="n">Total</span>   <span class="n">Spent</span>    <span class="n">Left</span>  <span class="n">Speed</span>
<span class="mi">100</span> <span class="mi">39751</span>  <span class="mi">100</span> <span class="mi">39751</span>    <span class="mi">0</span>     <span class="mi">0</span>  <span class="mi">7763</span><span class="n">k</span>      <span class="mi">0</span> <span class="o">--</span><span class="p">:</span><span class="o">--</span><span class="p">:</span><span class="o">--</span> <span class="o">--</span><span class="p">:</span><span class="o">--</span><span class="p">:</span><span class="o">--</span> <span class="o">--</span><span class="p">:</span><span class="o">--</span><span class="p">:</span><span class="o">--</span> <span class="mi">9704</span><span class="n">k</span>
</pre></div>
</div>
<section id="you-prepare-your-dataset">
<h3>1. You prepare your dataset<a class="headerlink" href="#you-prepare-your-dataset" title="Link to this heading"></a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">v2</span>
<span class="c1"># torch.set_default_device(&#39;cuda&#39;)</span>

<span class="n">transform_train</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))])</span>
<span class="c1"># transform_train = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),transforms.Resize((300,300))])</span>
<span class="k">def</span> <span class="nf">remap_255</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_unique</span><span class="o">=</span><span class="mi">21</span><span class="p">):</span>
    <span class="c1"># return x</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">x</span><span class="o">!=</span><span class="mi">255</span>
    <span class="c1"># mask = mask.to(&#39;cuda&#39;)</span>
    <span class="c1"># mask = mask.to(x.)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span>
    <span class="c1"># x = x.to(&#39;cuda&#39;)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># print(x.device, mask.device)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">n_unique</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">n_unique</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

<span class="n">transforms</span> <span class="o">=</span> <span class="n">v2</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="c1"># v2.ToImage(),</span>
        <span class="c1"># v2.RandomPhotometricDistort(p=1),</span>
        <span class="c1"># v2.RandomZoomOut(fill={tv_tensors.Image: (123, 117, 104), &quot;others&quot;: 0}),</span>
        <span class="c1"># v2.RandomIoUCrop(),</span>
        <span class="c1"># v2.RandomHorizontalFlip(p=1),</span>
        <span class="c1"># v2.SanitizeBoundingBoxes(),</span>
        <span class="n">v2</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">v2</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">300</span><span class="p">,</span><span class="mi">300</span><span class="p">)),</span>
        <span class="c1"># v2.ToDtype(torch.float32, scale=True),</span>
        <span class="c1"># v2.ToTensor(),</span>
        <span class="c1"># v2.Lambda(remap_255)</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform_train</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">VOCSegmentation</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">year</span><span class="o">=</span><span class="s1">&#39;2007&#39;</span><span class="p">,</span>
    <span class="n">image_set</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span>
    <span class="c1"># image_set=&#39;train&#39;,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span>
    <span class="n">target_transform</span><span class="o">=</span><span class="n">v2</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">v2</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">v2</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">300</span><span class="p">,</span><span class="mi">300</span><span class="p">)),</span> <span class="n">v2</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="n">remap_255</span><span class="p">)])</span>
    <span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">wrap_dataset_for_transforms_v2</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="p">)</span>

<span class="c1"># train_dataset.data.to(torch.device(&#39;cuda&#39;))</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>
    <span class="c1"># batch_size=64,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="c1"># num_workers=torch.cuda.device_count()*4</span>
    <span class="c1"># collate_fn=lambda batch: list(zip(*batch))</span>
    <span class="p">)</span>
<span class="c1"># train_dataloader.to(torch.device(&#39;cuda&#39;))</span>
</pre></div>
</div>
<pre class="literal-block">/home/ubuntu/projects/.venv/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform <cite>ToTensor()</cite> is deprecated and will be removed in a future release. Instead, please use <cite>v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])</cite>.
  warnings.warn(</pre>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Files</span> <span class="n">already</span> <span class="n">downloaded</span> <span class="ow">and</span> <span class="n">verified</span>
<span class="n">Using</span> <span class="n">downloaded</span> <span class="ow">and</span> <span class="n">verified</span> <span class="n">file</span><span class="p">:</span> <span class="o">./</span><span class="n">data</span><span class="o">/</span><span class="n">VOCtest_06</span><span class="o">-</span><span class="n">Nov</span><span class="o">-</span><span class="mf">2007.</span><span class="n">tar</span>
<span class="n">Extracting</span> <span class="o">./</span><span class="n">data</span><span class="o">/</span><span class="n">VOCtest_06</span><span class="o">-</span><span class="n">Nov</span><span class="o">-</span><span class="mf">2007.</span><span class="n">tar</span> <span class="n">to</span> <span class="o">./</span><span class="n">data</span>
</pre></div>
</div>
</section>
<section id="modlee-recommends-a-model-close-to-your-target-solution-by-analyzing-your-dataset-and-solution-requirements">
<h3>2. Modlee recommends a model close to your target solution by analyzing your dataset and solution requirements:<a class="headerlink" href="#modlee-recommends-a-model-close-to-your-target-solution-by-analyzing-your-dataset-and-solution-requirements" title="Link to this heading"></a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recommender</span> <span class="o">=</span> <span class="n">modlee</span><span class="o">.</span><span class="n">recommender</span><span class="o">.</span><span class="n">from_modality_task</span><span class="p">(</span>
    <span class="n">modality</span><span class="o">=</span><span class="s1">&#39;image&#39;</span><span class="p">,</span>
    <span class="c1"># task=&#39;classification&#39;,</span>
    <span class="n">task</span><span class="o">=</span><span class="s1">&#39;segmentation&#39;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">recommender</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
<span class="n">modlee_model</span> <span class="o">=</span> <span class="n">recommender</span><span class="o">.</span><span class="n">model</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">Modlee</span><span class="p">]</span> <span class="o">-&gt;</span> <span class="n">Just</span> <span class="n">a</span> <span class="n">moment</span><span class="p">,</span> <span class="n">analyzing</span> <span class="n">your</span> <span class="n">dataset</span> <span class="o">...</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recommender</span><span class="o">.</span><span class="n">get_model_details</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--- Modlee Recommended Model Details ---&gt;

[Modlee] -&gt; In case you want to take a deeper look, I saved the summary of my current model recommendation here:
                    file: ./modlee_model.txt

[Modlee] -&gt; I also saved the model as a python editable version (model def, train, val, optimizer):
                    file: ./modlee_model.py
            This is a great place to start your own model exploration!
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>cat<span class="w"> </span>./modlee_model.txt
<span class="o">!</span>cat<span class="w"> </span>./modlee_model.py
<span class="c1"># train_dataloader.dataset.to(&#39;cuda&#39;)</span>
<span class="n">b1</span><span class="p">,</span><span class="n">b2</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b1</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># modlee_model.to(torch.device(&#39;cuda&#39;))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">modlee_model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">b1</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># b1.to(modlee_model.device)</span>
<span class="c1"># modlee_model(b1.to(modlee_model.device)).shape</span>
<span class="n">modlee_model</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span>
   <span class="n">ir_version</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span>
   <span class="n">opset_import</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;&quot;</span> <span class="p">:</span> <span class="mi">17</span><span class="p">],</span>
   <span class="n">producer_name</span><span class="p">:</span> <span class="s2">&quot;pytorch&quot;</span><span class="p">,</span>
   <span class="n">producer_version</span><span class="p">:</span> <span class="s2">&quot;2.2.0&quot;</span>
<span class="o">&gt;</span>
<span class="n">main_graph</span> <span class="p">(</span><span class="nb">float</span><span class="p">[</span><span class="n">input_1_dynamic_axes_1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">300</span><span class="p">,</span><span class="mi">300</span><span class="p">]</span> <span class="n">input_1</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">21</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">model_classifier_model_4_weight</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">21</span><span class="p">]</span> <span class="n">model_classifier_model_4_bias</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">]</span> <span class="n">onnx__Conv_525</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">]</span> <span class="n">onnx__Conv_526</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_528</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">]</span> <span class="n">onnx__Conv_529</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_531</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">]</span> <span class="n">onnx__Conv_532</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_534</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_535</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_537</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_538</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_540</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">]</span> <span class="n">onnx__Conv_541</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_543</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">]</span> <span class="n">onnx__Conv_544</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_546</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_547</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_549</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">]</span> <span class="n">onnx__Conv_550</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_552</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">64</span><span class="p">]</span> <span class="n">onnx__Conv_553</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_555</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_556</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_558</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">]</span> <span class="n">onnx__Conv_559</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_561</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">]</span> <span class="n">onnx__Conv_562</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_564</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_565</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_567</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_568</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_570</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">]</span> <span class="n">onnx__Conv_571</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_573</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">]</span> <span class="n">onnx__Conv_574</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_576</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_577</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_579</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">]</span> <span class="n">onnx__Conv_580</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_582</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">]</span> <span class="n">onnx__Conv_583</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_585</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_586</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_588</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">]</span> <span class="n">onnx__Conv_589</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_591</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">128</span><span class="p">]</span> <span class="n">onnx__Conv_592</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_594</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_595</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_597</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_598</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_600</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_601</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_603</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">]</span> <span class="n">onnx__Conv_604</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_606</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">]</span> <span class="n">onnx__Conv_607</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">1024</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_609</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_610</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_612</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_613</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_615</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">]</span> <span class="n">onnx__Conv_616</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">1024</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_618</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_619</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_621</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_622</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_624</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">]</span> <span class="n">onnx__Conv_625</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">1024</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_627</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_628</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_630</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_631</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_633</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">]</span> <span class="n">onnx__Conv_634</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">1024</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_636</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_637</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_639</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_640</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_642</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">]</span> <span class="n">onnx__Conv_643</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">1024</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_645</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_646</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_648</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="n">onnx__Conv_649</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_651</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">1024</span><span class="p">]</span> <span class="n">onnx__Conv_652</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">1024</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_654</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_655</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_657</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_658</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">2048</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_660</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">2048</span><span class="p">]</span> <span class="n">onnx__Conv_661</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">2048</span><span class="p">,</span><span class="mi">1024</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_663</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">2048</span><span class="p">]</span> <span class="n">onnx__Conv_664</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">2048</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_666</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_667</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_669</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_670</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">2048</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_672</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">2048</span><span class="p">]</span> <span class="n">onnx__Conv_673</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">2048</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_675</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_676</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_678</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_679</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">2048</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">onnx__Conv_681</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">2048</span><span class="p">]</span> <span class="n">onnx__Conv_682</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">2048</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="n">onnx__Conv_684</span><span class="p">,</span> <span class="nb">float</span><span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="n">onnx__Conv_685</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="nb">float</span><span class="p">[</span><span class="n">resize_output_0000_dynamic_axes_1</span><span class="p">,</span><span class="n">Resizeresize_output_0000_dim_1</span><span class="p">,</span><span class="n">Resizeresize_output_0000_dim_2</span><span class="p">,</span><span class="n">Resizeresize_output_0000_dim_3</span><span class="p">]</span> <span class="n">output_var</span><span class="p">)</span> <span class="p">{</span>
   <span class="n">shape_output_0000</span> <span class="o">=</span> <span class="n">Shape</span> <span class="p">(</span><span class="n">input_1</span><span class="p">)</span>
   <span class="n">constant_output_0000</span> <span class="o">=</span> <span class="n">Constant</span> <span class="o">&lt;</span><span class="n">value</span> <span class="o">=</span> <span class="n">int64</span> <span class="p">{</span><span class="mi">2</span><span class="p">}</span><span class="o">&gt;</span> <span class="p">()</span>
   <span class="n">gather_output_0000</span> <span class="o">=</span> <span class="n">Gather</span> <span class="o">&lt;</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">shape_output_0000</span><span class="p">,</span> <span class="n">constant_output_0000</span><span class="p">)</span>
   <span class="n">shape_output_0001</span> <span class="o">=</span> <span class="n">Shape</span> <span class="p">(</span><span class="n">input_1</span><span class="p">)</span>
   <span class="n">constant_output_0001</span> <span class="o">=</span> <span class="n">Constant</span> <span class="o">&lt;</span><span class="n">value</span> <span class="o">=</span> <span class="n">int64</span> <span class="p">{</span><span class="mi">3</span><span class="p">}</span><span class="o">&gt;</span> <span class="p">()</span>
   <span class="n">gather_output_0001</span> <span class="o">=</span> <span class="n">Gather</span> <span class="o">&lt;</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">shape_output_0001</span><span class="p">,</span> <span class="n">constant_output_0001</span><span class="p">)</span>
   <span class="n">conv_output_0000</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">input_1</span><span class="p">,</span> <span class="n">onnx__Conv_525</span><span class="p">,</span> <span class="n">onnx__Conv_526</span><span class="p">)</span>
   <span class="n">relu_output_0000</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0000</span><span class="p">)</span>
   <span class="n">maxpool_output_0000</span> <span class="o">=</span> <span class="n">MaxPool</span> <span class="o">&lt;</span><span class="n">ceil_mode</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0000</span><span class="p">)</span>
   <span class="n">conv_output_0001</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">maxpool_output_0000</span><span class="p">,</span> <span class="n">onnx__Conv_528</span><span class="p">,</span> <span class="n">onnx__Conv_529</span><span class="p">)</span>
   <span class="n">relu_output_0001</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0001</span><span class="p">)</span>
   <span class="n">conv_output_0002</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0001</span><span class="p">,</span> <span class="n">onnx__Conv_531</span><span class="p">,</span> <span class="n">onnx__Conv_532</span><span class="p">)</span>
   <span class="n">relu_output_0002</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0002</span><span class="p">)</span>
   <span class="n">conv_output_0003</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0002</span><span class="p">,</span> <span class="n">onnx__Conv_534</span><span class="p">,</span> <span class="n">onnx__Conv_535</span><span class="p">)</span>
   <span class="n">conv_output_0004</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">maxpool_output_0000</span><span class="p">,</span> <span class="n">onnx__Conv_537</span><span class="p">,</span> <span class="n">onnx__Conv_538</span><span class="p">)</span>
   <span class="n">add_output_0000</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0003</span><span class="p">,</span> <span class="n">conv_output_0004</span><span class="p">)</span>
   <span class="n">relu_output_0003</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0000</span><span class="p">)</span>
   <span class="n">conv_output_0005</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0003</span><span class="p">,</span> <span class="n">onnx__Conv_540</span><span class="p">,</span> <span class="n">onnx__Conv_541</span><span class="p">)</span>
   <span class="n">relu_output_0004</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0005</span><span class="p">)</span>
   <span class="n">conv_output_0006</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0004</span><span class="p">,</span> <span class="n">onnx__Conv_543</span><span class="p">,</span> <span class="n">onnx__Conv_544</span><span class="p">)</span>
   <span class="n">relu_output_0005</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0006</span><span class="p">)</span>
   <span class="n">conv_output_0007</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0005</span><span class="p">,</span> <span class="n">onnx__Conv_546</span><span class="p">,</span> <span class="n">onnx__Conv_547</span><span class="p">)</span>
   <span class="n">add_output_0001</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0007</span><span class="p">,</span> <span class="n">relu_output_0003</span><span class="p">)</span>
   <span class="n">relu_output_0006</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0001</span><span class="p">)</span>
   <span class="n">conv_output_0008</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0006</span><span class="p">,</span> <span class="n">onnx__Conv_549</span><span class="p">,</span> <span class="n">onnx__Conv_550</span><span class="p">)</span>
   <span class="n">relu_output_0007</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0008</span><span class="p">)</span>
   <span class="n">conv_output_0009</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0007</span><span class="p">,</span> <span class="n">onnx__Conv_552</span><span class="p">,</span> <span class="n">onnx__Conv_553</span><span class="p">)</span>
   <span class="n">relu_output_0008</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0009</span><span class="p">)</span>
   <span class="n">conv_output_0010</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0008</span><span class="p">,</span> <span class="n">onnx__Conv_555</span><span class="p">,</span> <span class="n">onnx__Conv_556</span><span class="p">)</span>
   <span class="n">add_output_0002</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0010</span><span class="p">,</span> <span class="n">relu_output_0006</span><span class="p">)</span>
   <span class="n">relu_output_0009</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0002</span><span class="p">)</span>
   <span class="n">conv_output_0011</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0009</span><span class="p">,</span> <span class="n">onnx__Conv_558</span><span class="p">,</span> <span class="n">onnx__Conv_559</span><span class="p">)</span>
   <span class="n">relu_output_0010</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0011</span><span class="p">)</span>
   <span class="n">conv_output_0012</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0010</span><span class="p">,</span> <span class="n">onnx__Conv_561</span><span class="p">,</span> <span class="n">onnx__Conv_562</span><span class="p">)</span>
   <span class="n">relu_output_0011</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0012</span><span class="p">)</span>
   <span class="n">conv_output_0013</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0011</span><span class="p">,</span> <span class="n">onnx__Conv_564</span><span class="p">,</span> <span class="n">onnx__Conv_565</span><span class="p">)</span>
   <span class="n">conv_output_0014</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0009</span><span class="p">,</span> <span class="n">onnx__Conv_567</span><span class="p">,</span> <span class="n">onnx__Conv_568</span><span class="p">)</span>
   <span class="n">add_output_0003</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0013</span><span class="p">,</span> <span class="n">conv_output_0014</span><span class="p">)</span>
   <span class="n">relu_output_0012</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0003</span><span class="p">)</span>
   <span class="n">conv_output_0015</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0012</span><span class="p">,</span> <span class="n">onnx__Conv_570</span><span class="p">,</span> <span class="n">onnx__Conv_571</span><span class="p">)</span>
   <span class="n">relu_output_0013</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0015</span><span class="p">)</span>
   <span class="n">conv_output_0016</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0013</span><span class="p">,</span> <span class="n">onnx__Conv_573</span><span class="p">,</span> <span class="n">onnx__Conv_574</span><span class="p">)</span>
   <span class="n">relu_output_0014</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0016</span><span class="p">)</span>
   <span class="n">conv_output_0017</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0014</span><span class="p">,</span> <span class="n">onnx__Conv_576</span><span class="p">,</span> <span class="n">onnx__Conv_577</span><span class="p">)</span>
   <span class="n">add_output_0004</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0017</span><span class="p">,</span> <span class="n">relu_output_0012</span><span class="p">)</span>
   <span class="n">relu_output_0015</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0004</span><span class="p">)</span>
   <span class="n">conv_output_0018</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0015</span><span class="p">,</span> <span class="n">onnx__Conv_579</span><span class="p">,</span> <span class="n">onnx__Conv_580</span><span class="p">)</span>
   <span class="n">relu_output_0016</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0018</span><span class="p">)</span>
   <span class="n">conv_output_0019</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0016</span><span class="p">,</span> <span class="n">onnx__Conv_582</span><span class="p">,</span> <span class="n">onnx__Conv_583</span><span class="p">)</span>
   <span class="n">relu_output_0017</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0019</span><span class="p">)</span>
   <span class="n">conv_output_0020</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0017</span><span class="p">,</span> <span class="n">onnx__Conv_585</span><span class="p">,</span> <span class="n">onnx__Conv_586</span><span class="p">)</span>
   <span class="n">add_output_0005</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0020</span><span class="p">,</span> <span class="n">relu_output_0015</span><span class="p">)</span>
   <span class="n">relu_output_0018</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0005</span><span class="p">)</span>
   <span class="n">conv_output_0021</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0018</span><span class="p">,</span> <span class="n">onnx__Conv_588</span><span class="p">,</span> <span class="n">onnx__Conv_589</span><span class="p">)</span>
   <span class="n">relu_output_0019</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0021</span><span class="p">)</span>
   <span class="n">conv_output_0022</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0019</span><span class="p">,</span> <span class="n">onnx__Conv_591</span><span class="p">,</span> <span class="n">onnx__Conv_592</span><span class="p">)</span>
   <span class="n">relu_output_0020</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0022</span><span class="p">)</span>
   <span class="n">conv_output_0023</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0020</span><span class="p">,</span> <span class="n">onnx__Conv_594</span><span class="p">,</span> <span class="n">onnx__Conv_595</span><span class="p">)</span>
   <span class="n">add_output_0006</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0023</span><span class="p">,</span> <span class="n">relu_output_0018</span><span class="p">)</span>
   <span class="n">relu_output_0021</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0006</span><span class="p">)</span>
   <span class="n">conv_output_0024</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0021</span><span class="p">,</span> <span class="n">onnx__Conv_597</span><span class="p">,</span> <span class="n">onnx__Conv_598</span><span class="p">)</span>
   <span class="n">relu_output_0022</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0024</span><span class="p">)</span>
   <span class="n">conv_output_0025</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0022</span><span class="p">,</span> <span class="n">onnx__Conv_600</span><span class="p">,</span> <span class="n">onnx__Conv_601</span><span class="p">)</span>
   <span class="n">relu_output_0023</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0025</span><span class="p">)</span>
   <span class="n">conv_output_0026</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0023</span><span class="p">,</span> <span class="n">onnx__Conv_603</span><span class="p">,</span> <span class="n">onnx__Conv_604</span><span class="p">)</span>
   <span class="n">conv_output_0027</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0021</span><span class="p">,</span> <span class="n">onnx__Conv_606</span><span class="p">,</span> <span class="n">onnx__Conv_607</span><span class="p">)</span>
   <span class="n">add_output_0007</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0026</span><span class="p">,</span> <span class="n">conv_output_0027</span><span class="p">)</span>
   <span class="n">relu_output_0024</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0007</span><span class="p">)</span>
   <span class="n">conv_output_0028</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0024</span><span class="p">,</span> <span class="n">onnx__Conv_609</span><span class="p">,</span> <span class="n">onnx__Conv_610</span><span class="p">)</span>
   <span class="n">relu_output_0025</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0028</span><span class="p">)</span>
   <span class="n">conv_output_0029</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0025</span><span class="p">,</span> <span class="n">onnx__Conv_612</span><span class="p">,</span> <span class="n">onnx__Conv_613</span><span class="p">)</span>
   <span class="n">relu_output_0026</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0029</span><span class="p">)</span>
   <span class="n">conv_output_0030</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0026</span><span class="p">,</span> <span class="n">onnx__Conv_615</span><span class="p">,</span> <span class="n">onnx__Conv_616</span><span class="p">)</span>
   <span class="n">add_output_0008</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0030</span><span class="p">,</span> <span class="n">relu_output_0024</span><span class="p">)</span>
   <span class="n">relu_output_0027</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0008</span><span class="p">)</span>
   <span class="n">conv_output_0031</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0027</span><span class="p">,</span> <span class="n">onnx__Conv_618</span><span class="p">,</span> <span class="n">onnx__Conv_619</span><span class="p">)</span>
   <span class="n">relu_output_0028</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0031</span><span class="p">)</span>
   <span class="n">conv_output_0032</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0028</span><span class="p">,</span> <span class="n">onnx__Conv_621</span><span class="p">,</span> <span class="n">onnx__Conv_622</span><span class="p">)</span>
   <span class="n">relu_output_0029</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0032</span><span class="p">)</span>
   <span class="n">conv_output_0033</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0029</span><span class="p">,</span> <span class="n">onnx__Conv_624</span><span class="p">,</span> <span class="n">onnx__Conv_625</span><span class="p">)</span>
   <span class="n">add_output_0009</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0033</span><span class="p">,</span> <span class="n">relu_output_0027</span><span class="p">)</span>
   <span class="n">relu_output_0030</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0009</span><span class="p">)</span>
   <span class="n">conv_output_0034</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0030</span><span class="p">,</span> <span class="n">onnx__Conv_627</span><span class="p">,</span> <span class="n">onnx__Conv_628</span><span class="p">)</span>
   <span class="n">relu_output_0031</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0034</span><span class="p">)</span>
   <span class="n">conv_output_0035</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0031</span><span class="p">,</span> <span class="n">onnx__Conv_630</span><span class="p">,</span> <span class="n">onnx__Conv_631</span><span class="p">)</span>
   <span class="n">relu_output_0032</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0035</span><span class="p">)</span>
   <span class="n">conv_output_0036</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0032</span><span class="p">,</span> <span class="n">onnx__Conv_633</span><span class="p">,</span> <span class="n">onnx__Conv_634</span><span class="p">)</span>
   <span class="n">add_output_0010</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0036</span><span class="p">,</span> <span class="n">relu_output_0030</span><span class="p">)</span>
   <span class="n">relu_output_0033</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0010</span><span class="p">)</span>
   <span class="n">conv_output_0037</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0033</span><span class="p">,</span> <span class="n">onnx__Conv_636</span><span class="p">,</span> <span class="n">onnx__Conv_637</span><span class="p">)</span>
   <span class="n">relu_output_0034</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0037</span><span class="p">)</span>
   <span class="n">conv_output_0038</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0034</span><span class="p">,</span> <span class="n">onnx__Conv_639</span><span class="p">,</span> <span class="n">onnx__Conv_640</span><span class="p">)</span>
   <span class="n">relu_output_0035</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0038</span><span class="p">)</span>
   <span class="n">conv_output_0039</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0035</span><span class="p">,</span> <span class="n">onnx__Conv_642</span><span class="p">,</span> <span class="n">onnx__Conv_643</span><span class="p">)</span>
   <span class="n">add_output_0011</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0039</span><span class="p">,</span> <span class="n">relu_output_0033</span><span class="p">)</span>
   <span class="n">relu_output_0036</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0011</span><span class="p">)</span>
   <span class="n">conv_output_0040</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0036</span><span class="p">,</span> <span class="n">onnx__Conv_645</span><span class="p">,</span> <span class="n">onnx__Conv_646</span><span class="p">)</span>
   <span class="n">relu_output_0037</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0040</span><span class="p">)</span>
   <span class="n">conv_output_0041</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0037</span><span class="p">,</span> <span class="n">onnx__Conv_648</span><span class="p">,</span> <span class="n">onnx__Conv_649</span><span class="p">)</span>
   <span class="n">relu_output_0038</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0041</span><span class="p">)</span>
   <span class="n">conv_output_0042</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0038</span><span class="p">,</span> <span class="n">onnx__Conv_651</span><span class="p">,</span> <span class="n">onnx__Conv_652</span><span class="p">)</span>
   <span class="n">add_output_0012</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0042</span><span class="p">,</span> <span class="n">relu_output_0036</span><span class="p">)</span>
   <span class="n">relu_output_0039</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0012</span><span class="p">)</span>
   <span class="n">conv_output_0043</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0039</span><span class="p">,</span> <span class="n">onnx__Conv_654</span><span class="p">,</span> <span class="n">onnx__Conv_655</span><span class="p">)</span>
   <span class="n">relu_output_0040</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0043</span><span class="p">)</span>
   <span class="n">conv_output_0044</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0040</span><span class="p">,</span> <span class="n">onnx__Conv_657</span><span class="p">,</span> <span class="n">onnx__Conv_658</span><span class="p">)</span>
   <span class="n">relu_output_0041</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0044</span><span class="p">)</span>
   <span class="n">conv_output_0045</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0041</span><span class="p">,</span> <span class="n">onnx__Conv_660</span><span class="p">,</span> <span class="n">onnx__Conv_661</span><span class="p">)</span>
   <span class="n">conv_output_0046</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0039</span><span class="p">,</span> <span class="n">onnx__Conv_663</span><span class="p">,</span> <span class="n">onnx__Conv_664</span><span class="p">)</span>
   <span class="n">add_output_0013</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0045</span><span class="p">,</span> <span class="n">conv_output_0046</span><span class="p">)</span>
   <span class="n">relu_output_0042</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0013</span><span class="p">)</span>
   <span class="n">conv_output_0047</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0042</span><span class="p">,</span> <span class="n">onnx__Conv_666</span><span class="p">,</span> <span class="n">onnx__Conv_667</span><span class="p">)</span>
   <span class="n">relu_output_0043</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0047</span><span class="p">)</span>
   <span class="n">conv_output_0048</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0043</span><span class="p">,</span> <span class="n">onnx__Conv_669</span><span class="p">,</span> <span class="n">onnx__Conv_670</span><span class="p">)</span>
   <span class="n">relu_output_0044</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0048</span><span class="p">)</span>
   <span class="n">conv_output_0049</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0044</span><span class="p">,</span> <span class="n">onnx__Conv_672</span><span class="p">,</span> <span class="n">onnx__Conv_673</span><span class="p">)</span>
   <span class="n">add_output_0014</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0049</span><span class="p">,</span> <span class="n">relu_output_0042</span><span class="p">)</span>
   <span class="n">relu_output_0045</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0014</span><span class="p">)</span>
   <span class="n">conv_output_0050</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0045</span><span class="p">,</span> <span class="n">onnx__Conv_675</span><span class="p">,</span> <span class="n">onnx__Conv_676</span><span class="p">)</span>
   <span class="n">relu_output_0046</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0050</span><span class="p">)</span>
   <span class="n">conv_output_0051</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0046</span><span class="p">,</span> <span class="n">onnx__Conv_678</span><span class="p">,</span> <span class="n">onnx__Conv_679</span><span class="p">)</span>
   <span class="n">relu_output_0047</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0051</span><span class="p">)</span>
   <span class="n">conv_output_0052</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0047</span><span class="p">,</span> <span class="n">onnx__Conv_681</span><span class="p">,</span> <span class="n">onnx__Conv_682</span><span class="p">)</span>
   <span class="n">add_output_0015</span> <span class="o">=</span> <span class="n">Add</span> <span class="p">(</span><span class="n">conv_output_0052</span><span class="p">,</span> <span class="n">relu_output_0045</span><span class="p">)</span>
   <span class="n">relu_output_0048</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">add_output_0015</span><span class="p">)</span>
   <span class="n">conv_output_0053</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0048</span><span class="p">,</span> <span class="n">onnx__Conv_684</span><span class="p">,</span> <span class="n">onnx__Conv_685</span><span class="p">)</span>
   <span class="n">relu_output_0049</span> <span class="o">=</span> <span class="n">Relu</span> <span class="p">(</span><span class="n">conv_output_0053</span><span class="p">)</span>
   <span class="n">conv_output_0054</span> <span class="o">=</span> <span class="n">Conv</span> <span class="o">&lt;</span><span class="n">dilations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">group</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">relu_output_0049</span><span class="p">,</span> <span class="n">model_classifier_model_4_weight</span><span class="p">,</span> <span class="n">model_classifier_model_4_bias</span><span class="p">)</span>
   <span class="n">constant_output_0002</span> <span class="o">=</span> <span class="n">Constant</span> <span class="o">&lt;</span><span class="n">value</span> <span class="o">=</span> <span class="n">int64</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span><span class="mi">0</span><span class="p">}</span><span class="o">&gt;</span> <span class="p">()</span>
   <span class="n">unsqueeze_output_0000</span> <span class="o">=</span> <span class="n">Unsqueeze</span> <span class="p">(</span><span class="n">gather_output_0000</span><span class="p">,</span> <span class="n">constant_output_0002</span><span class="p">)</span>
   <span class="n">constant_output_0003</span> <span class="o">=</span> <span class="n">Constant</span> <span class="o">&lt;</span><span class="n">value</span> <span class="o">=</span> <span class="n">int64</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span><span class="mi">0</span><span class="p">}</span><span class="o">&gt;</span> <span class="p">()</span>
   <span class="n">unsqueeze_output_0001</span> <span class="o">=</span> <span class="n">Unsqueeze</span> <span class="p">(</span><span class="n">gather_output_0001</span><span class="p">,</span> <span class="n">constant_output_0003</span><span class="p">)</span>
   <span class="n">concat_output_0000</span> <span class="o">=</span> <span class="n">Concat</span> <span class="o">&lt;</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">unsqueeze_output_0000</span><span class="p">,</span> <span class="n">unsqueeze_output_0001</span><span class="p">)</span>
   <span class="n">shape_output_0002</span> <span class="o">=</span> <span class="n">Shape</span> <span class="p">(</span><span class="n">conv_output_0054</span><span class="p">)</span>
   <span class="n">constant_output_0004</span> <span class="o">=</span> <span class="n">Constant</span> <span class="o">&lt;</span><span class="n">value</span> <span class="o">=</span> <span class="n">int64</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span><span class="mi">0</span><span class="p">}</span><span class="o">&gt;</span> <span class="p">()</span>
   <span class="n">constant_output_0005</span> <span class="o">=</span> <span class="n">Constant</span> <span class="o">&lt;</span><span class="n">value</span> <span class="o">=</span> <span class="n">int64</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span><span class="mi">0</span><span class="p">}</span><span class="o">&gt;</span> <span class="p">()</span>
   <span class="n">constant_output_0006</span> <span class="o">=</span> <span class="n">Constant</span> <span class="o">&lt;</span><span class="n">value</span> <span class="o">=</span> <span class="n">int64</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span><span class="mi">2</span><span class="p">}</span><span class="o">&gt;</span> <span class="p">()</span>
   <span class="n">slice_output_0000</span> <span class="o">=</span> <span class="n">Slice</span> <span class="p">(</span><span class="n">shape_output_0002</span><span class="p">,</span> <span class="n">constant_output_0005</span><span class="p">,</span> <span class="n">constant_output_0006</span><span class="p">,</span> <span class="n">constant_output_0004</span><span class="p">)</span>
   <span class="n">cast_output_0000</span> <span class="o">=</span> <span class="n">Cast</span> <span class="o">&lt;</span><span class="n">to</span> <span class="o">=</span> <span class="mi">7</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">concat_output_0000</span><span class="p">)</span>
   <span class="n">concat_output_0001</span> <span class="o">=</span> <span class="n">Concat</span> <span class="o">&lt;</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">slice_output_0000</span><span class="p">,</span> <span class="n">cast_output_0000</span><span class="p">)</span>
   <span class="n">output_var</span> <span class="o">=</span> <span class="n">Resize</span> <span class="o">&lt;</span><span class="n">coordinate_transformation_mode</span> <span class="o">=</span> <span class="s2">&quot;half_pixel&quot;</span><span class="p">,</span> <span class="n">cubic_coeff_a</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">nearest_mode</span> <span class="o">=</span> <span class="s2">&quot;floor&quot;</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">conv_output_0054</span><span class="p">,</span> <span class="p">,</span> <span class="p">,</span> <span class="n">concat_output_0001</span><span class="p">)</span>
<span class="p">}</span>
<span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">onnx2torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">tensor</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Shape&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">OnnxShape</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;start&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;end&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Constant&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">OnnxConstant</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(())</span><span class="o">*</span><span class="mi">2</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Gather&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">gather</span><span class="o">.</span><span class="n">OnnxGather</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Shape_1&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">OnnxShape</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;start&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;end&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Constant_1&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">OnnxConstant</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(())</span><span class="o">*</span><span class="mi">3</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Gather_1&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">gather</span><span class="o">.</span><span class="n">OnnxGather</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">pooling</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span><span class="s1">&#39;stride&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span><span class="s1">&#39;padding&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span><span class="s1">&#39;dilation&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span><span class="s1">&#39;return_indices&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;ceil_mode&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_1&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_1&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_2&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_2&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_3&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_4&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_3&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_5&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_4&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_6&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_5&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_7&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_1&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_6&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_8&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_7&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_9&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_8&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_10&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">64</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_2&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_9&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_11&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_10&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_12&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_11&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_13&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_14&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_3&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_12&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_15&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_13&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_16&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_14&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_17&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_4&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_15&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_18&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_16&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_19&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_17&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_20&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_5&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_18&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_21&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_19&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_22&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_20&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_23&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">128</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_6&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_21&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_24&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_22&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_25&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_23&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_26&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_27&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_7&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_24&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_28&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_25&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_29&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_26&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_30&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_8&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_27&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_31&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_28&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_32&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_29&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_33&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_9&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_30&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_34&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_31&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_35&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_32&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_36&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_10&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_33&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_37&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_34&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_38&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_35&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_39&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_11&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_36&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_40&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_37&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_41&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_38&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_42&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_12&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_39&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_43&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_40&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_44&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_41&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_45&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">2048</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_46&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">2048</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_13&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_42&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_47&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">2048</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_43&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_48&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_44&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_49&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">2048</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_14&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_45&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_50&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">2048</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_46&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_51&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_47&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_52&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">2048</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Add_15&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">binary_math_operations</span><span class="o">.</span><span class="n">OnnxBinaryMathOperation</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;operation_type&#39;</span><span class="p">:</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;broadcast&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_48&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_53&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">2048</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Relu_49&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;inplace&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Conv_54&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;in_channels&#39;</span><span class="p">:</span><span class="mi">512</span><span class="p">,</span><span class="s1">&#39;out_channels&#39;</span><span class="p">:</span><span class="mi">21</span><span class="p">,</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;stride&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;padding&#39;</span><span class="p">:(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span><span class="s1">&#39;dilation&#39;</span><span class="p">:(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span><span class="s1">&#39;groups&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;padding_mode&#39;</span><span class="p">:</span><span class="s1">&#39;zeros&#39;</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Constant_2&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">OnnxConstant</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,))}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Unsqueeze&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">unsqueeze</span><span class="o">.</span><span class="n">OnnxUnsqueezeStaticAxes</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;axes&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Constant_3&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">OnnxConstant</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,))}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Unsqueeze_1&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">unsqueeze</span><span class="o">.</span><span class="n">OnnxUnsqueezeStaticAxes</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;axes&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Concat&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">concat</span><span class="o">.</span><span class="n">OnnxConcat</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Shape_2&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">OnnxShape</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;start&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;end&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Constant_4&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">OnnxConstant</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,))}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Constant_5&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">OnnxConstant</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,))}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Constant_6&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">OnnxConstant</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span><span class="o">*</span><span class="mi">2</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Slice&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">slice</span><span class="o">.</span><span class="n">OnnxSlice</span><span class="p">(</span><span class="o">**</span><span class="p">{}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Cast&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">cast</span><span class="o">.</span><span class="n">OnnxCast</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;onnx_dtype&#39;</span><span class="p">:</span><span class="mi">7</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Concat_1&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">concat</span><span class="o">.</span><span class="n">OnnxConcat</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;axis&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">}))</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;Resize&#39;</span><span class="p">,</span> <span class="n">onnx2torch</span><span class="o">.</span><span class="n">node_converters</span><span class="o">.</span><span class="n">resize</span><span class="o">.</span><span class="n">OnnxResize</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">&#39;mode&#39;</span><span class="p">:</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span><span class="s1">&#39;align_corners&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span><span class="s1">&#39;ignore_roi&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">,</span><span class="s1">&#39;ignore_bs_ch_size&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_1</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Shape</span><span class="p">(</span><span class="n">input_1</span><span class="p">)</span>
        <span class="n">constant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Constant</span><span class="p">()</span>
        <span class="n">gather</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">constant</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">));</span>  <span class="n">shape</span> <span class="o">=</span> <span class="n">constant</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">shape_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Shape_1</span><span class="p">(</span><span class="n">input_1</span><span class="p">)</span>
        <span class="n">constant_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Constant_1</span><span class="p">()</span>
        <span class="n">gather_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Gather_1</span><span class="p">(</span><span class="n">shape_1</span><span class="p">,</span> <span class="n">constant_1</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">));</span>  <span class="n">shape_1</span> <span class="o">=</span> <span class="n">constant_1</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">input_1</span><span class="p">);</span>  <span class="n">input_1</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu</span><span class="p">(</span><span class="n">conv</span><span class="p">);</span>  <span class="n">conv</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">max_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">relu</span><span class="p">);</span>  <span class="n">relu</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_1</span><span class="p">(</span><span class="n">max_pool</span><span class="p">)</span>
        <span class="n">relu_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_1</span><span class="p">(</span><span class="n">conv_1</span><span class="p">);</span>  <span class="n">conv_1</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_2</span><span class="p">(</span><span class="n">relu_1</span><span class="p">);</span>  <span class="n">relu_1</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_2</span><span class="p">(</span><span class="n">conv_2</span><span class="p">);</span>  <span class="n">conv_2</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_3</span><span class="p">(</span><span class="n">relu_2</span><span class="p">);</span>  <span class="n">relu_2</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_4</span><span class="p">(</span><span class="n">max_pool</span><span class="p">);</span>  <span class="n">max_pool</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">conv_3</span><span class="p">,</span> <span class="n">conv_4</span><span class="p">);</span>  <span class="n">conv_3</span> <span class="o">=</span> <span class="n">conv_4</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_3</span><span class="p">(</span><span class="n">add</span><span class="p">);</span>  <span class="n">add</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_5</span><span class="p">(</span><span class="n">relu_3</span><span class="p">)</span>
        <span class="n">relu_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_4</span><span class="p">(</span><span class="n">conv_5</span><span class="p">);</span>  <span class="n">conv_5</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_6</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_6</span><span class="p">(</span><span class="n">relu_4</span><span class="p">);</span>  <span class="n">relu_4</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_5</span><span class="p">(</span><span class="n">conv_6</span><span class="p">);</span>  <span class="n">conv_6</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_7</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_7</span><span class="p">(</span><span class="n">relu_5</span><span class="p">);</span>  <span class="n">relu_5</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_1</span><span class="p">(</span><span class="n">conv_7</span><span class="p">,</span> <span class="n">relu_3</span><span class="p">);</span>  <span class="n">conv_7</span> <span class="o">=</span> <span class="n">relu_3</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_6</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_6</span><span class="p">(</span><span class="n">add_1</span><span class="p">);</span>  <span class="n">add_1</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_8</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_8</span><span class="p">(</span><span class="n">relu_6</span><span class="p">)</span>
        <span class="n">relu_7</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_7</span><span class="p">(</span><span class="n">conv_8</span><span class="p">);</span>  <span class="n">conv_8</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_9</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_9</span><span class="p">(</span><span class="n">relu_7</span><span class="p">);</span>  <span class="n">relu_7</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_8</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_8</span><span class="p">(</span><span class="n">conv_9</span><span class="p">);</span>  <span class="n">conv_9</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_10</span><span class="p">(</span><span class="n">relu_8</span><span class="p">);</span>  <span class="n">relu_8</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_2</span><span class="p">(</span><span class="n">conv_10</span><span class="p">,</span> <span class="n">relu_6</span><span class="p">);</span>  <span class="n">conv_10</span> <span class="o">=</span> <span class="n">relu_6</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_9</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_9</span><span class="p">(</span><span class="n">add_2</span><span class="p">);</span>  <span class="n">add_2</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_11</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_11</span><span class="p">(</span><span class="n">relu_9</span><span class="p">)</span>
        <span class="n">relu_10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_10</span><span class="p">(</span><span class="n">conv_11</span><span class="p">);</span>  <span class="n">conv_11</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_12</span><span class="p">(</span><span class="n">relu_10</span><span class="p">);</span>  <span class="n">relu_10</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_11</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_11</span><span class="p">(</span><span class="n">conv_12</span><span class="p">);</span>  <span class="n">conv_12</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_13</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_13</span><span class="p">(</span><span class="n">relu_11</span><span class="p">);</span>  <span class="n">relu_11</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_14</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_14</span><span class="p">(</span><span class="n">relu_9</span><span class="p">);</span>  <span class="n">relu_9</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_3</span><span class="p">(</span><span class="n">conv_13</span><span class="p">,</span> <span class="n">conv_14</span><span class="p">);</span>  <span class="n">conv_13</span> <span class="o">=</span> <span class="n">conv_14</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_12</span><span class="p">(</span><span class="n">add_3</span><span class="p">);</span>  <span class="n">add_3</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_15</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_15</span><span class="p">(</span><span class="n">relu_12</span><span class="p">)</span>
        <span class="n">relu_13</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_13</span><span class="p">(</span><span class="n">conv_15</span><span class="p">);</span>  <span class="n">conv_15</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_16</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_16</span><span class="p">(</span><span class="n">relu_13</span><span class="p">);</span>  <span class="n">relu_13</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_14</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_14</span><span class="p">(</span><span class="n">conv_16</span><span class="p">);</span>  <span class="n">conv_16</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_17</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_17</span><span class="p">(</span><span class="n">relu_14</span><span class="p">);</span>  <span class="n">relu_14</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_4</span><span class="p">(</span><span class="n">conv_17</span><span class="p">,</span> <span class="n">relu_12</span><span class="p">);</span>  <span class="n">conv_17</span> <span class="o">=</span> <span class="n">relu_12</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_15</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_15</span><span class="p">(</span><span class="n">add_4</span><span class="p">);</span>  <span class="n">add_4</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_18</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_18</span><span class="p">(</span><span class="n">relu_15</span><span class="p">)</span>
        <span class="n">relu_16</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_16</span><span class="p">(</span><span class="n">conv_18</span><span class="p">);</span>  <span class="n">conv_18</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_19</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_19</span><span class="p">(</span><span class="n">relu_16</span><span class="p">);</span>  <span class="n">relu_16</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_17</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_17</span><span class="p">(</span><span class="n">conv_19</span><span class="p">);</span>  <span class="n">conv_19</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_20</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_20</span><span class="p">(</span><span class="n">relu_17</span><span class="p">);</span>  <span class="n">relu_17</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_5</span><span class="p">(</span><span class="n">conv_20</span><span class="p">,</span> <span class="n">relu_15</span><span class="p">);</span>  <span class="n">conv_20</span> <span class="o">=</span> <span class="n">relu_15</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_18</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_18</span><span class="p">(</span><span class="n">add_5</span><span class="p">);</span>  <span class="n">add_5</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_21</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_21</span><span class="p">(</span><span class="n">relu_18</span><span class="p">)</span>
        <span class="n">relu_19</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_19</span><span class="p">(</span><span class="n">conv_21</span><span class="p">);</span>  <span class="n">conv_21</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_22</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_22</span><span class="p">(</span><span class="n">relu_19</span><span class="p">);</span>  <span class="n">relu_19</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_20</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_20</span><span class="p">(</span><span class="n">conv_22</span><span class="p">);</span>  <span class="n">conv_22</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_23</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_23</span><span class="p">(</span><span class="n">relu_20</span><span class="p">);</span>  <span class="n">relu_20</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_6</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_6</span><span class="p">(</span><span class="n">conv_23</span><span class="p">,</span> <span class="n">relu_18</span><span class="p">);</span>  <span class="n">conv_23</span> <span class="o">=</span> <span class="n">relu_18</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_21</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_21</span><span class="p">(</span><span class="n">add_6</span><span class="p">);</span>  <span class="n">add_6</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_24</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_24</span><span class="p">(</span><span class="n">relu_21</span><span class="p">)</span>
        <span class="n">relu_22</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_22</span><span class="p">(</span><span class="n">conv_24</span><span class="p">);</span>  <span class="n">conv_24</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_25</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_25</span><span class="p">(</span><span class="n">relu_22</span><span class="p">);</span>  <span class="n">relu_22</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_23</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_23</span><span class="p">(</span><span class="n">conv_25</span><span class="p">);</span>  <span class="n">conv_25</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_26</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_26</span><span class="p">(</span><span class="n">relu_23</span><span class="p">);</span>  <span class="n">relu_23</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_27</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_27</span><span class="p">(</span><span class="n">relu_21</span><span class="p">);</span>  <span class="n">relu_21</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_7</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_7</span><span class="p">(</span><span class="n">conv_26</span><span class="p">,</span> <span class="n">conv_27</span><span class="p">);</span>  <span class="n">conv_26</span> <span class="o">=</span> <span class="n">conv_27</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_24</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_24</span><span class="p">(</span><span class="n">add_7</span><span class="p">);</span>  <span class="n">add_7</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_28</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_28</span><span class="p">(</span><span class="n">relu_24</span><span class="p">)</span>
        <span class="n">relu_25</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_25</span><span class="p">(</span><span class="n">conv_28</span><span class="p">);</span>  <span class="n">conv_28</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_29</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_29</span><span class="p">(</span><span class="n">relu_25</span><span class="p">);</span>  <span class="n">relu_25</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_26</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_26</span><span class="p">(</span><span class="n">conv_29</span><span class="p">);</span>  <span class="n">conv_29</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_30</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_30</span><span class="p">(</span><span class="n">relu_26</span><span class="p">);</span>  <span class="n">relu_26</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_8</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_8</span><span class="p">(</span><span class="n">conv_30</span><span class="p">,</span> <span class="n">relu_24</span><span class="p">);</span>  <span class="n">conv_30</span> <span class="o">=</span> <span class="n">relu_24</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_27</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_27</span><span class="p">(</span><span class="n">add_8</span><span class="p">);</span>  <span class="n">add_8</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_31</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_31</span><span class="p">(</span><span class="n">relu_27</span><span class="p">)</span>
        <span class="n">relu_28</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_28</span><span class="p">(</span><span class="n">conv_31</span><span class="p">);</span>  <span class="n">conv_31</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_32</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_32</span><span class="p">(</span><span class="n">relu_28</span><span class="p">);</span>  <span class="n">relu_28</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_29</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_29</span><span class="p">(</span><span class="n">conv_32</span><span class="p">);</span>  <span class="n">conv_32</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_33</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_33</span><span class="p">(</span><span class="n">relu_29</span><span class="p">);</span>  <span class="n">relu_29</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_9</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_9</span><span class="p">(</span><span class="n">conv_33</span><span class="p">,</span> <span class="n">relu_27</span><span class="p">);</span>  <span class="n">conv_33</span> <span class="o">=</span> <span class="n">relu_27</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_30</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_30</span><span class="p">(</span><span class="n">add_9</span><span class="p">);</span>  <span class="n">add_9</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_34</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_34</span><span class="p">(</span><span class="n">relu_30</span><span class="p">)</span>
        <span class="n">relu_31</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_31</span><span class="p">(</span><span class="n">conv_34</span><span class="p">);</span>  <span class="n">conv_34</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_35</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_35</span><span class="p">(</span><span class="n">relu_31</span><span class="p">);</span>  <span class="n">relu_31</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_32</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_32</span><span class="p">(</span><span class="n">conv_35</span><span class="p">);</span>  <span class="n">conv_35</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_36</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_36</span><span class="p">(</span><span class="n">relu_32</span><span class="p">);</span>  <span class="n">relu_32</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_10</span><span class="p">(</span><span class="n">conv_36</span><span class="p">,</span> <span class="n">relu_30</span><span class="p">);</span>  <span class="n">conv_36</span> <span class="o">=</span> <span class="n">relu_30</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_33</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_33</span><span class="p">(</span><span class="n">add_10</span><span class="p">);</span>  <span class="n">add_10</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_37</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_37</span><span class="p">(</span><span class="n">relu_33</span><span class="p">)</span>
        <span class="n">relu_34</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_34</span><span class="p">(</span><span class="n">conv_37</span><span class="p">);</span>  <span class="n">conv_37</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_38</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_38</span><span class="p">(</span><span class="n">relu_34</span><span class="p">);</span>  <span class="n">relu_34</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_35</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_35</span><span class="p">(</span><span class="n">conv_38</span><span class="p">);</span>  <span class="n">conv_38</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_39</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_39</span><span class="p">(</span><span class="n">relu_35</span><span class="p">);</span>  <span class="n">relu_35</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_11</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_11</span><span class="p">(</span><span class="n">conv_39</span><span class="p">,</span> <span class="n">relu_33</span><span class="p">);</span>  <span class="n">conv_39</span> <span class="o">=</span> <span class="n">relu_33</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_36</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_36</span><span class="p">(</span><span class="n">add_11</span><span class="p">);</span>  <span class="n">add_11</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_40</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_40</span><span class="p">(</span><span class="n">relu_36</span><span class="p">)</span>
        <span class="n">relu_37</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_37</span><span class="p">(</span><span class="n">conv_40</span><span class="p">);</span>  <span class="n">conv_40</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_41</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_41</span><span class="p">(</span><span class="n">relu_37</span><span class="p">);</span>  <span class="n">relu_37</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_38</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_38</span><span class="p">(</span><span class="n">conv_41</span><span class="p">);</span>  <span class="n">conv_41</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_42</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_42</span><span class="p">(</span><span class="n">relu_38</span><span class="p">);</span>  <span class="n">relu_38</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_12</span><span class="p">(</span><span class="n">conv_42</span><span class="p">,</span> <span class="n">relu_36</span><span class="p">);</span>  <span class="n">conv_42</span> <span class="o">=</span> <span class="n">relu_36</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_39</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_39</span><span class="p">(</span><span class="n">add_12</span><span class="p">);</span>  <span class="n">add_12</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_43</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_43</span><span class="p">(</span><span class="n">relu_39</span><span class="p">)</span>
        <span class="n">relu_40</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_40</span><span class="p">(</span><span class="n">conv_43</span><span class="p">);</span>  <span class="n">conv_43</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_44</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_44</span><span class="p">(</span><span class="n">relu_40</span><span class="p">);</span>  <span class="n">relu_40</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_41</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_41</span><span class="p">(</span><span class="n">conv_44</span><span class="p">);</span>  <span class="n">conv_44</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_45</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_45</span><span class="p">(</span><span class="n">relu_41</span><span class="p">);</span>  <span class="n">relu_41</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_46</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_46</span><span class="p">(</span><span class="n">relu_39</span><span class="p">);</span>  <span class="n">relu_39</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_13</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_13</span><span class="p">(</span><span class="n">conv_45</span><span class="p">,</span> <span class="n">conv_46</span><span class="p">);</span>  <span class="n">conv_45</span> <span class="o">=</span> <span class="n">conv_46</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_42</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_42</span><span class="p">(</span><span class="n">add_13</span><span class="p">);</span>  <span class="n">add_13</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_47</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_47</span><span class="p">(</span><span class="n">relu_42</span><span class="p">)</span>
        <span class="n">relu_43</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_43</span><span class="p">(</span><span class="n">conv_47</span><span class="p">);</span>  <span class="n">conv_47</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_48</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_48</span><span class="p">(</span><span class="n">relu_43</span><span class="p">);</span>  <span class="n">relu_43</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_44</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_44</span><span class="p">(</span><span class="n">conv_48</span><span class="p">);</span>  <span class="n">conv_48</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_49</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_49</span><span class="p">(</span><span class="n">relu_44</span><span class="p">);</span>  <span class="n">relu_44</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_14</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_14</span><span class="p">(</span><span class="n">conv_49</span><span class="p">,</span> <span class="n">relu_42</span><span class="p">);</span>  <span class="n">conv_49</span> <span class="o">=</span> <span class="n">relu_42</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_45</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_45</span><span class="p">(</span><span class="n">add_14</span><span class="p">);</span>  <span class="n">add_14</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_50</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_50</span><span class="p">(</span><span class="n">relu_45</span><span class="p">)</span>
        <span class="n">relu_46</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_46</span><span class="p">(</span><span class="n">conv_50</span><span class="p">);</span>  <span class="n">conv_50</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_51</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_51</span><span class="p">(</span><span class="n">relu_46</span><span class="p">);</span>  <span class="n">relu_46</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_47</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_47</span><span class="p">(</span><span class="n">conv_51</span><span class="p">);</span>  <span class="n">conv_51</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_52</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_52</span><span class="p">(</span><span class="n">relu_47</span><span class="p">);</span>  <span class="n">relu_47</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">add_15</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Add_15</span><span class="p">(</span><span class="n">conv_52</span><span class="p">,</span> <span class="n">relu_45</span><span class="p">);</span>  <span class="n">conv_52</span> <span class="o">=</span> <span class="n">relu_45</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_48</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_48</span><span class="p">(</span><span class="n">add_15</span><span class="p">);</span>  <span class="n">add_15</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_53</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_53</span><span class="p">(</span><span class="n">relu_48</span><span class="p">);</span>  <span class="n">relu_48</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">relu_49</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Relu_49</span><span class="p">(</span><span class="n">conv_53</span><span class="p">);</span>  <span class="n">conv_53</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_54</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Conv_54</span><span class="p">(</span><span class="n">relu_49</span><span class="p">);</span>  <span class="n">relu_49</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">constant_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Constant_2</span><span class="p">()</span>
        <span class="n">unsqueeze</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Unsqueeze</span><span class="p">(</span><span class="n">gather</span><span class="p">);</span>  <span class="n">gather</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">constant_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Constant_3</span><span class="p">()</span>
        <span class="n">unsqueeze_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Unsqueeze_1</span><span class="p">(</span><span class="n">gather_1</span><span class="p">);</span>  <span class="n">gather_1</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">concat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">unsqueeze</span><span class="p">,</span> <span class="n">unsqueeze_1</span><span class="p">);</span>  <span class="n">unsqueeze</span> <span class="o">=</span> <span class="n">unsqueeze_1</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">shape_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Shape_2</span><span class="p">(</span><span class="n">conv_54</span><span class="p">)</span>
        <span class="n">constant_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Constant_4</span><span class="p">()</span>
        <span class="n">constant_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Constant_5</span><span class="p">()</span>
        <span class="n">constant_6</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Constant_6</span><span class="p">()</span>
        <span class="n">slice_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Slice</span><span class="p">(</span><span class="n">shape_2</span><span class="p">,</span> <span class="n">constant_5</span><span class="p">,</span> <span class="n">constant_6</span><span class="p">,</span> <span class="n">constant_4</span><span class="p">);</span>  <span class="n">shape_2</span> <span class="o">=</span> <span class="n">constant_5</span> <span class="o">=</span> <span class="n">constant_6</span> <span class="o">=</span> <span class="n">constant_4</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">cast</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">concat</span><span class="p">);</span>  <span class="n">concat</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">concat_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Concat_1</span><span class="p">(</span><span class="n">slice_1</span><span class="p">,</span> <span class="n">cast</span><span class="p">);</span>  <span class="n">slice_1</span> <span class="o">=</span> <span class="n">cast</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">resize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">conv_54</span><span class="p">,</span> <span class="n">sizes</span> <span class="o">=</span> <span class="n">concat_1</span><span class="p">);</span>  <span class="n">conv_54</span> <span class="o">=</span> <span class="n">concat_1</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">resize</span>

<span class="n">cpu</span>
<span class="n">cpu</span> <span class="n">cpu</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="while-you-train-the-model-modlee-prepares-everything-you-need-for-your-convenience">
<h3>3. While you train the model, Modlee prepares everything you need for your convenience:<a class="headerlink" href="#while-you-train-the-model-modlee-prepares-everything-you-need-for-your-convenience" title="Link to this heading"></a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assumes that modlee_model is</span>
<span class="kn">import</span> <span class="nn">inspect</span>

<span class="k">class</span> <span class="nc">RecommendedModel</span><span class="p">(</span><span class="n">modlee</span><span class="o">.</span><span class="n">recommender</span><span class="o">.</span><span class="n">RecommendedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
            <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span>
            <span class="n">optimizer</span><span class="p">,</span>
            <span class="n">factor</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">patience</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the learning rate scheduler</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sch</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">):</span>
            <span class="n">sch</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">callback_metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;scheduler_last_lr&#39;</span><span class="p">,</span><span class="n">sch</span><span class="o">.</span><span class="n">_last_lr</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">on_train_epoch_end</span><span class="p">()</span>

<span class="n">recd_model</span> <span class="o">=</span> <span class="n">RecommendedModel</span><span class="p">(</span><span class="n">modlee_model</span><span class="p">)</span>

<span class="c1"># The built-in configure callbacks function should be the same as the base ModleeModel</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== ORIGINAL configure_callbacks ====&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">getsource</span><span class="p">(</span><span class="n">recd_model</span><span class="o">.</span><span class="n">configure_callbacks</span><span class="p">))</span>
<span class="c1"># The updated configure_optimizers, with patience of 200, should be printed</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== ORIGINAL configure_optimizers ====&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">getsource</span><span class="p">(</span><span class="n">modlee</span><span class="o">.</span><span class="n">recommender</span><span class="o">.</span><span class="n">RecommendedModel</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== UPDATED configure_optimizers ====&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">getsource</span><span class="p">(</span><span class="n">recd_model</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">====</span> <span class="n">ORIGINAL</span> <span class="n">configure_callbacks</span> <span class="o">====</span>
    <span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">base_callbacks</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">configure_callbacks</span><span class="p">()</span>
        <span class="c1"># base_callbacks.append(</span>
        <span class="c1">#     pl.callbacks.EarlyStopping(</span>
        <span class="c1">#         &#39;val_loss&#39;,</span>
        <span class="c1">#         patience=10,</span>
        <span class="c1">#         verbose=True,)</span>
        <span class="c1"># )</span>
        <span class="k">return</span> <span class="n">base_callbacks</span>

<span class="o">====</span> <span class="n">ORIGINAL</span> <span class="n">configure_optimizers</span> <span class="o">====</span>
    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
            <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span>
            <span class="n">optimizer</span><span class="p">,</span>
            <span class="n">factor</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span>

<span class="o">====</span> <span class="n">ORIGINAL</span> <span class="n">configure_optimizers</span> <span class="o">====</span>
    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
            <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span>
            <span class="n">optimizer</span><span class="p">,</span>
            <span class="n">factor</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">patience</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print(dir(modlee_model))</span>
<span class="c1"># import inspect</span>
<span class="c1"># print(inspect.getsource(modlee_model.train))</span>
<span class="c1"># import lightning.pytorch as pl</span>
<span class="c1"># callbacks = modlee_model.configure_callbacks()</span>
<span class="c1"># print(callbacks)</span>
<span class="c1"># trainer = pl.Trainer(</span>
<span class="c1">#     max_epochs=1,</span>
<span class="c1">#     # callbacks 2,3,4 (logOutput, logParams, PushAPI) are fine</span>
<span class="c1">#     # callback 0 (dataStats) is fine</span>
<span class="c1">#     # 1 also seems fine</span>
<span class="c1">#     # callbacks=[callbacks[c] for c in [1]],</span>
<span class="c1">#     callbacks=callbacks,</span>
<span class="c1">#     enable_model_summary=False,</span>
<span class="c1">#     )</span>
<span class="c1"># with modlee.start_run() as run:</span>
<span class="c1">#     trainer.fit(model=modlee_model,</span>
<span class="c1">#         train_dataloaders=train_dataloader,</span>
<span class="c1">#         val_dataloaders=train_dataloader)</span>
<span class="n">recommender</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">INFO</span><span class="p">:</span> <span class="n">LOCAL_RANK</span><span class="p">:</span> <span class="mi">0</span> <span class="o">-</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">lightning</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">accelerators</span><span class="o">.</span><span class="n">cuda</span><span class="p">:</span><span class="n">LOCAL_RANK</span><span class="p">:</span> <span class="mi">0</span> <span class="o">-</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">----------------------------------------------------------------</span>
<span class="n">Training</span> <span class="n">your</span> <span class="n">recommended</span> <span class="n">modlee</span> <span class="n">model</span><span class="p">:</span>
     <span class="o">-</span> <span class="n">Running</span> <span class="n">this</span> <span class="n">model</span><span class="p">:</span> <span class="o">./</span><span class="n">modlee_model</span><span class="o">.</span><span class="n">py</span>
     <span class="o">-</span> <span class="n">On</span> <span class="n">the</span> <span class="n">dataloader</span> <span class="n">previously</span> <span class="n">analyzed</span> <span class="n">by</span> <span class="n">the</span> <span class="n">recommender</span>
<span class="o">----------------------------------------------------------------</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Sanity Checking: 0it [00:00, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">projects</span><span class="o">/.</span><span class="n">venv</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">lightning</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">loops</span><span class="o">/</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">281</span><span class="p">:</span> <span class="n">PossibleUserWarning</span><span class="p">:</span> <span class="n">The</span> <span class="n">number</span> <span class="n">of</span> <span class="n">training</span> <span class="n">batches</span> <span class="p">(</span><span class="mi">14</span><span class="p">)</span> <span class="ow">is</span> <span class="n">smaller</span> <span class="n">than</span> <span class="n">the</span> <span class="n">logging</span> <span class="n">interval</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span> <span class="n">Set</span> <span class="n">a</span> <span class="n">lower</span> <span class="n">value</span> <span class="k">for</span> <span class="n">log_every_n_steps</span> <span class="k">if</span> <span class="n">you</span> <span class="n">want</span> <span class="n">to</span> <span class="n">see</span> <span class="n">logs</span> <span class="k">for</span> <span class="n">the</span> <span class="n">training</span> <span class="n">epoch</span><span class="o">.</span>
  <span class="n">rank_zero_warn</span><span class="p">(</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Training: 0it [00:00, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">projects</span><span class="o">/.</span><span class="n">venv</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">onnx2torch</span><span class="o">/</span><span class="n">node_converters</span><span class="o">/</span><span class="n">shape</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">46</span><span class="p">:</span> <span class="n">TracerWarning</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span> <span class="n">results</span> <span class="n">are</span> <span class="n">registered</span> <span class="k">as</span> <span class="n">constants</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">trace</span><span class="o">.</span> <span class="n">You</span> <span class="n">can</span> <span class="n">safely</span> <span class="n">ignore</span> <span class="n">this</span> <span class="n">warning</span> <span class="k">if</span> <span class="n">you</span> <span class="n">use</span> <span class="n">this</span> <span class="n">function</span> <span class="n">to</span> <span class="n">create</span> <span class="n">tensors</span> <span class="n">out</span> <span class="n">of</span> <span class="n">constant</span> <span class="n">variables</span> <span class="n">that</span> <span class="n">would</span> <span class="n">be</span> <span class="n">the</span> <span class="n">same</span> <span class="n">every</span> <span class="n">time</span> <span class="n">you</span> <span class="n">call</span> <span class="n">this</span> <span class="n">function</span><span class="o">.</span> <span class="n">In</span> <span class="nb">any</span> <span class="n">other</span> <span class="n">case</span><span class="p">,</span> <span class="n">this</span> <span class="n">might</span> <span class="n">cause</span> <span class="n">the</span> <span class="n">trace</span> <span class="n">to</span> <span class="n">be</span> <span class="n">incorrect</span><span class="o">.</span>
  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
<span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">projects</span><span class="o">/.</span><span class="n">venv</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">onnx2torch</span><span class="o">/</span><span class="n">node_converters</span><span class="o">/</span><span class="nb">slice</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">33</span><span class="p">:</span> <span class="n">TracerWarning</span><span class="p">:</span> <span class="n">Converting</span> <span class="n">a</span> <span class="n">tensor</span> <span class="n">to</span> <span class="n">a</span> <span class="n">NumPy</span> <span class="n">array</span> <span class="n">might</span> <span class="n">cause</span> <span class="n">the</span> <span class="n">trace</span> <span class="n">to</span> <span class="n">be</span> <span class="n">incorrect</span><span class="o">.</span> <span class="n">We</span> <span class="n">can</span><span class="s1">&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!</span>
  <span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">projects</span><span class="o">/.</span><span class="n">venv</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">onnx2torch</span><span class="o">/</span><span class="n">node_converters</span><span class="o">/</span><span class="nb">slice</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">36</span><span class="p">:</span> <span class="n">TracerWarning</span><span class="p">:</span> <span class="n">Using</span> <span class="nb">len</span> <span class="n">to</span> <span class="n">get</span> <span class="n">tensor</span> <span class="n">shape</span> <span class="n">might</span> <span class="n">cause</span> <span class="n">the</span> <span class="n">trace</span> <span class="n">to</span> <span class="n">be</span> <span class="n">incorrect</span><span class="o">.</span> <span class="n">Recommended</span> <span class="n">usage</span> <span class="n">would</span> <span class="n">be</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span> <span class="n">Passing</span> <span class="n">a</span> <span class="n">tensor</span> <span class="n">of</span> <span class="n">different</span> <span class="n">shape</span> <span class="n">might</span> <span class="n">lead</span> <span class="n">to</span> <span class="n">errors</span> <span class="ow">or</span> <span class="n">silently</span> <span class="n">give</span> <span class="n">incorrect</span> <span class="n">results</span><span class="o">.</span>
  <span class="n">steps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">starts</span><span class="p">)</span>
<span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">projects</span><span class="o">/.</span><span class="n">venv</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">onnx2torch</span><span class="o">/</span><span class="n">node_converters</span><span class="o">/</span><span class="nb">slice</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">42</span><span class="p">:</span> <span class="n">TracerWarning</span><span class="p">:</span> <span class="n">Iterating</span> <span class="n">over</span> <span class="n">a</span> <span class="n">tensor</span> <span class="n">might</span> <span class="n">cause</span> <span class="n">the</span> <span class="n">trace</span> <span class="n">to</span> <span class="n">be</span> <span class="n">incorrect</span><span class="o">.</span> <span class="n">Passing</span> <span class="n">a</span> <span class="n">tensor</span> <span class="n">of</span> <span class="n">different</span> <span class="n">shape</span> <span class="n">won</span><span class="s1">&#39;t change the number of iterations executed (and might lead to errors or silently give incorrect results).</span>
  <span class="k">for</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">starts</span><span class="p">,</span> <span class="n">ends</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">steps</span><span class="p">):</span>
<span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">projects</span><span class="o">/.</span><span class="n">venv</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">onnx2torch</span><span class="o">/</span><span class="n">node_converters</span><span class="o">/</span><span class="n">resize</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">73</span><span class="p">:</span> <span class="n">TracerWarning</span><span class="p">:</span> <span class="n">Converting</span> <span class="n">a</span> <span class="n">tensor</span> <span class="n">to</span> <span class="n">a</span> <span class="n">Python</span> <span class="n">boolean</span> <span class="n">might</span> <span class="n">cause</span> <span class="n">the</span> <span class="n">trace</span> <span class="n">to</span> <span class="n">be</span> <span class="n">incorrect</span><span class="o">.</span> <span class="n">We</span> <span class="n">can</span><span class="s1">&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!</span>
  <span class="k">if</span> <span class="n">sizes</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
<span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">projects</span><span class="o">/.</span><span class="n">venv</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">onnx2torch</span><span class="o">/</span><span class="n">node_converters</span><span class="o">/</span><span class="n">resize</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">74</span><span class="p">:</span> <span class="n">TracerWarning</span><span class="p">:</span> <span class="n">Converting</span> <span class="n">a</span> <span class="n">tensor</span> <span class="n">to</span> <span class="n">a</span> <span class="n">Python</span> <span class="nb">list</span> <span class="n">might</span> <span class="n">cause</span> <span class="n">the</span> <span class="n">trace</span> <span class="n">to</span> <span class="n">be</span> <span class="n">incorrect</span><span class="o">.</span> <span class="n">We</span> <span class="n">can</span><span class="s1">&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!</span>
  <span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">projects</span><span class="o">/.</span><span class="n">venv</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.10</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">onnx2torch</span><span class="o">/</span><span class="n">node_converters</span><span class="o">/</span><span class="n">resize</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">76</span><span class="p">:</span> <span class="n">TracerWarning</span><span class="p">:</span> <span class="n">Converting</span> <span class="n">a</span> <span class="n">tensor</span> <span class="n">to</span> <span class="n">a</span> <span class="n">Python</span> <span class="n">boolean</span> <span class="n">might</span> <span class="n">cause</span> <span class="n">the</span> <span class="n">trace</span> <span class="n">to</span> <span class="n">be</span> <span class="n">incorrect</span><span class="o">.</span> <span class="n">We</span> <span class="n">can</span><span class="s1">&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_bs_ch_size</span> <span class="ow">and</span> <span class="n">input_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="n">sizes</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Validation: 0it [00:00, ?it/s]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">INFO</span><span class="p">:</span> <span class="n">Metric</span> <span class="n">val_loss</span> <span class="n">improved</span><span class="o">.</span> <span class="n">New</span> <span class="n">best</span> <span class="n">score</span><span class="p">:</span> <span class="mf">16.994</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">lightning</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">early_stopping</span><span class="p">:</span><span class="n">Metric</span> <span class="n">val_loss</span> <span class="n">improved</span><span class="o">.</span> <span class="n">New</span> <span class="n">best</span> <span class="n">score</span><span class="p">:</span> <span class="mf">16.994</span>
</pre></div>
</div>
</section>
<section id="modlee-auto-documents-your-experiment-locally-and-learns-from-non-sensitive-details">
<h3>4. Modlee auto-documents your experiment locally and learns from non-sensitive details:<a class="headerlink" href="#modlee-auto-documents-your-experiment-locally-and-learns-from-non-sensitive-details" title="Link to this heading"></a></h3>
<p>Sharing helps to enhance ML model recommendations across the entire
community of modlee users</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recommender</span><span class="o">.</span><span class="n">train_documentation_locations</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-----------------------------------------------------------------------------------------------</span>

<span class="n">Modlee</span> <span class="n">documented</span> <span class="nb">all</span> <span class="n">the</span> <span class="n">details</span> <span class="n">about</span> <span class="n">your</span> <span class="n">trained</span> <span class="n">model</span> <span class="ow">and</span> <span class="n">experiment</span> <span class="n">here</span><span class="p">:</span>

        <span class="n">Path</span><span class="p">:</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">projects</span><span class="o">/</span><span class="n">modlee_survey</span><span class="o">/</span><span class="n">notebooks</span><span class="o">/</span><span class="n">mlruns</span><span class="o">/</span><span class="mi">0</span><span class="o">/</span><span class="mi">23</span><span class="n">cd9c1a052c49a88e1b73c22a4ad574</span><span class="o">/</span>
        <span class="n">Experiment_id</span><span class="p">:</span> <span class="n">automatically</span> <span class="n">assigned</span> <span class="n">to</span> <span class="o">|</span> <span class="mi">0</span>
        <span class="n">Run_id</span><span class="p">:</span> <span class="n">automatically</span> <span class="n">assigned</span> <span class="n">to</span> <span class="o">|</span> <span class="mi">23</span><span class="n">cd9c1a052c49a88e1b73c22a4ad574</span>

<span class="o">-----------------------------------------------------------------------------------------------</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="document.html" class="btn btn-neutral float-left" title="Documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Modlee, Inc.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>